params_types_unique	return_types_unique	image_types	images_types	unsupported_types	first_image_param_names	subsequent_image_param_names	signatures	signatures_filtered
cv2.typing.Rect	tuple[_typing.Sequence[UMat], UMat]	UMat	_typing.Sequence[UMat]	_typing.Sequence	hu	meta	CamShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]	CamShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]
bool	tuple[int, UMat, UMat, cv2.typing.Rect]	cv2.typing.MatLike	_typing.Sequence[cv2.typing.MatLiike]	_typing.Callable	point	M	CamShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]	CamShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]
_typing.Sequence[float]	tuple[cv2.typing.MatLike, cv2.typing.MatLike]	cv2.typing.MatLike | None	_typing.Sequence[cv2.typing.Rect]	_typing.Type[cv2.dnn.LayerProtocol]	prevImg	iM	Canny(image: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, apertureSize: int, L2gradient: bool) -> cv2.typing.MatLike	Canny(image: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, apertureSize: int, L2gradient: bool) -> cv2.typing.MatLike
HandEyeCalibrationMethod	tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	cv2.cuda.GpuMat	_typing.Sequence[cv2.typing.MatLike]	HistogramCostExtractor	m	dst	Canny(image: UMat, threshold1: float, threshold2: float, edges: UMat | None, apertureSize: int, L2gradient: bool) -> UMat	Canny(image: UMat, threshold1: float, threshold2: float, edges: UMat | None, apertureSize: int, L2gradient: bool) -> UMat
RobotWorldHandEyeCalibrationMethod	cv2.typing.RotatedRect		_typing.Sequence[UMat] | None	ShapeTransformer	H1	dist_coeff1	Canny(dx: cv2.typing.MatLike, dy: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, L2gradient: bool) -> cv2.typing.MatLike	Canny(dx: cv2.typing.MatLike, dy: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, L2gradient: bool) -> cv2.typing.MatLike
CirclesGridFinderParameters	tuple[bool, Animation]			UsacParams	result	dist_coeff2	Canny(dx: UMat, dy: UMat, threshold1: float, threshold2: float, edges: UMat | None, L2gradient: bool) -> UMat	Canny(dx: UMat, dy: UMat, threshold1: float, threshold2: float, edges: UMat | None, L2gradient: bool) -> UMat
SolvePnPMethod	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]			Animation	M	kernelX	EMD(signature1: cv2.typing.MatLike, signature2: cv2.typing.MatLike, distType: int, cost: cv2.typing.MatLike | None, lowerBound: float | None, flow: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.MatLike]	EMD(signature1: cv2.typing.MatLike, signature2: cv2.typing.MatLike, distType: int, cost: cv2.typing.MatLike | None, lowerBound: float | None, flow: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.MatLike]
cv2.typing.Point	tuple[int, cv2.typing.Rect]			CirclesGridFinderParameters	cameraMatrix1	points	EMD(signature1: UMat, signature2: UMat, distType: int, cost: UMat | None, lowerBound: float | None, flow: UMat | None) -> tuple[float, float, UMat]	EMD(signature1: UMat, signature2: UMat, distType: int, cost: UMat | None, lowerBound: float | None, flow: UMat | None) -> tuple[float, float, UMat]
_typing.Sequence[KeyPoint]	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat, UMat, UMat]			cv2.typing.FeatureDetector	dst	centroids	GaussianBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, sigmaX: float, dst: cv2.typing.MatLike | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> cv2.typing.MatLike	GaussianBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, sigmaX: float, dst: cv2.typing.MatLike | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> cv2.typing.MatLike
cv2.typing.RotatedRect	tuple[cv2.typing.Scalar, UMat]			AffineTransformerAlignMTBBackgroundSubtractorKNNBackgroundSubtractorMOG2CalibrateDebevecCalibrateRobertsonCLAHEGArrayDescGeneralizedHoughBallardGeneralizedHoughGuilGOpaqueDescGScalarDescHausdorffDistanceExtractorHistogramCostExtractorLineSegmentDetectorMergeDebevecMergeMertensMergeRobertsonShapeContextDistanceExtractorThinPlateSplineShapeTransformerTonemapTonemapDragoTonemapMantiukTonemapReinhard	from_	v2	GaussianBlur(src: UMat, ksize: cv2.typing.Size, sigmaX: float, dst: UMat | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> UMat	GaussianBlur(src: UMat, ksize: cv2.typing.Size, sigmaX: float, dst: UMat | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> UMat
cv2.typing.Size | None	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], _typing.Sequence[UMat]]				projMatr1	dABdB	HoughCircles(image: cv2.typing.MatLike, method: int, dp: float, minDist: float, circles: cv2.typing.MatLike | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> cv2.typing.MatLike	HoughCircles(image: cv2.typing.MatLike, method: int, dp: float, minDist: float, circles: cv2.typing.MatLike | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> cv2.typing.MatLike
_typing.Callable[[int, int, int, int, _typing.Any | None], None]	None				src1	F	HoughCircles(image: UMat, method: int, dp: float, minDist: float, circles: UMat | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> UMat	HoughCircles(image: UMat, method: int, dp: float, minDist: float, circles: UMat | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> UMat
AlgorithmHint	tuple[cv2.typing.Point2d, float]				prev	warpMatrix	HoughLines(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> cv2.typing.MatLike	HoughLines(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> cv2.typing.MatLike
UsacParams	int				points	contour2	HoughLines(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> UMat	HoughLines(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> UMat
UMat | None	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]				image	P	HoughLinesP(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, minLineLength: float, maxLineGap: float) -> cv2.typing.MatLike	HoughLinesP(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, minLineLength: float, maxLineGap: float) -> cv2.typing.MatLike
cv2.typing.Point2d	tuple[bool, UMat]				F	nextImg	HoughLinesP(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, minLineLength: float, maxLineGap: float) -> UMat	HoughLinesP(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, minLineLength: float, maxLineGap: float) -> UMat
cv2.typing.Rect2d	LineSegmentDetector				srcPoints	R1	HoughLinesPointSet(point: cv2.typing.MatLike, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike	HoughLinesPointSet(point: cv2.typing.MatLike, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Point2f	GScalarDesc				v1	src2	HoughLinesPointSet(point: UMat, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: UMat | None) -> UMat	HoughLinesPointSet(point: UMat, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: UMat | None) -> UMat
_typing.Sequence[int]	tuple[float, UMat, UMat]				data	err	HoughLinesWithAccumulator(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float) -> cv2.typing.MatLike	HoughLinesWithAccumulator(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float) -> cv2.typing.MatLike
float | None	tuple[bool, cv2.typing.MatLike]				pt1	u	HoughLinesWithAccumulator(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float) -> UMat	HoughLinesWithAccumulator(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float) -> UMat
_typing.Sequence[str]	_typing.Sequence[UMat]				R_cam2gripper	rhs	HuMoments(m: cv2.typing.Moments, hu: cv2.typing.MatLike | None) -> cv2.typing.MatLike	HuMoments(m: cv2.typing.Moments, hu: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Range	MergeDebevec				map1	dstmap1	HuMoments(m: cv2.typing.Moments, hu: UMat | None) -> UMat	HuMoments(m: cv2.typing.Moments, hu: UMat | None) -> UMat
_typing.Sequence[_typing.Sequence[DMatch]]	tuple[bool, UMat, UMat, UMat, UMat]				src	userColor	LUT(src: cv2.typing.MatLike, lut: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	LUT(src: cv2.typing.MatLike, lut: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.TermCriteria	tuple[int, UMat, UMat]				src2	dst1	LUT(src: UMat, lut: UMat, dst: UMat | None) -> UMat	LUT(src: UMat, lut: UMat, dst: UMat | None) -> UMat
_typing.Any | None	tuple[cv2.typing.RotatedRect, cv2.typing.Rect]				beforePoints	p12	Laplacian(src: cv2.typing.MatLike, ddepth: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Laplacian(src: cv2.typing.MatLike, ddepth: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
_typing.Sequence[cv2.typing.Rect]	tuple[bool, _typing.Sequence[cv2.typing.MatLike]]				Func	pts2	Laplacian(src: UMat, ddepth: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat	Laplacian(src: UMat, ddepth: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat
_typing.Sequence[cv2.typing.MatLike]	cv2.typing.Rect				array	dt3dr1	Mahalanobis(v1: cv2.typing.MatLike, v2: cv2.typing.MatLike, icovar: cv2.typing.MatLike) -> float	Mahalanobis(v1: cv2.typing.MatLike, v2: cv2.typing.MatLike, icovar: cv2.typing.MatLike) -> float
_typing.Callable[[int], None]	tuple[cv2.typing.MatLike, cv2.typing.Rect]				p1	Qz	Mahalanobis(v1: UMat, v2: UMat, icovar: UMat) -> float	Mahalanobis(v1: UMat, v2: UMat, icovar: UMat) -> float
Animation	tuple[float, UMat]				buf	labels	PCABackProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike	PCABackProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.MatLike | None	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				mat	dr3dt1	PCABackProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat	PCABackProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat
str	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]				mtx	inputImage	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
int	tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]				img1	dr3dr2	PCACompute(data: UMat, mean: UMat, eigenvectors: UMat | None, maxComponents: int) -> tuple[UMat, UMat]	PCACompute(data: UMat, mean: UMat, eigenvectors: UMat | None, maxComponents: int) -> tuple[UMat, UMat]
DrawMatchesFlags	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				curve	R_gripper2cam	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Callable[[tuple[int] | tuple[int, _typing.Any]], None]	_typing.Sequence[cv2.typing.Point]				probImage	hull	PCACompute(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None) -> tuple[UMat, UMat]	PCACompute(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None) -> tuple[UMat, UMat]
_typing.Sequence[UMat] | None	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				contour1	R13	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
HistogramCostExtractor	AffineTransformer				mask	lut	PCACompute2(data: UMat, mean: UMat, eigenvectors: UMat | None, eigenvalues: UMat | None, maxComponents: int) -> tuple[UMat, UMat, UMat]	PCACompute2(data: UMat, mean: UMat, eigenvectors: UMat | None, eigenvalues: UMat | None, maxComponents: int) -> tuple[UMat, UMat, UMat]
cv2.typing.FeatureDetector	BackgroundSubtractorMOG2				objectPoints	flow	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Sequence[_typing.Sequence[str]]	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat]]				cameraMatrix	magnitude	PCACompute2(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None, eigenvalues: UMat | None) -> tuple[UMat, UMat, UMat]	PCACompute2(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None, eigenvalues: UMat | None) -> tuple[UMat, UMat, UMat]
UMat	tuple[bool, UMat, UMat]				hist	dstPoints	PCAProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike	PCAProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.MatLike	Tonemap				x	projPoints1	PCAProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat	PCAProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat
_typing.Callable[[int, str, str, str, int], None] | None	_typing.Sequence[cv2.typing.Rect]				rvec1	window	PSNR(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, R: float) -> float	PSNR(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, R: float) -> float
cv2.typing.Scalar	tuple[cv2.typing.Scalar, cv2.typing.MatLike]				kx	delta	PSNR(src1: UMat, src2: UMat, R: float) -> float	PSNR(src1: UMat, src2: UMat, R: float) -> float
ShapeTransformer	GArrayDesc				E	hierarchy	RQDecomp3x3(src: cv2.typing.MatLike, mtxR: cv2.typing.MatLike | None, mtxQ: cv2.typing.MatLike | None, Qx: cv2.typing.MatLike | None, Qy: cv2.typing.MatLike | None, Qz: cv2.typing.MatLike | None) -> tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	RQDecomp3x3(src: cv2.typing.MatLike, mtxR: cv2.typing.MatLike | None, mtxQ: cv2.typing.MatLike | None, Qx: cv2.typing.MatLike | None, Qy: cv2.typing.MatLike | None, Qz: cv2.typing.MatLike | None) -> tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Sequence[DMatch]	CalibrateRobertson				signature1	dt3dt2	RQDecomp3x3(src: UMat, mtxR: UMat | None, mtxQ: UMat | None, Qx: UMat | None, Qy: UMat | None, Qz: UMat | None) -> tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]	RQDecomp3x3(src: UMat, mtxR: UMat | None, mtxQ: UMat | None, Qx: UMat | None, Qy: UMat | None, Qz: UMat | None) -> tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]
float	CalibrateDebevec				R_base2world	roots	Rodrigues(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	Rodrigues(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
cv2.typing.Size	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]				flow	status	Rodrigues(src: UMat, dst: UMat | None, jacobian: UMat | None) -> tuple[UMat, UMat]	Rodrigues(src: UMat, dst: UMat | None, jacobian: UMat | None) -> tuple[UMat, UMat]
_typing.Sequence[cv2.typing.MatLike] | None	GeneralizedHoughBallard				templateImage	p2	SVBackSubst(w: cv2.typing.MatLike, u: cv2.typing.MatLike, vt: cv2.typing.MatLike, rhs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	SVBackSubst(w: cv2.typing.MatLike, u: cv2.typing.MatLike, vt: cv2.typing.MatLike, rhs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
_typing.Sequence[UMat]	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]				magnitude	dst2	SVBackSubst(w: UMat, u: UMat, vt: UMat, rhs: UMat, dst: UMat | None) -> UMat	SVBackSubst(w: UMat, u: UMat, vt: UMat, rhs: UMat, dst: UMat | None) -> UMat
_typing.Type[cv2.dnn.LayerProtocol]	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]				disparity	triangulatedPoints	SVDecomp(src: cv2.typing.MatLike, w: cv2.typing.MatLike | None, u: cv2.typing.MatLike | None, vt: cv2.typing.MatLike | None, flags: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	SVDecomp(src: cv2.typing.MatLike, w: cv2.typing.MatLike | None, u: cv2.typing.MatLike | None, vt: cv2.typing.MatLike | None, flags: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
cv2.typing.Moments	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]				H	t_base2world	SVDecomp(src: UMat, w: UMat | None, u: UMat | None, vt: UMat | None, flags: int) -> tuple[UMat, UMat, UMat]	SVDecomp(src: UMat, w: UMat | None, u: UMat | None, vt: UMat | None, flags: int) -> tuple[UMat, UMat, UMat]
cv2.cuda.GpuMat	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]				w	projMatr2	Scharr(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Scharr(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
	tuple[int, _typing.Sequence[UMat]]				projMatrix	distCoeffs3	Scharr(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, scale: float, delta: float, borderType: int) -> UMat	Scharr(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, scale: float, delta: float, borderType: int) -> UMat
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				intersectingRegion	inputMask	Sobel(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Sobel(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
	AlignMTB				coeffs	bgdModel	Sobel(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat	Sobel(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat
	ThinPlateSplineShapeTransformer				contour	rvec2	absdiff(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	absdiff(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				pts1	weights1	absdiff(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	absdiff(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
	tuple[int, cv2.typing.MatLike]				A	templ	accumulate(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulate(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]				points1	b	accumulate(src: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulate(src: UMat, dst: UMat, mask: UMat | None) -> UMat
	MergeMertens				a	mtxQ	accumulateProduct(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateProduct(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	TonemapDrago				samples	upperb	accumulateProduct(src1: UMat, src2: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulateProduct(src1: UMat, src2: UMat, dst: UMat, mask: UMat | None) -> UMat
	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				img	B	accumulateSquare(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateSquare(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	TonemapReinhard				dx	idx	accumulateSquare(src: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulateSquare(src: UMat, dst: UMat, mask: UMat | None) -> UMat
	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]					cost	accumulateWeighted(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateWeighted(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, UMat]					perViewErrors	accumulateWeighted(src: UMat, dst: UMat, alpha: float, mask: UMat | None) -> UMat	accumulateWeighted(src: UMat, dst: UMat, alpha: float, mask: UMat | None) -> UMat
	tuple[int, _typing.Sequence[cv2.typing.MatLike]]					eulerAngles	adaptiveThreshold(src: cv2.typing.MatLike, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	adaptiveThreshold(src: cv2.typing.MatLike, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, UMat]					src3	adaptiveThreshold(src: UMat, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: UMat | None) -> UMat	adaptiveThreshold(src: UMat, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: UMat | None) -> UMat
	GeneralizedHoughGuil					line	add(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	add(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat]					convexityDefects	add(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat	add(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat
	tuple[_typing.Sequence[cv2.typing.Rect], _typing.Sequence[int]]					R12	addText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, nameFont: str, pointSize: int, color: cv2.typing.Scalar, weight: int, style: int, spacing: int) -> None	addText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, nameFont: str, pointSize: int, color: cv2.typing.Scalar, weight: int, style: int, spacing: int) -> None
	tuple[float, float, float, cv2.typing.Point2d, float]					lines	addWeighted(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, beta: float, gamma: float, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	addWeighted(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, beta: float, gamma: float, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					triangle	addWeighted(src1: UMat, alpha: float, src2: UMat, beta: float, gamma: float, dst: UMat | None, dtype: int) -> UMat	addWeighted(src1: UMat, alpha: float, src2: UMat, beta: float, gamma: float, dst: UMat | None, dtype: int) -> UMat
	GOpaqueDesc					fgdModel	applyColorMap(src: cv2.typing.MatLike, colormap: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	applyColorMap(src: cv2.typing.MatLike, colormap: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	str					rotMatrixX	applyColorMap(src: UMat, colormap: int, dst: UMat | None) -> UMat	applyColorMap(src: UMat, colormap: int, dst: UMat | None) -> UMat
	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat]]					transVect	applyColorMap(src: cv2.typing.MatLike, userColor: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	applyColorMap(src: cv2.typing.MatLike, userColor: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, cv2.typing.MatLike]					corners	applyColorMap(src: UMat, userColor: UMat, dst: UMat | None) -> UMat	applyColorMap(src: UMat, userColor: UMat, dst: UMat | None) -> UMat
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					img2	approxPolyDP(curve: cv2.typing.MatLike, epsilon: float, closed: bool, approxCurve: cv2.typing.MatLike | None) -> cv2.typing.MatLike	approxPolyDP(curve: cv2.typing.MatLike, epsilon: float, closed: bool, approxCurve: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					P3	approxPolyDP(curve: UMat, epsilon: float, closed: bool, approxCurve: UMat | None) -> UMat	approxPolyDP(curve: UMat, epsilon: float, closed: bool, approxCurve: UMat | None) -> UMat
	tuple[int, UMat, UMat, UMat]					tilted	approxPolyN(curve: cv2.typing.MatLike, nsides: int, approxCurve: cv2.typing.MatLike | None, epsilon_percentage: float, ensure_convex: bool) -> cv2.typing.MatLike	approxPolyN(curve: cv2.typing.MatLike, nsides: int, approxCurve: cv2.typing.MatLike | None, epsilon_percentage: float, ensure_convex: bool) -> cv2.typing.MatLike
	UMat					out	approxPolyN(curve: UMat, nsides: int, approxCurve: UMat | None, epsilon_percentage: float, ensure_convex: bool) -> UMat	approxPolyN(curve: UMat, nsides: int, approxCurve: UMat | None, epsilon_percentage: float, ensure_convex: bool) -> UMat
	tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					to	arcLength(curve: cv2.typing.MatLike, closed: bool) -> float	arcLength(curve: cv2.typing.MatLike, closed: bool) -> float
	cv2.typing.MatLike					hist	arcLength(curve: UMat, closed: bool) -> float	arcLength(curve: UMat, closed: bool) -> float
	MergeRobertson					rotMatrixZ	arrowedLine(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> cv2.typing.MatLike	arrowedLine(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					convexhull	arrowedLine(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> UMat	arrowedLine(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> UMat
	tuple[bool, UMat, UMat, UMat]					sharpness	batchDistance(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dtype: int, dist: cv2.typing.MatLike | None, nidx: cv2.typing.MatLike | None, normType: int, K: int, mask: cv2.typing.MatLike | None, update: int, crosscheck: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	batchDistance(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dtype: int, dist: cv2.typing.MatLike | None, nidx: cv2.typing.MatLike | None, normType: int, K: int, mask: cv2.typing.MatLike | None, update: int, crosscheck: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]					stddev	batchDistance(src1: UMat, src2: UMat, dtype: int, dist: UMat | None, nidx: UMat | None, normType: int, K: int, mask: UMat | None, update: int, crosscheck: bool) -> tuple[UMat, UMat]	batchDistance(src1: UMat, src2: UMat, dtype: int, dist: UMat | None, nidx: UMat | None, normType: int, K: int, mask: UMat | None, update: int, crosscheck: bool) -> tuple[UMat, UMat]
	float					covar	bilateralFilter(src: cv2.typing.MatLike, d: int, sigmaColor: float, sigmaSpace: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	bilateralFilter(src: cv2.typing.MatLike, d: int, sigmaColor: float, sigmaSpace: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
	tuple[float, float, UMat]					mean	bilateralFilter(src: UMat, d: int, sigmaColor: float, sigmaSpace: float, dst: UMat | None, borderType: int) -> UMat	bilateralFilter(src: UMat, d: int, sigmaColor: float, sigmaSpace: float, dst: UMat | None, borderType: int) -> UMat
	tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]					kernel	bitwise_and(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_and(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]					tvec1	bitwise_and(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_and(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	cv2.typing.Moments					eigenvectors	bitwise_not(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_not(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	CLAHE					stdDeviationsIntrinsics	bitwise_not(src: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_not(src: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	tuple[cv2.typing.Point2f, float]					_3dImage	bitwise_or(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_or(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, float, cv2.typing.Point, cv2.typing.Point]					newPoints2	bitwise_or(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_or(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					P1	bitwise_xor(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_xor(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	bool					dx	bitwise_xor(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_xor(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	tuple[int, UMat, UMat, UMat, UMat]					dr3dr1	blendLinear(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, weights1: cv2.typing.MatLike, weights2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	blendLinear(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, weights1: cv2.typing.MatLike, weights2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]					rotMatrixY	blendLinear(src1: UMat, src2: UMat, weights1: UMat, weights2: UMat, dst: UMat | None) -> UMat	blendLinear(src1: UMat, src2: UMat, weights1: UMat, weights2: UMat, dst: UMat | None) -> UMat
	TonemapMantiuk					outImage	blur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, borderType: int) -> cv2.typing.MatLike	blur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, borderType: int) -> cv2.typing.MatLike
	HausdorffDistanceExtractor					T13	blur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, borderType: int) -> UMat	blur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, borderType: int) -> UMat
	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					jacobian	borderInterpolate(p: int, len: int, borderType: int) -> int	borderInterpolate(p: int, len: int, borderType: int) -> int
	BackgroundSubtractorKNN					m	boundingRect(array: cv2.typing.MatLike) -> cv2.typing.Rect	boundingRect(array: cv2.typing.MatLike) -> cv2.typing.Rect
	tuple[UMat, UMat, UMat, UMat]					H1	boundingRect(array: UMat) -> cv2.typing.Rect	boundingRect(array: UMat) -> cv2.typing.Rect
	AlgorithmHint					result	boxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike	boxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike
	ShapeContextDistanceExtractor					bestLabels	boxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat	boxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat
	tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]					weights2	boxPoints(box: cv2.typing.RotatedRect, points: cv2.typing.MatLike | None) -> cv2.typing.MatLike	boxPoints(box: cv2.typing.RotatedRect, points: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.Size, int]					newObjPoints	boxPoints(box: cv2.typing.RotatedRect, points: UMat | None) -> UMat	boxPoints(box: cv2.typing.RotatedRect, points: UMat | None) -> UMat
	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]					centers	broadcast(src: cv2.typing.MatLike, shape: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	broadcast(src: cv2.typing.MatLike, shape: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[bool, cv2.typing.Point]					icovar	broadcast(src: UMat, shape: UMat, dst: UMat | None) -> UMat	broadcast(src: UMat, shape: UMat, dst: UMat | None) -> UMat
	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]					shape	buildOpticalFlowPyramid(img: cv2.typing.MatLike, winSize: cv2.typing.Size, maxLevel: int, pyramid: _typing.Sequence[cv2.typing.MatLike] | None, withDerivatives: bool, pyrBorder: int, derivBorder: int, tryReuseInputImage: bool) -> tuple[int, _typing.Sequence[cv2.typing.MatLike]]	calcCovarMatrix(samples: cv2.typing.MatLike, mean: cv2.typing.MatLike, flags: int, covar: cv2.typing.MatLike | None, ctype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					distCoeffs2	buildOpticalFlowPyramid(img: UMat, winSize: cv2.typing.Size, maxLevel: int, pyramid: _typing.Sequence[UMat] | None, withDerivatives: bool, pyrBorder: int, derivBorder: int, tryReuseInputImage: bool) -> tuple[int, _typing.Sequence[UMat]]	calcCovarMatrix(samples: UMat, mean: UMat, flags: int, covar: UMat | None, ctype: int) -> tuple[UMat, UMat]
	_typing.Sequence[cv2.typing.MatLike]					next	calcBackProject(images: _typing.Sequence[cv2.typing.MatLike], channels: _typing.Sequence[int], hist: cv2.typing.MatLike, ranges: _typing.Sequence[float], scale: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	calcOpticalFlowFarneback(prev: cv2.typing.MatLike, next: cv2.typing.MatLike, flow: cv2.typing.MatLike, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> cv2.typing.MatLike
	tuple[UMat, UMat, UMat]					stats	calcBackProject(images: _typing.Sequence[UMat], channels: _typing.Sequence[int], hist: UMat, ranges: _typing.Sequence[float], scale: float, dst: UMat | None) -> UMat	calcOpticalFlowFarneback(prev: UMat, next: UMat, flow: UMat, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> UMat
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]					cornersQuality	calcCovarMatrix(samples: cv2.typing.MatLike, mean: cv2.typing.MatLike, flags: int, covar: cv2.typing.MatLike | None, ctype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	calcOpticalFlowPyrLK(prevImg: cv2.typing.MatLike, nextImg: cv2.typing.MatLike, prevPts: cv2.typing.MatLike, nextPts: cv2.typing.MatLike, status: cv2.typing.MatLike | None, err: cv2.typing.MatLike | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[float, float, cv2.typing.MatLike]					cameraMatrix2	calcCovarMatrix(samples: UMat, mean: UMat, flags: int, covar: UMat | None, ctype: int) -> tuple[UMat, UMat]	calcOpticalFlowPyrLK(prevImg: UMat, nextImg: UMat, prevPts: UMat, nextPts: UMat, status: UMat | None, err: UMat | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[UMat, UMat, UMat]
	tuple[bool, cv2.typing.Point, cv2.typing.Point]					map1	calcHist(images: _typing.Sequence[cv2.typing.MatLike], channels: _typing.Sequence[int], mask: cv2.typing.MatLike | None, histSize: _typing.Sequence[int], ranges: _typing.Sequence[float], hist: cv2.typing.MatLike | None, accumulate: bool) -> cv2.typing.MatLike	calibrationMatrixValues(cameraMatrix: cv2.typing.MatLike, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]
	HistogramCostExtractor					T	calcHist(images: _typing.Sequence[UMat], channels: _typing.Sequence[int], mask: UMat | None, histSize: _typing.Sequence[int], ranges: _typing.Sequence[float], hist: UMat | None, accumulate: bool) -> UMat	calibrationMatrixValues(cameraMatrix: UMat, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]
	tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]					patch	calcOpticalFlowFarneback(prev: cv2.typing.MatLike, next: cv2.typing.MatLike, flow: cv2.typing.MatLike, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> cv2.typing.MatLike	cartToPolar(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[cv2.typing.MatLike, float]					markers	calcOpticalFlowFarneback(prev: UMat, next: UMat, flow: UMat, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> UMat	cartToPolar(x: UMat, y: UMat, magnitude: UMat | None, angle: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]					afterPoints	calcOpticalFlowPyrLK(prevImg: cv2.typing.MatLike, nextImg: cv2.typing.MatLike, prevPts: cv2.typing.MatLike, nextPts: cv2.typing.MatLike, status: cv2.typing.MatLike | None, err: cv2.typing.MatLike | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	checkChessboard(img: cv2.typing.MatLike, size: cv2.typing.Size) -> bool
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					stdDeviationsExtrinsics	calcOpticalFlowPyrLK(prevImg: UMat, nextImg: UMat, prevPts: UMat, nextPts: UMat, status: UMat | None, err: UMat | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[UMat, UMat, UMat]	checkChessboard(img: UMat, size: cv2.typing.Size) -> bool
	cv2.typing.Scalar					buf	calibrateCamera(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	checkHardwareSupport(feature: int) -> bool
	tuple[UMat, UMat]					z	calibrateCamera(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat]]	checkRange(a: cv2.typing.MatLike, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]
						edges	calibrateCameraExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, stdDeviationsIntrinsics: cv2.typing.MatLike | None, stdDeviationsExtrinsics: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	checkRange(a: UMat, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]
						points4D	calibrateCameraExtended(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, stdDeviationsIntrinsics: UMat | None, stdDeviationsExtrinsics: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat]	circle(img: cv2.typing.MatLike, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
						nextPts	calibrateCameraRO(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, newObjPoints: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	circle(img: UMat, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
						newPoints1	calibrateCameraRO(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, newObjPoints: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	clipLine(imgRect: cv2.typing.Rect, pt1: cv2.typing.Point, pt2: cv2.typing.Point) -> tuple[bool, cv2.typing.Point, cv2.typing.Point]
						mask	calibrateCameraROExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, newObjPoints: cv2.typing.MatLike | None, stdDeviationsIntrinsics: cv2.typing.MatLike | None, stdDeviationsExtrinsics: cv2.typing.MatLike | None, stdDeviationsObjPoints: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	colorChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, red_mul: float, green_mul: float, blue_mul: float) -> cv2.typing.MatLike
						cameraMatrix	calibrateCameraROExtended(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, newObjPoints: UMat | None, stdDeviationsIntrinsics: UMat | None, stdDeviationsExtrinsics: UMat | None, stdDeviationsObjPoints: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat, UMat, UMat]	colorChange(src: UMat, mask: UMat, dst: UMat | None, red_mul: float, green_mul: float, blue_mul: float) -> UMat
						x	calibrateHandEye(R_gripper2base: _typing.Sequence[cv2.typing.MatLike], t_gripper2base: _typing.Sequence[cv2.typing.MatLike], R_target2cam: _typing.Sequence[cv2.typing.MatLike], t_target2cam: _typing.Sequence[cv2.typing.MatLike], R_cam2gripper: cv2.typing.MatLike | None, t_cam2gripper: cv2.typing.MatLike | None, method: HandEyeCalibrationMethod) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	compare(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, cmpop: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						dr3dt2	calibrateHandEye(R_gripper2base: _typing.Sequence[UMat], t_gripper2base: _typing.Sequence[UMat], R_target2cam: _typing.Sequence[UMat], t_target2cam: _typing.Sequence[UMat], R_cam2gripper: UMat | None, t_cam2gripper: UMat | None, method: HandEyeCalibrationMethod) -> tuple[UMat, UMat]	compare(src1: UMat, src2: UMat, cmpop: int, dst: UMat | None) -> UMat
						dist	calibrateRobotWorldHandEye(R_world2cam: _typing.Sequence[cv2.typing.MatLike], t_world2cam: _typing.Sequence[cv2.typing.MatLike], R_base2gripper: _typing.Sequence[cv2.typing.MatLike], t_base2gripper: _typing.Sequence[cv2.typing.MatLike], R_base2world: cv2.typing.MatLike | None, t_base2world: cv2.typing.MatLike | None, R_gripper2cam: cv2.typing.MatLike | None, t_gripper2cam: cv2.typing.MatLike | None, method: RobotWorldHandEyeCalibrationMethod) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	compareHist(H1: cv2.typing.MatLike, H2: cv2.typing.MatLike, method: int) -> float
						signature2	calibrateRobotWorldHandEye(R_world2cam: _typing.Sequence[UMat], t_world2cam: _typing.Sequence[UMat], R_base2gripper: _typing.Sequence[UMat], t_base2gripper: _typing.Sequence[UMat], R_base2world: UMat | None, t_base2world: UMat | None, R_gripper2cam: UMat | None, t_gripper2cam: UMat | None, method: RobotWorldHandEyeCalibrationMethod) -> tuple[UMat, UMat, UMat, UMat]	compareHist(H1: UMat, H2: UMat, method: int) -> float
						distCoeffs	calibrationMatrixValues(cameraMatrix: cv2.typing.MatLike, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]	completeSymm(m: cv2.typing.MatLike, lowerToUpper: bool) -> cv2.typing.MatLike
						t_gripper2cam	calibrationMatrixValues(cameraMatrix: UMat, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]	completeSymm(m: UMat, lowerToUpper: bool) -> UMat
						t	cartToPolar(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	composeRT(rvec1: cv2.typing.MatLike, tvec1: cv2.typing.MatLike, rvec2: cv2.typing.MatLike, tvec2: cv2.typing.MatLike, rvec3: cv2.typing.MatLike | None, tvec3: cv2.typing.MatLike | None, dr3dr1: cv2.typing.MatLike | None, dr3dt1: cv2.typing.MatLike | None, dr3dr2: cv2.typing.MatLike | None, dr3dt2: cv2.typing.MatLike | None, dt3dr1: cv2.typing.MatLike | None, dt3dt1: cv2.typing.MatLike | None, dt3dr2: cv2.typing.MatLike | None, dt3dt2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						Q	cartToPolar(x: UMat, y: UMat, magnitude: UMat | None, angle: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]	composeRT(rvec1: UMat, tvec1: UMat, rvec2: UMat, tvec2: UMat, rvec3: UMat | None, tvec3: UMat | None, dr3dr1: UMat | None, dr3dt1: UMat | None, dr3dr2: UMat | None, dr3dt2: UMat | None, dt3dr1: UMat | None, dt3dt1: UMat | None, dt3dr2: UMat | None, dt3dt2: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]
						kernelY	checkChessboard(img: cv2.typing.MatLike, size: cv2.typing.Size) -> bool	computeCorrespondEpilines(points: cv2.typing.MatLike, whichImage: int, F: cv2.typing.MatLike, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						w	checkChessboard(img: UMat, size: cv2.typing.Size) -> bool	computeCorrespondEpilines(points: UMat, whichImage: int, F: UMat, lines: UMat | None) -> UMat
						blend	checkHardwareSupport(feature: int) -> bool	computeECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, inputMask: cv2.typing.MatLike | None) -> float
						R3	checkRange(a: cv2.typing.MatLike, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]	computeECC(templateImage: UMat, inputImage: UMat, inputMask: UMat | None) -> float
						y	checkRange(a: UMat, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]	connectedComponents(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike]
						projPoints2	circle(img: cv2.typing.MatLike, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	connectedComponents(image: UMat, labels: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat]
						circles	circle(img: UMat, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	connectedComponentsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
						lowerb	clipLine(imgRect: cv2.typing.Rect, pt1: cv2.typing.Point, pt2: cv2.typing.Point) -> tuple[bool, cv2.typing.Point, cv2.typing.Point]	connectedComponentsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None) -> tuple[int, UMat]
						map2	colorChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, red_mul: float, green_mul: float, blue_mul: float) -> cv2.typing.MatLike	connectedComponentsWithStats(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						H2	colorChange(src: UMat, mask: UMat, dst: UMat | None, red_mul: float, green_mul: float, blue_mul: float) -> UMat	connectedComponentsWithStats(image: UMat, labels: UMat | None, stats: UMat | None, centroids: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat, UMat, UMat]
						cameraMatrix3	compare(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, cmpop: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	connectedComponentsWithStatsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						dy	compare(src1: UMat, src2: UMat, cmpop: int, dst: UMat | None) -> UMat	connectedComponentsWithStatsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None, stats: UMat | None, centroids: UMat | None) -> tuple[int, UMat, UMat, UMat]
						ky	compareHist(H1: cv2.typing.MatLike, H2: cv2.typing.MatLike, method: int) -> float	contourArea(contour: cv2.typing.MatLike, oriented: bool) -> float
						imagePoints	compareHist(H1: UMat, H2: UMat, method: int) -> float	contourArea(contour: UMat, oriented: bool) -> float
						reprojectionError	completeSymm(m: cv2.typing.MatLike, lowerToUpper: bool) -> cv2.typing.MatLike	convertFp16(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						cameraMatrix1	completeSymm(m: UMat, lowerToUpper: bool) -> UMat	convertFp16(src: UMat, dst: UMat | None) -> UMat
						grayscale	composeRT(rvec1: cv2.typing.MatLike, tvec1: cv2.typing.MatLike, rvec2: cv2.typing.MatLike, tvec2: cv2.typing.MatLike, rvec3: cv2.typing.MatLike | None, tvec3: cv2.typing.MatLike | None, dr3dr1: cv2.typing.MatLike | None, dr3dt1: cv2.typing.MatLike | None, dr3dr2: cv2.typing.MatLike | None, dr3dt2: cv2.typing.MatLike | None, dt3dr1: cv2.typing.MatLike | None, dt3dt1: cv2.typing.MatLike | None, dt3dr2: cv2.typing.MatLike | None, dt3dt2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	convertMaps(map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, dstmap1type: int, dstmap1: cv2.typing.MatLike | None, dstmap2: cv2.typing.MatLike | None, nninterpolation: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
						nidx	composeRT(rvec1: UMat, tvec1: UMat, rvec2: UMat, tvec2: UMat, rvec3: UMat | None, tvec3: UMat | None, dr3dr1: UMat | None, dr3dt1: UMat | None, dr3dr2: UMat | None, dr3dt2: UMat | None, dt3dr1: UMat | None, dt3dt1: UMat | None, dt3dr2: UMat | None, dt3dt2: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	convertMaps(map1: UMat, map2: UMat, dstmap1type: int, dstmap1: UMat | None, dstmap2: UMat | None, nninterpolation: bool) -> tuple[UMat, UMat]
						rotMatrix	computeCorrespondEpilines(points: cv2.typing.MatLike, whichImage: int, F: cv2.typing.MatLike, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike	convertPointsFromHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						prevPts	computeCorrespondEpilines(points: UMat, whichImage: int, F: UMat, lines: UMat | None) -> UMat	convertPointsFromHomogeneous(src: UMat, dst: UMat | None) -> UMat
						tvec2	computeECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, inputMask: cv2.typing.MatLike | None) -> float	convertPointsToHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						R	computeECC(templateImage: UMat, inputImage: UMat, inputMask: UMat | None) -> float	convertPointsToHomogeneous(src: UMat, dst: UMat | None) -> UMat
						inliers	connectedComponents(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike]	convertScaleAbs(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike
						newCameraMatrix	connectedComponents(image: UMat, labels: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat]	convertScaleAbs(src: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat
						inpaintMask	connectedComponentsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	convexHull(points: cv2.typing.MatLike, hull: cv2.typing.MatLike | None, clockwise: bool, returnPoints: bool) -> cv2.typing.MatLike
						Qy	connectedComponentsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None) -> tuple[int, UMat]	convexHull(points: UMat, hull: UMat | None, clockwise: bool, returnPoints: bool) -> UMat
						dABdA	connectedComponentsWithStats(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	convexityDefects(contour: cv2.typing.MatLike, convexhull: cv2.typing.MatLike, convexityDefects: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						high	connectedComponentsWithStats(image: UMat, labels: UMat | None, stats: UMat | None, centroids: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat, UMat, UMat]	convexityDefects(contour: UMat, convexhull: UMat, convexityDefects: UMat | None) -> UMat
						mtxR	connectedComponentsWithStatsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	copyMakeBorder(src: cv2.typing.MatLike, top: int, bottom: int, left: int, right: int, borderType: int, dst: cv2.typing.MatLike | None, value: cv2.typing.Scalar) -> cv2.typing.MatLike
						points2	connectedComponentsWithStatsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None, stats: UMat | None, centroids: UMat | None) -> tuple[int, UMat, UMat, UMat]	copyMakeBorder(src: UMat, top: int, bottom: int, left: int, right: int, borderType: int, dst: UMat | None, value: cv2.typing.Scalar) -> UMat
						rvec	contourArea(contour: cv2.typing.MatLike, oriented: bool) -> float	copyTo(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						Qx	contourArea(contour: UMat, oriented: bool) -> float	copyTo(src: UMat, mask: UMat, dst: UMat | None) -> UMat
						dt3dt1	convertFp16(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerEigenValsAndVecs(src: cv2.typing.MatLike, blockSize: int, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
						Constr	convertFp16(src: UMat, dst: UMat | None) -> UMat	cornerEigenValsAndVecs(src: UMat, blockSize: int, ksize: int, dst: UMat | None, borderType: int) -> UMat
						dstmap2	convertMaps(map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, dstmap1type: int, dstmap1: cv2.typing.MatLike | None, dstmap2: cv2.typing.MatLike | None, nninterpolation: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	cornerHarris(src: cv2.typing.MatLike, blockSize: int, ksize: int, k: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
						color_boost	convertMaps(map1: UMat, map2: UMat, dstmap1type: int, dstmap1: UMat | None, dstmap2: UMat | None, nninterpolation: bool) -> tuple[UMat, UMat]	cornerHarris(src: UMat, blockSize: int, ksize: int, k: float, dst: UMat | None, borderType: int) -> UMat
						P2	convertPointsFromHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerMinEigenVal(src: cv2.typing.MatLike, blockSize: int, dst: cv2.typing.MatLike | None, ksize: int, borderType: int) -> cv2.typing.MatLike
						approxCurve	convertPointsFromHomogeneous(src: UMat, dst: UMat | None) -> UMat	cornerMinEigenVal(src: UMat, blockSize: int, dst: UMat | None, ksize: int, borderType: int) -> UMat
						outImg	convertPointsToHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerSubPix(image: cv2.typing.MatLike, corners: cv2.typing.MatLike, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> cv2.typing.MatLike
						low	convertPointsToHomogeneous(src: UMat, dst: UMat | None) -> UMat	cornerSubPix(image: UMat, corners: UMat, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> UMat
						T12	convertScaleAbs(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike	correctMatches(F: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, newPoints1: cv2.typing.MatLike | None, newPoints2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
						pointsMask	convertScaleAbs(src: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat	correctMatches(F: UMat, points1: UMat, points2: UMat, newPoints1: UMat | None, newPoints2: UMat | None) -> tuple[UMat, UMat]
						stdDeviationsObjPoints	convexHull(points: cv2.typing.MatLike, hull: cv2.typing.MatLike | None, clockwise: bool, returnPoints: bool) -> cv2.typing.MatLike	countNonZero(src: cv2.typing.MatLike) -> int
						E	convexHull(points: UMat, hull: UMat | None, clockwise: bool, returnPoints: bool) -> UMat	countNonZero(src: UMat) -> int
						vt	convexityDefects(contour: cv2.typing.MatLike, convexhull: cv2.typing.MatLike, convexityDefects: cv2.typing.MatLike | None) -> cv2.typing.MatLike	createAffineTransformer(fullAffine: bool) -> AffineTransformer
						tvec3	convexityDefects(contour: UMat, convexhull: UMat, convexityDefects: UMat | None) -> UMat	createAlignMTB(max_bits: int, exclude_range: int, cut: bool) -> AlignMTB
						possibleSolutions	copyMakeBorder(src: cv2.typing.MatLike, top: int, bottom: int, left: int, right: int, borderType: int, dst: cv2.typing.MatLike | None, value: cv2.typing.Scalar) -> cv2.typing.MatLike	createBackgroundSubtractorKNN(history: int, dist2Threshold: float, detectShadows: bool) -> BackgroundSubtractorKNN
						pt2	copyMakeBorder(src: UMat, top: int, bottom: int, left: int, right: int, borderType: int, dst: UMat | None, value: cv2.typing.Scalar) -> UMat	createBackgroundSubtractorMOG2(history: int, varThreshold: float, detectShadows: bool) -> BackgroundSubtractorMOG2
						c	copyTo(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	createCLAHE(clipLimit: float, tileGridSize: cv2.typing.Size) -> CLAHE
						K	copyTo(src: UMat, mask: UMat, dst: UMat | None) -> UMat	createCalibrateDebevec(samples: int, lambda_: float, random: bool) -> CalibrateDebevec
						distCoeffs1	cornerEigenValsAndVecs(src: cv2.typing.MatLike, blockSize: int, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	createCalibrateRobertson(max_iter: int, threshold: float) -> CalibrateRobertson
						angle	cornerEigenValsAndVecs(src: UMat, blockSize: int, ksize: int, dst: UMat | None, borderType: int) -> UMat	createGeneralizedHoughBallard() -> GeneralizedHoughBallard
						sum	cornerHarris(src: cv2.typing.MatLike, blockSize: int, ksize: int, k: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	createGeneralizedHoughGuil() -> GeneralizedHoughGuil
						sqsum	cornerHarris(src: UMat, blockSize: int, ksize: int, k: float, dst: UMat | None, borderType: int) -> UMat	createHanningWindow(winSize: cv2.typing.Size, type: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						eigenvalues	cornerMinEigenVal(src: cv2.typing.MatLike, blockSize: int, dst: cv2.typing.MatLike | None, ksize: int, borderType: int) -> cv2.typing.MatLike	createHanningWindow(winSize: cv2.typing.Size, type: int, dst: UMat | None) -> UMat
						tvec	cornerMinEigenVal(src: UMat, blockSize: int, dst: UMat | None, ksize: int, borderType: int) -> UMat	createHausdorffDistanceExtractor(distanceFlag: int, rankProp: float) -> HausdorffDistanceExtractor
						points1	cornerSubPix(image: cv2.typing.MatLike, corners: cv2.typing.MatLike, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> cv2.typing.MatLike	createLineSegmentDetector(refine: int, scale: float, sigma_scale: float, quant: float, ang_th: float, log_eps: float, density_th: float, n_bins: int) -> LineSegmentDetector
						dt3dr2	cornerSubPix(image: UMat, corners: UMat, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> UMat	createMergeDebevec() -> MergeDebevec
						R2	correctMatches(F: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, newPoints1: cv2.typing.MatLike | None, newPoints2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	createMergeMertens(contrast_weight: float, saturation_weight: float, exposure_weight: float) -> MergeMertens
						t_cam2gripper	correctMatches(F: UMat, points1: UMat, points2: UMat, newPoints1: UMat | None, newPoints2: UMat | None) -> tuple[UMat, UMat]	createMergeRobertson() -> MergeRobertson
						rvec3	countNonZero(src: cv2.typing.MatLike) -> int	createTonemap(gamma: float) -> Tonemap
							countNonZero(src: UMat) -> int	createTonemapDrago(gamma: float, saturation: float, bias: float) -> TonemapDrago
							createAffineTransformer(fullAffine: bool) -> AffineTransformer	createTonemapMantiuk(gamma: float, scale: float, saturation: float) -> TonemapMantiuk
							createAlignMTB(max_bits: int, exclude_range: int, cut: bool) -> AlignMTB	createTonemapReinhard(gamma: float, intensity: float, light_adapt: float, color_adapt: float) -> TonemapReinhard
							createBackgroundSubtractorKNN(history: int, dist2Threshold: float, detectShadows: bool) -> BackgroundSubtractorKNN	cubeRoot(val: float) -> float
							createBackgroundSubtractorMOG2(history: int, varThreshold: float, detectShadows: bool) -> BackgroundSubtractorMOG2	currentUIFramework() -> str
							createCLAHE(clipLimit: float, tileGridSize: cv2.typing.Size) -> CLAHE	cvtColor(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int, hint: AlgorithmHint) -> cv2.typing.MatLike
							createCalibrateDebevec(samples: int, lambda_: float, random: bool) -> CalibrateDebevec	cvtColor(src: UMat, code: int, dst: UMat | None, dstCn: int, hint: AlgorithmHint) -> UMat
							createCalibrateRobertson(max_iter: int, threshold: float) -> CalibrateRobertson	cvtColorTwoPlane(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, hint: AlgorithmHint) -> cv2.typing.MatLike
							createChiHistogramCostExtractor(nDummies: int, defaultCost: float) -> HistogramCostExtractor	cvtColorTwoPlane(src1: UMat, src2: UMat, code: int, dst: UMat | None, hint: AlgorithmHint) -> UMat
							createEMDHistogramCostExtractor(flag: int, nDummies: int, defaultCost: float) -> HistogramCostExtractor	dct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							createEMDL1HistogramCostExtractor(nDummies: int, defaultCost: float) -> HistogramCostExtractor	dct(src: UMat, dst: UMat | None, flags: int) -> UMat
							createGeneralizedHoughBallard() -> GeneralizedHoughBallard	decolor(src: cv2.typing.MatLike, grayscale: cv2.typing.MatLike | None, color_boost: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							createGeneralizedHoughGuil() -> GeneralizedHoughGuil	decolor(src: UMat, grayscale: UMat | None, color_boost: UMat | None) -> tuple[UMat, UMat]
							createHanningWindow(winSize: cv2.typing.Size, type: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	decomposeEssentialMat(E: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							createHanningWindow(winSize: cv2.typing.Size, type: int, dst: UMat | None) -> UMat	decomposeEssentialMat(E: UMat, R1: UMat | None, R2: UMat | None, t: UMat | None) -> tuple[UMat, UMat, UMat]
							createHausdorffDistanceExtractor(distanceFlag: int, rankProp: float) -> HausdorffDistanceExtractor	decomposeProjectionMatrix(projMatrix: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike | None, rotMatrix: cv2.typing.MatLike | None, transVect: cv2.typing.MatLike | None, rotMatrixX: cv2.typing.MatLike | None, rotMatrixY: cv2.typing.MatLike | None, rotMatrixZ: cv2.typing.MatLike | None, eulerAngles: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							createLineSegmentDetector(refine: int, scale: float, sigma_scale: float, quant: float, ang_th: float, log_eps: float, density_th: float, n_bins: int) -> LineSegmentDetector	decomposeProjectionMatrix(projMatrix: UMat, cameraMatrix: UMat | None, rotMatrix: UMat | None, transVect: UMat | None, rotMatrixX: UMat | None, rotMatrixY: UMat | None, rotMatrixZ: UMat | None, eulerAngles: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]
							createMergeDebevec() -> MergeDebevec	demosaicing(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int) -> cv2.typing.MatLike
							createMergeMertens(contrast_weight: float, saturation_weight: float, exposure_weight: float) -> MergeMertens	demosaicing(src: UMat, code: int, dst: UMat | None, dstCn: int) -> UMat
							createMergeRobertson() -> MergeRobertson	destroyAllWindows() -> None
							createNormHistogramCostExtractor(flag: int, nDummies: int, defaultCost: float) -> HistogramCostExtractor	destroyWindow(winname: str) -> None
							createShapeContextDistanceExtractor(nAngularBins: int, nRadialBins: int, innerRadius: float, outerRadius: float, iterations: int, comparer: HistogramCostExtractor, transformer: ShapeTransformer) -> ShapeContextDistanceExtractor	detailEnhance(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							createThinPlateSplineShapeTransformer(regularizationParameter: float) -> ThinPlateSplineShapeTransformer	detailEnhance(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat
							createTonemap(gamma: float) -> Tonemap	determinant(mtx: cv2.typing.MatLike) -> float
							createTonemapDrago(gamma: float, saturation: float, bias: float) -> TonemapDrago	determinant(mtx: UMat) -> float
							createTonemapMantiuk(gamma: float, scale: float, saturation: float) -> TonemapMantiuk	dft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike
							createTonemapReinhard(gamma: float, intensity: float, light_adapt: float, color_adapt: float) -> TonemapReinhard	dft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat
							cubeRoot(val: float) -> float	dilate(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							currentUIFramework() -> str	dilate(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							cvtColor(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int, hint: AlgorithmHint) -> cv2.typing.MatLike	displayOverlay(winname: str, text: str, delayms: int) -> None
							cvtColor(src: UMat, code: int, dst: UMat | None, dstCn: int, hint: AlgorithmHint) -> UMat	displayStatusBar(winname: str, text: str, delayms: int) -> None
							cvtColorTwoPlane(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, hint: AlgorithmHint) -> cv2.typing.MatLike	distanceTransform(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, dstType: int) -> cv2.typing.MatLike
							cvtColorTwoPlane(src1: UMat, src2: UMat, code: int, dst: UMat | None, hint: AlgorithmHint) -> UMat	distanceTransform(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, dstType: int) -> UMat
							dct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	distanceTransformWithLabels(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, labels: cv2.typing.MatLike | None, labelType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							dct(src: UMat, dst: UMat | None, flags: int) -> UMat	distanceTransformWithLabels(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, labels: UMat | None, labelType: int) -> tuple[UMat, UMat]
							decolor(src: cv2.typing.MatLike, grayscale: cv2.typing.MatLike | None, color_boost: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	divSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike
							decolor(src: UMat, grayscale: UMat | None, color_boost: UMat | None) -> tuple[UMat, UMat]	divSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat
							decomposeEssentialMat(E: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	divide(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							decomposeEssentialMat(E: UMat, R1: UMat | None, R2: UMat | None, t: UMat | None) -> tuple[UMat, UMat, UMat]	divide(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat
							decomposeHomographyMat(H: cv2.typing.MatLike, K: cv2.typing.MatLike, rotations: _typing.Sequence[cv2.typing.MatLike] | None, translations: _typing.Sequence[cv2.typing.MatLike] | None, normals: _typing.Sequence[cv2.typing.MatLike] | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	divide(scale: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							decomposeHomographyMat(H: UMat, K: UMat, rotations: _typing.Sequence[UMat] | None, translations: _typing.Sequence[UMat] | None, normals: _typing.Sequence[UMat] | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], _typing.Sequence[UMat]]	divide(scale: float, src2: UMat, dst: UMat | None, dtype: int) -> UMat
							decomposeProjectionMatrix(projMatrix: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike | None, rotMatrix: cv2.typing.MatLike | None, transVect: cv2.typing.MatLike | None, rotMatrixX: cv2.typing.MatLike | None, rotMatrixY: cv2.typing.MatLike | None, rotMatrixZ: cv2.typing.MatLike | None, eulerAngles: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	drawChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, patternWasFound: bool) -> cv2.typing.MatLike
							decomposeProjectionMatrix(projMatrix: UMat, cameraMatrix: UMat | None, rotMatrix: UMat | None, transVect: UMat | None, rotMatrixX: UMat | None, rotMatrixY: UMat | None, rotMatrixZ: UMat | None, eulerAngles: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]	drawChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat, patternWasFound: bool) -> UMat
							demosaicing(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int) -> cv2.typing.MatLike	drawFrameAxes(image: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, length: float, thickness: int) -> cv2.typing.MatLike
							demosaicing(src: UMat, code: int, dst: UMat | None, dstCn: int) -> UMat	drawFrameAxes(image: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, length: float, thickness: int) -> UMat
							denoise_TVL1(observations: _typing.Sequence[cv2.typing.MatLike], result: cv2.typing.MatLike, lambda_: float, niters: int) -> None	drawMarker(img: cv2.typing.MatLike, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> cv2.typing.MatLike
							destroyAllWindows() -> None	drawMarker(img: UMat, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> UMat
							destroyWindow(winname: str) -> None	edgePreservingFilter(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							detailEnhance(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	edgePreservingFilter(src: UMat, dst: UMat | None, flags: int, sigma_s: float, sigma_r: float) -> UMat
							detailEnhance(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat	eigen(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							determinant(mtx: cv2.typing.MatLike) -> float	eigen(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[bool, UMat, UMat]
							determinant(mtx: UMat) -> float	eigenNonSymmetric(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							dft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike	eigenNonSymmetric(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[UMat, UMat]
							dft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat	ellipse(img: cv2.typing.MatLike, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							dilate(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	ellipse(img: UMat, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							dilate(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	ellipse(img: cv2.typing.MatLike, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> cv2.typing.MatLike
							displayOverlay(winname: str, text: str, delayms: int) -> None	ellipse(img: UMat, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> UMat
							displayStatusBar(winname: str, text: str, delayms: int) -> None	empty_array_desc() -> GArrayDesc
							distanceTransform(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, dstType: int) -> cv2.typing.MatLike	empty_gopaque_desc() -> GOpaqueDesc
							distanceTransform(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, dstType: int) -> UMat	empty_scalar_desc() -> GScalarDesc
							distanceTransformWithLabels(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, labels: cv2.typing.MatLike | None, labelType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	equalizeHist(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							distanceTransformWithLabels(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, labels: UMat | None, labelType: int) -> tuple[UMat, UMat]	equalizeHist(src: UMat, dst: UMat | None) -> UMat
							divSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike	erode(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							divSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat	erode(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							divide(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	estimateAffine2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							divide(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat	estimateAffine2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]
							divide(scale: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]
							divide(scale: float, src2: UMat, dst: UMat | None, dtype: int) -> UMat	estimateAffine3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]
							drawChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, patternWasFound: bool) -> cv2.typing.MatLike	estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]
							drawChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat, patternWasFound: bool) -> UMat	estimateAffine3D(src: UMat, dst: UMat, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]
							drawContours(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike], contourIdx: int, color: cv2.typing.Scalar, thickness: int, lineType: int, hierarchy: cv2.typing.MatLike | None, maxLevel: int, offset: cv2.typing.Point) -> cv2.typing.MatLike	estimateAffinePartial2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							drawContours(image: UMat, contours: _typing.Sequence[UMat], contourIdx: int, color: cv2.typing.Scalar, thickness: int, lineType: int, hierarchy: UMat | None, maxLevel: int, offset: cv2.typing.Point) -> UMat	estimateAffinePartial2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]
							drawFrameAxes(image: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, length: float, thickness: int) -> cv2.typing.MatLike	estimateChessboardSharpness(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, rise_distance: float, vertical: bool, sharpness: cv2.typing.MatLike | None) -> tuple[cv2.typing.Scalar, cv2.typing.MatLike]
							drawFrameAxes(image: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, length: float, thickness: int) -> UMat	estimateChessboardSharpness(image: UMat, patternSize: cv2.typing.Size, corners: UMat, rise_distance: float, vertical: bool, sharpness: UMat | None) -> tuple[cv2.typing.Scalar, UMat]
							drawKeypoints(image: cv2.typing.MatLike, keypoints: _typing.Sequence[KeyPoint], outImage: cv2.typing.MatLike, color: cv2.typing.Scalar, flags: DrawMatchesFlags) -> cv2.typing.MatLike	estimateTranslation3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]
							drawKeypoints(image: UMat, keypoints: _typing.Sequence[KeyPoint], outImage: UMat, color: cv2.typing.Scalar, flags: DrawMatchesFlags) -> UMat	estimateTranslation3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]
							drawMarker(img: cv2.typing.MatLike, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> cv2.typing.MatLike	exp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							drawMarker(img: UMat, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> UMat	exp(src: UMat, dst: UMat | None) -> UMat
							drawMatches(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: cv2.typing.MatLike, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> cv2.typing.MatLike	extractChannel(src: cv2.typing.MatLike, coi: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							drawMatches(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: UMat, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> UMat	extractChannel(src: UMat, coi: int, dst: UMat | None) -> UMat
							drawMatches(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: cv2.typing.MatLike, matchesThickness: int, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> cv2.typing.MatLike	fastAtan2(y: float, x: float) -> float
							drawMatches(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: UMat, matchesThickness: int, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> UMat	fastNlMeansDenoising(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike
							drawMatchesKnn(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[_typing.Sequence[DMatch]], outImg: cv2.typing.MatLike, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[_typing.Sequence[str]], flags: DrawMatchesFlags) -> cv2.typing.MatLike	fastNlMeansDenoising(src: UMat, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat
							drawMatchesKnn(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[_typing.Sequence[DMatch]], outImg: UMat, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[_typing.Sequence[str]], flags: DrawMatchesFlags) -> UMat	fastNlMeansDenoisingColored(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike
							edgePreservingFilter(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	fastNlMeansDenoisingColored(src: UMat, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat
							edgePreservingFilter(src: UMat, dst: UMat | None, flags: int, sigma_s: float, sigma_r: float) -> UMat	fillConvexPoly(img: cv2.typing.MatLike, points: cv2.typing.MatLike, color: cv2.typing.Scalar, lineType: int, shift: int) -> cv2.typing.MatLike
							eigen(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	fillConvexPoly(img: UMat, points: UMat, color: cv2.typing.Scalar, lineType: int, shift: int) -> UMat
							eigen(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[bool, UMat, UMat]	filter2D(src: cv2.typing.MatLike, ddepth: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike
							eigenNonSymmetric(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	filter2D(src: UMat, ddepth: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat
							eigenNonSymmetric(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[UMat, UMat]	filterSpeckles(img: cv2.typing.MatLike, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							ellipse(img: cv2.typing.MatLike, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	filterSpeckles(img: UMat, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: UMat | None) -> tuple[UMat, UMat]
							ellipse(img: UMat, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	find4QuadCornerSubpix(img: cv2.typing.MatLike, corners: cv2.typing.MatLike, region_size: cv2.typing.Size) -> tuple[bool, cv2.typing.MatLike]
							ellipse(img: cv2.typing.MatLike, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> cv2.typing.MatLike	find4QuadCornerSubpix(img: UMat, corners: UMat, region_size: cv2.typing.Size) -> tuple[bool, UMat]
							ellipse(img: UMat, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> UMat	findChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							ellipse2Poly(center: cv2.typing.Point, axes: cv2.typing.Size, angle: int, arcStart: int, arcEnd: int, delta: int) -> _typing.Sequence[cv2.typing.Point]	findChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]
							empty_array_desc() -> GArrayDesc	findChessboardCornersSB(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							empty_gopaque_desc() -> GOpaqueDesc	findChessboardCornersSB(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]
							empty_scalar_desc() -> GScalarDesc	findChessboardCornersSBWithMeta(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, corners: cv2.typing.MatLike | None, meta: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							equalizeHist(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	findChessboardCornersSBWithMeta(image: UMat, patternSize: cv2.typing.Size, flags: int, corners: UMat | None, meta: UMat | None) -> tuple[bool, UMat, UMat]
							equalizeHist(src: UMat, dst: UMat | None) -> UMat	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							erode(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	findEssentialMat(points1: UMat, points2: UMat, cameraMatrix: UMat, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							erode(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							estimateAffine2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	findEssentialMat(points1: UMat, points2: UMat, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							estimateAffine2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							estimateAffine2D(pts1: cv2.typing.MatLike, pts2: cv2.typing.MatLike, params: UsacParams, inliers: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							estimateAffine2D(pts1: UMat, pts2: UMat, params: UsacParams, inliers: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]	findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							estimateAffine3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]	findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]	findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							estimateAffine3D(src: UMat, dst: UMat, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]	findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, mask: cv2.typing.MatLike | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							estimateAffinePartial2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	findHomography(srcPoints: UMat, dstPoints: UMat, method: int, ransacReprojThreshold: float, mask: UMat | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, UMat]
							estimateAffinePartial2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]	findNonZero(src: cv2.typing.MatLike, idx: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							estimateChessboardSharpness(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, rise_distance: float, vertical: bool, sharpness: cv2.typing.MatLike | None) -> tuple[cv2.typing.Scalar, cv2.typing.MatLike]	findNonZero(src: UMat, idx: UMat | None) -> UMat
							estimateChessboardSharpness(image: UMat, patternSize: cv2.typing.Size, corners: UMat, rise_distance: float, vertical: bool, sharpness: UMat | None) -> tuple[cv2.typing.Scalar, UMat]	findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike, gaussFiltSize: int) -> tuple[float, cv2.typing.MatLike]
							estimateTranslation3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]	findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat, gaussFiltSize: int) -> tuple[float, UMat]
							estimateTranslation3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]	findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							exp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat | None) -> tuple[float, UMat]
							exp(src: UMat, dst: UMat | None) -> UMat	fitEllipse(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							extractChannel(src: cv2.typing.MatLike, coi: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	fitEllipse(points: UMat) -> cv2.typing.RotatedRect
							extractChannel(src: UMat, coi: int, dst: UMat | None) -> UMat	fitEllipseAMS(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							fastAtan2(y: float, x: float) -> float	fitEllipseAMS(points: UMat) -> cv2.typing.RotatedRect
							fastNlMeansDenoising(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	fitEllipseDirect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							fastNlMeansDenoising(src: UMat, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat	fitEllipseDirect(points: UMat) -> cv2.typing.RotatedRect
							fastNlMeansDenoising(src: cv2.typing.MatLike, h: _typing.Sequence[float], dst: cv2.typing.MatLike | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> cv2.typing.MatLike	fitLine(points: cv2.typing.MatLike, distType: int, param: float, reps: float, aeps: float, line: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							fastNlMeansDenoising(src: UMat, h: _typing.Sequence[float], dst: UMat | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> UMat	fitLine(points: UMat, distType: int, param: float, reps: float, aeps: float, line: UMat | None) -> UMat
							fastNlMeansDenoisingColored(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	flip(src: cv2.typing.MatLike, flipCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							fastNlMeansDenoisingColored(src: UMat, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat	flip(src: UMat, flipCode: int, dst: UMat | None) -> UMat
							fastNlMeansDenoisingColoredMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	flipND(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							fastNlMeansDenoisingColoredMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat	flipND(src: UMat, axis: int, dst: UMat | None) -> UMat
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	floodFill(image: cv2.typing.MatLike, mask: cv2.typing.MatLike | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat	floodFill(image: UMat, mask: UMat | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, UMat, UMat, cv2.typing.Rect]
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, h: _typing.Sequence[float], dst: cv2.typing.MatLike | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> cv2.typing.MatLike	gemm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, alpha: float, src3: cv2.typing.MatLike, beta: float, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, h: _typing.Sequence[float], dst: UMat | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> UMat	gemm(src1: UMat, src2: UMat, alpha: float, src3: UMat, beta: float, dst: UMat | None, flags: int) -> UMat
							fillConvexPoly(img: cv2.typing.MatLike, points: cv2.typing.MatLike, color: cv2.typing.Scalar, lineType: int, shift: int) -> cv2.typing.MatLike	getAffineTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike) -> cv2.typing.MatLike
							fillConvexPoly(img: UMat, points: UMat, color: cv2.typing.Scalar, lineType: int, shift: int) -> UMat	getAffineTransform(src: UMat, dst: UMat) -> cv2.typing.MatLike
							fillPoly(img: cv2.typing.MatLike, pts: _typing.Sequence[cv2.typing.MatLike], color: cv2.typing.Scalar, lineType: int, shift: int, offset: cv2.typing.Point) -> cv2.typing.MatLike	getBuildInformation() -> str
							fillPoly(img: UMat, pts: _typing.Sequence[UMat], color: cv2.typing.Scalar, lineType: int, shift: int, offset: cv2.typing.Point) -> UMat	getCPUFeaturesLine() -> str
							filter2D(src: cv2.typing.MatLike, ddepth: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike	getCPUTickCount() -> int
							filter2D(src: UMat, ddepth: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat	getDefaultAlgorithmHint() -> AlgorithmHint
							filterHomographyDecompByVisibleRefpoints(rotations: _typing.Sequence[cv2.typing.MatLike], normals: _typing.Sequence[cv2.typing.MatLike], beforePoints: cv2.typing.MatLike, afterPoints: cv2.typing.MatLike, possibleSolutions: cv2.typing.MatLike | None, pointsMask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	getDefaultNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike
							filterHomographyDecompByVisibleRefpoints(rotations: _typing.Sequence[UMat], normals: _typing.Sequence[UMat], beforePoints: UMat, afterPoints: UMat, possibleSolutions: UMat | None, pointsMask: UMat | None) -> UMat	getDefaultNewCameraMatrix(cameraMatrix: UMat, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike
							filterSpeckles(img: cv2.typing.MatLike, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getDerivKernels(dx: int, dy: int, ksize: int, kx: cv2.typing.MatLike | None, ky: cv2.typing.MatLike | None, normalize: bool, ktype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							filterSpeckles(img: UMat, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: UMat | None) -> tuple[UMat, UMat]	getDerivKernels(dx: int, dy: int, ksize: int, kx: UMat | None, ky: UMat | None, normalize: bool, ktype: int) -> tuple[UMat, UMat]
							find4QuadCornerSubpix(img: cv2.typing.MatLike, corners: cv2.typing.MatLike, region_size: cv2.typing.Size) -> tuple[bool, cv2.typing.MatLike]	getFontScaleFromHeight(fontFace: int, pixelHeight: int, thickness: int) -> float
							find4QuadCornerSubpix(img: UMat, corners: UMat, region_size: cv2.typing.Size) -> tuple[bool, UMat]	getGaborKernel(ksize: cv2.typing.Size, sigma: float, theta: float, lambd: float, gamma: float, psi: float, ktype: int) -> cv2.typing.MatLike
							findChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	getGaussianKernel(ksize: int, sigma: float, ktype: int) -> cv2.typing.MatLike
							findChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]	getHardwareFeatureName(feature: int) -> str
							findChessboardCornersSB(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	getLogLevel() -> int
							findChessboardCornersSB(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]	getNumThreads() -> int
							findChessboardCornersSBWithMeta(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, corners: cv2.typing.MatLike | None, meta: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	getNumberOfCPUs() -> int
							findChessboardCornersSBWithMeta(image: UMat, patternSize: cv2.typing.Size, flags: int, corners: UMat | None, meta: UMat | None) -> tuple[bool, UMat, UMat]	getOptimalDFTSize(vecsize: int) -> int
							findCirclesGrid(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, blobDetector: cv2.typing.FeatureDetector, parameters: CirclesGridFinderParameters, centers: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike]	getOptimalNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]
							findCirclesGrid(image: UMat, patternSize: cv2.typing.Size, flags: int, blobDetector: cv2.typing.FeatureDetector, parameters: CirclesGridFinderParameters, centers: UMat | None) -> tuple[bool, UMat]	getOptimalNewCameraMatrix(cameraMatrix: UMat, distCoeffs: UMat, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]
							findCirclesGrid(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, centers: cv2.typing.MatLike | None, flags: int, blobDetector: cv2.typing.FeatureDetector) -> tuple[bool, cv2.typing.MatLike]	getPerspectiveTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, solveMethod: int) -> cv2.typing.MatLike
							findCirclesGrid(image: UMat, patternSize: cv2.typing.Size, centers: UMat | None, flags: int, blobDetector: cv2.typing.FeatureDetector) -> tuple[bool, UMat]	getPerspectiveTransform(src: UMat, dst: UMat, solveMethod: int) -> cv2.typing.MatLike
							findContours(image: cv2.typing.MatLike, mode: int, method: int, contours: _typing.Sequence[cv2.typing.MatLike] | None, hierarchy: cv2.typing.MatLike | None, offset: cv2.typing.Point) -> tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	getRectSubPix(image: cv2.typing.MatLike, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: cv2.typing.MatLike | None, patchType: int) -> cv2.typing.MatLike
							findContours(image: UMat, mode: int, method: int, contours: _typing.Sequence[UMat] | None, hierarchy: UMat | None, offset: cv2.typing.Point) -> tuple[_typing.Sequence[UMat], UMat]	getRectSubPix(image: UMat, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: UMat | None, patchType: int) -> UMat
							findContoursLinkRuns(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike] | None, hierarchy: cv2.typing.MatLike | None) -> tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	getRotationMatrix2D(center: cv2.typing.Point2f, angle: float, scale: float) -> cv2.typing.MatLike
							findContoursLinkRuns(image: UMat, contours: _typing.Sequence[UMat] | None, hierarchy: UMat | None) -> tuple[_typing.Sequence[UMat], UMat]	getStructuringElement(shape: int, ksize: cv2.typing.Size, anchor: cv2.typing.Point) -> cv2.typing.MatLike
							findContoursLinkRuns(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike] | None) -> _typing.Sequence[cv2.typing.MatLike]	getTextSize(text: str, fontFace: int, fontScale: float, thickness: int) -> tuple[cv2.typing.Size, int]
							findContoursLinkRuns(image: UMat, contours: _typing.Sequence[UMat] | None) -> _typing.Sequence[UMat]	getThreadNum() -> int
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getTickCount() -> int
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix: UMat, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	getTickFrequency() -> float
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getTrackbarPos(trackbarname: str, winname: str) -> int
							findEssentialMat(points1: UMat, points2: UMat, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	getValidDisparityROI(roi1: cv2.typing.Rect, roi2: cv2.typing.Rect, minDisparity: int, numberOfDisparities: int, blockSize: int) -> cv2.typing.Rect
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getVersionMajor() -> int
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	getVersionMinor() -> int
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, dist_coeff1: cv2.typing.MatLike, dist_coeff2: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getVersionRevision() -> int
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, cameraMatrix2: UMat, dist_coeff1: UMat, dist_coeff2: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	getVersionString() -> str
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getWindowImageRect(winname: str) -> cv2.typing.Rect
							findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	getWindowProperty(winname: str, prop_id: int) -> float
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, corners: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, blockSize: int, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike
							findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, corners: UMat | None, mask: UMat | None, blockSize: int, useHarrisDetector: bool, k: float) -> UMat
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, blockSize: int, gradientSize: int, corners: cv2.typing.MatLike | None, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike
							findFundamentalMat(points1: UMat, points2: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, blockSize: int, gradientSize: int, corners: UMat | None, useHarrisDetector: bool, k: float) -> UMat
							findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, mask: cv2.typing.MatLike | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	goodFeaturesToTrackWithQuality(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, corners: cv2.typing.MatLike | None, cornersQuality: cv2.typing.MatLike | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							findHomography(srcPoints: UMat, dstPoints: UMat, method: int, ransacReprojThreshold: float, mask: UMat | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, UMat]	goodFeaturesToTrackWithQuality(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, corners: UMat | None, cornersQuality: UMat | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[UMat, UMat]
							findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	grabCut(img: cv2.typing.MatLike, mask: cv2.typing.MatLike, rect: cv2.typing.Rect, bgdModel: cv2.typing.MatLike, fgdModel: cv2.typing.MatLike, iterCount: int, mode: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							findHomography(srcPoints: UMat, dstPoints: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	grabCut(img: UMat, mask: UMat, rect: cv2.typing.Rect, bgdModel: UMat, fgdModel: UMat, iterCount: int, mode: int) -> tuple[UMat, UMat, UMat]
							findNonZero(src: cv2.typing.MatLike, idx: cv2.typing.MatLike | None) -> cv2.typing.MatLike	hasNonZero(src: cv2.typing.MatLike) -> bool
							findNonZero(src: UMat, idx: UMat | None) -> UMat	hasNonZero(src: UMat) -> bool
							findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike, gaussFiltSize: int) -> tuple[float, cv2.typing.MatLike]	haveImageReader(filename: str) -> bool
							findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat, gaussFiltSize: int) -> tuple[float, UMat]	haveImageWriter(filename: str) -> bool
							findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	haveOpenVX() -> bool
							findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat | None) -> tuple[float, UMat]	idct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							fitEllipse(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	idct(src: UMat, dst: UMat | None, flags: int) -> UMat
							fitEllipse(points: UMat) -> cv2.typing.RotatedRect	idft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike
							fitEllipseAMS(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	idft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat
							fitEllipseAMS(points: UMat) -> cv2.typing.RotatedRect	illuminationChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike
							fitEllipseDirect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	illuminationChange(src: UMat, mask: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat
							fitEllipseDirect(points: UMat) -> cv2.typing.RotatedRect	imcount(filename: str, flags: int) -> int
							fitLine(points: cv2.typing.MatLike, distType: int, param: float, reps: float, aeps: float, line: cv2.typing.MatLike | None) -> cv2.typing.MatLike	imdecode(buf: cv2.typing.MatLike, flags: int) -> cv2.typing.MatLike
							fitLine(points: UMat, distType: int, param: float, reps: float, aeps: float, line: UMat | None) -> UMat	imdecode(buf: UMat, flags: int) -> cv2.typing.MatLike
							flip(src: cv2.typing.MatLike, flipCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	imread(filename: str, flags: int) -> cv2.typing.MatLike
							flip(src: UMat, flipCode: int, dst: UMat | None) -> UMat	imread(filename: str, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							flipND(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	imread(filename: str, dst: UMat | None, flags: int) -> UMat
							flipND(src: UMat, axis: int, dst: UMat | None) -> UMat	imshow(winname: str, mat: cv2.typing.MatLike) -> None
							floodFill(image: cv2.typing.MatLike, mask: cv2.typing.MatLike | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]	imshow(winname: str, mat: cv2.cuda.GpuMat) -> None
							floodFill(image: UMat, mask: UMat | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, UMat, UMat, cv2.typing.Rect]	imshow(winname: str, mat: UMat) -> None
							gemm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, alpha: float, src3: cv2.typing.MatLike, beta: float, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	inRange(src: cv2.typing.MatLike, lowerb: cv2.typing.MatLike, upperb: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							gemm(src1: UMat, src2: UMat, alpha: float, src3: UMat, beta: float, dst: UMat | None, flags: int) -> UMat	inRange(src: UMat, lowerb: UMat, upperb: UMat, dst: UMat | None) -> UMat
							getAffineTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike) -> cv2.typing.MatLike	initInverseRectificationMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getAffineTransform(src: UMat, dst: UMat) -> cv2.typing.MatLike	initInverseRectificationMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]
							getBuildInformation() -> str	initUndistortRectifyMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getCPUFeaturesLine() -> str	initUndistortRectifyMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]
							getCPUTickCount() -> int	inpaint(src: cv2.typing.MatLike, inpaintMask: cv2.typing.MatLike, inpaintRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getDefaultAlgorithmHint() -> AlgorithmHint	inpaint(src: UMat, inpaintMask: UMat, inpaintRadius: float, flags: int, dst: UMat | None) -> UMat
							getDefaultNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike	insertChannel(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, coi: int) -> cv2.typing.MatLike
							getDefaultNewCameraMatrix(cameraMatrix: UMat, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike	insertChannel(src: UMat, dst: UMat, coi: int) -> UMat
							getDerivKernels(dx: int, dy: int, ksize: int, kx: cv2.typing.MatLike | None, ky: cv2.typing.MatLike | None, normalize: bool, ktype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	integral(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sdepth: int) -> cv2.typing.MatLike
							getDerivKernels(dx: int, dy: int, ksize: int, kx: UMat | None, ky: UMat | None, normalize: bool, ktype: int) -> tuple[UMat, UMat]	integral(src: UMat, sum: UMat | None, sdepth: int) -> UMat
							getFontScaleFromHeight(fontFace: int, pixelHeight: int, thickness: int) -> float	integral2(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getGaborKernel(ksize: cv2.typing.Size, sigma: float, theta: float, lambd: float, gamma: float, psi: float, ktype: int) -> cv2.typing.MatLike	integral2(src: UMat, sum: UMat | None, sqsum: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat]
							getGaussianKernel(ksize: int, sigma: float, ktype: int) -> cv2.typing.MatLike	integral3(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, tilted: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							getHardwareFeatureName(feature: int) -> str	integral3(src: UMat, sum: UMat | None, sqsum: UMat | None, tilted: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat, UMat]
							getLogLevel() -> int	intersectConvexConvex(p1: cv2.typing.MatLike, p2: cv2.typing.MatLike, p12: cv2.typing.MatLike | None, handleNested: bool) -> tuple[float, cv2.typing.MatLike]
							getNumThreads() -> int	intersectConvexConvex(p1: UMat, p2: UMat, p12: UMat | None, handleNested: bool) -> tuple[float, UMat]
							getNumberOfCPUs() -> int	invert(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[float, cv2.typing.MatLike]
							getOptimalDFTSize(vecsize: int) -> int	invert(src: UMat, dst: UMat | None, flags: int) -> tuple[float, UMat]
							getOptimalNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]	invertAffineTransform(M: cv2.typing.MatLike, iM: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getOptimalNewCameraMatrix(cameraMatrix: UMat, distCoeffs: UMat, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]	invertAffineTransform(M: UMat, iM: UMat | None) -> UMat
							getPerspectiveTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, solveMethod: int) -> cv2.typing.MatLike	isContourConvex(contour: cv2.typing.MatLike) -> bool
							getPerspectiveTransform(src: UMat, dst: UMat, solveMethod: int) -> cv2.typing.MatLike	isContourConvex(contour: UMat) -> bool
							getRectSubPix(image: cv2.typing.MatLike, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: cv2.typing.MatLike | None, patchType: int) -> cv2.typing.MatLike	kmeans(data: cv2.typing.MatLike, K: int, bestLabels: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]
							getRectSubPix(image: UMat, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: UMat | None, patchType: int) -> UMat	kmeans(data: UMat, K: int, bestLabels: UMat, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: UMat | None) -> tuple[float, UMat, UMat]
							getRotationMatrix2D(center: cv2.typing.Point2f, angle: float, scale: float) -> cv2.typing.MatLike	line(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							getStructuringElement(shape: int, ksize: cv2.typing.Size, anchor: cv2.typing.Point) -> cv2.typing.MatLike	line(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							getTextSize(text: str, fontFace: int, fontScale: float, thickness: int) -> tuple[cv2.typing.Size, int]	linearPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getThreadNum() -> int	linearPolar(src: UMat, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat
							getTickCount() -> int	log(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getTickFrequency() -> float	log(src: UMat, dst: UMat | None) -> UMat
							getTrackbarPos(trackbarname: str, winname: str) -> int	logPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, M: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getValidDisparityROI(roi1: cv2.typing.Rect, roi2: cv2.typing.Rect, minDisparity: int, numberOfDisparities: int, blockSize: int) -> cv2.typing.Rect	logPolar(src: UMat, center: cv2.typing.Point2f, M: float, flags: int, dst: UMat | None) -> UMat
							getVersionMajor() -> int	magnitude(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getVersionMinor() -> int	magnitude(x: UMat, y: UMat, magnitude: UMat | None) -> UMat
							getVersionRevision() -> int	matMulDeriv(A: cv2.typing.MatLike, B: cv2.typing.MatLike, dABdA: cv2.typing.MatLike | None, dABdB: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getVersionString() -> str	matMulDeriv(A: UMat, B: UMat, dABdA: UMat | None, dABdB: UMat | None) -> tuple[UMat, UMat]
							getWindowImageRect(winname: str) -> cv2.typing.Rect	matchShapes(contour1: cv2.typing.MatLike, contour2: cv2.typing.MatLike, method: int, parameter: float) -> float
							getWindowProperty(winname: str, prop_id: int) -> float	matchShapes(contour1: UMat, contour2: UMat, method: int, parameter: float) -> float
							goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, corners: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, blockSize: int, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike	matchTemplate(image: cv2.typing.MatLike, templ: cv2.typing.MatLike, method: int, result: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, corners: UMat | None, mask: UMat | None, blockSize: int, useHarrisDetector: bool, k: float) -> UMat	matchTemplate(image: UMat, templ: UMat, method: int, result: UMat | None, mask: UMat | None) -> UMat
							goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, blockSize: int, gradientSize: int, corners: cv2.typing.MatLike | None, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike	max(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, blockSize: int, gradientSize: int, corners: UMat | None, useHarrisDetector: bool, k: float) -> UMat	max(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
							goodFeaturesToTrackWithQuality(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, corners: cv2.typing.MatLike | None, cornersQuality: cv2.typing.MatLike | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	mean(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.Scalar
							goodFeaturesToTrackWithQuality(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, corners: UMat | None, cornersQuality: UMat | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[UMat, UMat]	mean(src: UMat, mask: UMat | None) -> cv2.typing.Scalar
							grabCut(img: cv2.typing.MatLike, mask: cv2.typing.MatLike, rect: cv2.typing.Rect, bgdModel: cv2.typing.MatLike, fgdModel: cv2.typing.MatLike, iterCount: int, mode: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	meanShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]
							grabCut(img: UMat, mask: UMat, rect: cv2.typing.Rect, bgdModel: UMat, fgdModel: UMat, iterCount: int, mode: int) -> tuple[UMat, UMat, UMat]	meanShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]
							groupRectangles(rectList: _typing.Sequence[cv2.typing.Rect], groupThreshold: int, eps: float) -> tuple[_typing.Sequence[cv2.typing.Rect], _typing.Sequence[int]]	meanStdDev(src: cv2.typing.MatLike, mean: cv2.typing.MatLike | None, stddev: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							hasNonZero(src: cv2.typing.MatLike) -> bool	meanStdDev(src: UMat, mean: UMat | None, stddev: UMat | None, mask: UMat | None) -> tuple[UMat, UMat]
							hasNonZero(src: UMat) -> bool	medianBlur(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							haveImageReader(filename: str) -> bool	medianBlur(src: UMat, ksize: int, dst: UMat | None) -> UMat
							haveImageWriter(filename: str) -> bool	min(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							haveOpenVX() -> bool	min(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
							hconcat(src: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	minAreaRect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							hconcat(src: _typing.Sequence[UMat], dst: UMat | None) -> UMat	minAreaRect(points: UMat) -> cv2.typing.RotatedRect
							idct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	minEnclosingCircle(points: cv2.typing.MatLike) -> tuple[cv2.typing.Point2f, float]
							idct(src: UMat, dst: UMat | None, flags: int) -> UMat	minEnclosingCircle(points: UMat) -> tuple[cv2.typing.Point2f, float]
							idft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike	minEnclosingTriangle(points: cv2.typing.MatLike, triangle: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							idft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat	minEnclosingTriangle(points: UMat, triangle: UMat | None) -> tuple[float, UMat]
							illuminationChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike	minMaxLoc(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]
							illuminationChange(src: UMat, mask: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat	minMaxLoc(src: UMat, mask: UMat | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]
							imcount(filename: str, flags: int) -> int	moments(array: cv2.typing.MatLike, binaryImage: bool) -> cv2.typing.Moments
							imdecode(buf: cv2.typing.MatLike, flags: int) -> cv2.typing.MatLike	moments(array: UMat, binaryImage: bool) -> cv2.typing.Moments
							imdecode(buf: UMat, flags: int) -> cv2.typing.MatLike	morphologyEx(src: cv2.typing.MatLike, op: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							imdecodemulti(buf: cv2.typing.MatLike, flags: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, range: cv2.typing.Range) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	morphologyEx(src: UMat, op: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							imdecodemulti(buf: UMat, flags: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, range: cv2.typing.Range) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	moveWindow(winname: str, x: int, y: int) -> None
							imencode(ext: str, img: cv2.typing.MatLike, params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	mulSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike
							imencode(ext: str, img: UMat, params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	mulSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat
							imencodemulti(ext: str, imgs: _typing.Sequence[cv2.typing.MatLike], params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	mulTransposed(src: cv2.typing.MatLike, aTa: bool, dst: cv2.typing.MatLike | None, delta: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							imencodemulti(ext: str, imgs: _typing.Sequence[UMat], params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	mulTransposed(src: UMat, aTa: bool, dst: UMat | None, delta: UMat | None, scale: float, dtype: int) -> UMat
							imread(filename: str, flags: int) -> cv2.typing.MatLike	multiply(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							imread(filename: str, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	multiply(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat
							imread(filename: str, dst: UMat | None, flags: int) -> UMat	namedWindow(winname: str, flags: int) -> None
							imreadanimation(filename: str, start: int, count: int) -> tuple[bool, Animation]	norm(src1: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float
							imreadmulti(filename: str, mats: _typing.Sequence[cv2.typing.MatLike] | None, flags: int) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	norm(src1: UMat, normType: int, mask: UMat | None) -> float
							imreadmulti(filename: str, start: int, count: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, flags: int) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	norm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float
							imshow(winname: str, mat: cv2.typing.MatLike) -> None	norm(src1: UMat, src2: UMat, normType: int, mask: UMat | None) -> float
							imshow(winname: str, mat: cv2.cuda.GpuMat) -> None	normalize(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, beta: float, norm_type: int, dtype: int, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							imshow(winname: str, mat: UMat) -> None	normalize(src: UMat, dst: UMat, alpha: float, beta: float, norm_type: int, dtype: int, mask: UMat | None) -> UMat
							imwrite(filename: str, img: cv2.typing.MatLike, params: _typing.Sequence[int]) -> bool	patchNaNs(a: cv2.typing.MatLike, val: float) -> cv2.typing.MatLike
							imwrite(filename: str, img: UMat, params: _typing.Sequence[int]) -> bool	patchNaNs(a: UMat, val: float) -> UMat
							imwriteanimation(filename: str, animation: Animation, params: _typing.Sequence[int]) -> bool	pencilSketch(src: cv2.typing.MatLike, dst1: cv2.typing.MatLike | None, dst2: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							imwritemulti(filename: str, img: _typing.Sequence[cv2.typing.MatLike], params: _typing.Sequence[int]) -> bool	pencilSketch(src: UMat, dst1: UMat | None, dst2: UMat | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[UMat, UMat]
							imwritemulti(filename: str, img: _typing.Sequence[UMat], params: _typing.Sequence[int]) -> bool	perspectiveTransform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							inRange(src: cv2.typing.MatLike, lowerb: cv2.typing.MatLike, upperb: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	perspectiveTransform(src: UMat, m: UMat, dst: UMat | None) -> UMat
							inRange(src: UMat, lowerb: UMat, upperb: UMat, dst: UMat | None) -> UMat	phase(x: cv2.typing.MatLike, y: cv2.typing.MatLike, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> cv2.typing.MatLike
							initCameraMatrix2D(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, aspectRatio: float) -> cv2.typing.MatLike	phase(x: UMat, y: UMat, angle: UMat | None, angleInDegrees: bool) -> UMat
							initCameraMatrix2D(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, aspectRatio: float) -> cv2.typing.MatLike	phaseCorrelate(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, window: cv2.typing.MatLike | None) -> tuple[cv2.typing.Point2d, float]
							initInverseRectificationMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	phaseCorrelate(src1: UMat, src2: UMat, window: UMat | None) -> tuple[cv2.typing.Point2d, float]
							initInverseRectificationMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]	pointPolygonTest(contour: cv2.typing.MatLike, pt: cv2.typing.Point2f, measureDist: bool) -> float
							initUndistortRectifyMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	pointPolygonTest(contour: UMat, pt: cv2.typing.Point2f, measureDist: bool) -> float
							initUndistortRectifyMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]	polarToCart(magnitude: cv2.typing.MatLike, angle: cv2.typing.MatLike, x: cv2.typing.MatLike | None, y: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							inpaint(src: cv2.typing.MatLike, inpaintMask: cv2.typing.MatLike, inpaintRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	polarToCart(magnitude: UMat, angle: UMat, x: UMat | None, y: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]
							inpaint(src: UMat, inpaintMask: UMat, inpaintRadius: float, flags: int, dst: UMat | None) -> UMat	pollKey() -> int
							insertChannel(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, coi: int) -> cv2.typing.MatLike	pow(src: cv2.typing.MatLike, power: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							insertChannel(src: UMat, dst: UMat, coi: int) -> UMat	pow(src: UMat, power: float, dst: UMat | None) -> UMat
							integral(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sdepth: int) -> cv2.typing.MatLike	preCornerDetect(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
							integral(src: UMat, sum: UMat | None, sdepth: int) -> UMat	preCornerDetect(src: UMat, ksize: int, dst: UMat | None, borderType: int) -> UMat
							integral2(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	projectPoints(objectPoints: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None, aspectRatio: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							integral2(src: UMat, sum: UMat | None, sqsum: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat]	projectPoints(objectPoints: UMat, rvec: UMat, tvec: UMat, cameraMatrix: UMat, distCoeffs: UMat, imagePoints: UMat | None, jacobian: UMat | None, aspectRatio: float) -> tuple[UMat, UMat]
							integral3(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, tilted: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	putText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> cv2.typing.MatLike
							integral3(src: UMat, sum: UMat | None, sqsum: UMat | None, tilted: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat, UMat]	putText(img: UMat, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> UMat
							intersectConvexConvex(p1: cv2.typing.MatLike, p2: cv2.typing.MatLike, p12: cv2.typing.MatLike | None, handleNested: bool) -> tuple[float, cv2.typing.MatLike]	pyrDown(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike
							intersectConvexConvex(p1: UMat, p2: UMat, p12: UMat | None, handleNested: bool) -> tuple[float, UMat]	pyrDown(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat
							invert(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[float, cv2.typing.MatLike]	pyrMeanShiftFiltering(src: cv2.typing.MatLike, sp: float, sr: float, dst: cv2.typing.MatLike | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> cv2.typing.MatLike
							invert(src: UMat, dst: UMat | None, flags: int) -> tuple[float, UMat]	pyrMeanShiftFiltering(src: UMat, sp: float, sr: float, dst: UMat | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> UMat
							invertAffineTransform(M: cv2.typing.MatLike, iM: cv2.typing.MatLike | None) -> cv2.typing.MatLike	pyrUp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike
							invertAffineTransform(M: UMat, iM: UMat | None) -> UMat	pyrUp(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat
							isContourConvex(contour: cv2.typing.MatLike) -> bool	randShuffle(dst: cv2.typing.MatLike, iterFactor: float) -> cv2.typing.MatLike
							isContourConvex(contour: UMat) -> bool	randShuffle(dst: UMat, iterFactor: float) -> UMat
							kmeans(data: cv2.typing.MatLike, K: int, bestLabels: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]	randn(dst: cv2.typing.MatLike, mean: cv2.typing.MatLike, stddev: cv2.typing.MatLike) -> cv2.typing.MatLike
							kmeans(data: UMat, K: int, bestLabels: UMat, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: UMat | None) -> tuple[float, UMat, UMat]	randn(dst: UMat, mean: UMat, stddev: UMat) -> UMat
							line(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	randu(dst: cv2.typing.MatLike, low: cv2.typing.MatLike, high: cv2.typing.MatLike) -> cv2.typing.MatLike
							line(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	randu(dst: UMat, low: UMat, high: UMat) -> UMat
							linearPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	readOpticalFlow(path: str) -> cv2.typing.MatLike
							linearPolar(src: UMat, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat	recoverPose(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, E: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							log(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	recoverPose(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, E: UMat | None, R: UMat | None, t: UMat | None, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]
							log(src: UMat, dst: UMat | None) -> UMat	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							logPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, M: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, R: UMat | None, t: UMat | None, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]
							logPolar(src: UMat, center: cv2.typing.Point2f, M: float, flags: int, dst: UMat | None) -> UMat	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, focal: float, pp: cv2.typing.Point2d, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							magnitude(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None) -> cv2.typing.MatLike	recoverPose(E: UMat, points1: UMat, points2: UMat, R: UMat | None, t: UMat | None, focal: float, pp: cv2.typing.Point2d, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]
							magnitude(x: UMat, y: UMat, magnitude: UMat | None) -> UMat	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distanceThresh: float, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, triangulatedPoints: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							matMulDeriv(A: cv2.typing.MatLike, B: cv2.typing.MatLike, dABdA: cv2.typing.MatLike | None, dABdB: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, distanceThresh: float, R: UMat | None, t: UMat | None, mask: UMat | None, triangulatedPoints: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]
							matMulDeriv(A: UMat, B: UMat, dABdA: UMat | None, dABdB: UMat | None) -> tuple[UMat, UMat]	rectangle(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							matchShapes(contour1: cv2.typing.MatLike, contour2: cv2.typing.MatLike, method: int, parameter: float) -> float	rectangle(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							matchShapes(contour1: UMat, contour2: UMat, method: int, parameter: float) -> float	rectangle(img: cv2.typing.MatLike, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							matchTemplate(image: cv2.typing.MatLike, templ: cv2.typing.MatLike, method: int, result: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	rectangle(img: UMat, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							matchTemplate(image: UMat, templ: UMat, method: int, result: UMat | None, mask: UMat | None) -> UMat	rectangleIntersectionArea(a: cv2.typing.Rect2d, b: cv2.typing.Rect2d) -> float
							max(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	reduce(src: cv2.typing.MatLike, dim: int, rtype: int, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							max(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	reduce(src: UMat, dim: int, rtype: int, dst: UMat | None, dtype: int) -> UMat
							mean(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.Scalar	reduceArgMax(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike
							mean(src: UMat, mask: UMat | None) -> cv2.typing.Scalar	reduceArgMax(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat
							meanShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]	reduceArgMin(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike
							meanShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]	reduceArgMin(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat
							meanStdDev(src: cv2.typing.MatLike, mean: cv2.typing.MatLike | None, stddev: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	remap(src: cv2.typing.MatLike, map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, interpolation: int, dst: cv2.typing.MatLike | None, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							meanStdDev(src: UMat, mean: UMat | None, stddev: UMat | None, mask: UMat | None) -> tuple[UMat, UMat]	remap(src: UMat, map1: UMat, map2: UMat, interpolation: int, dst: UMat | None, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							medianBlur(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	repeat(src: cv2.typing.MatLike, ny: int, nx: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							medianBlur(src: UMat, ksize: int, dst: UMat | None) -> UMat	repeat(src: UMat, ny: int, nx: int, dst: UMat | None) -> UMat
							merge(mv: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	reprojectImageTo3D(disparity: cv2.typing.MatLike, Q: cv2.typing.MatLike, _3dImage: cv2.typing.MatLike | None, handleMissingValues: bool, ddepth: int) -> cv2.typing.MatLike
							merge(mv: _typing.Sequence[UMat], dst: UMat | None) -> UMat	reprojectImageTo3D(disparity: UMat, Q: UMat, _3dImage: UMat | None, handleMissingValues: bool, ddepth: int) -> UMat
							min(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	resize(src: cv2.typing.MatLike, dsize: cv2.typing.Size | None, dst: cv2.typing.MatLike | None, fx: float, fy: float, interpolation: int) -> cv2.typing.MatLike
							min(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	resize(src: UMat, dsize: cv2.typing.Size | None, dst: UMat | None, fx: float, fy: float, interpolation: int) -> UMat
							minAreaRect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	resizeWindow(winname: str, width: int, height: int) -> None
							minAreaRect(points: UMat) -> cv2.typing.RotatedRect	resizeWindow(winname: str, size: cv2.typing.Size) -> None
							minEnclosingCircle(points: cv2.typing.MatLike) -> tuple[cv2.typing.Point2f, float]	rotate(src: cv2.typing.MatLike, rotateCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							minEnclosingCircle(points: UMat) -> tuple[cv2.typing.Point2f, float]	rotate(src: UMat, rotateCode: int, dst: UMat | None) -> UMat
							minEnclosingTriangle(points: cv2.typing.MatLike, triangle: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							minEnclosingTriangle(points: UMat, triangle: UMat | None) -> tuple[float, UMat]	rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: UMat | None) -> tuple[int, UMat]
							minMaxLoc(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]	sampsonDistance(pt1: cv2.typing.MatLike, pt2: cv2.typing.MatLike, F: cv2.typing.MatLike) -> float
							minMaxLoc(src: UMat, mask: UMat | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]	sampsonDistance(pt1: UMat, pt2: UMat, F: UMat) -> float
							mixChannels(src: _typing.Sequence[cv2.typing.MatLike], dst: _typing.Sequence[cv2.typing.MatLike], fromTo: _typing.Sequence[int]) -> _typing.Sequence[cv2.typing.MatLike]	scaleAdd(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							mixChannels(src: _typing.Sequence[UMat], dst: _typing.Sequence[UMat], fromTo: _typing.Sequence[int]) -> _typing.Sequence[UMat]	scaleAdd(src1: UMat, alpha: float, src2: UMat, dst: UMat | None) -> UMat
							moments(array: cv2.typing.MatLike, binaryImage: bool) -> cv2.typing.Moments	seamlessClone(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike, p: cv2.typing.Point, flags: int, blend: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							moments(array: UMat, binaryImage: bool) -> cv2.typing.Moments	seamlessClone(src: UMat, dst: UMat, mask: UMat, p: cv2.typing.Point, flags: int, blend: UMat | None) -> UMat
							morphologyEx(src: cv2.typing.MatLike, op: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	selectROI(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							morphologyEx(src: UMat, op: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	selectROI(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							moveWindow(winname: str, x: int, y: int) -> None	selectROI(img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							mulSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike	selectROI(img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							mulSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat	sepFilter2D(src: cv2.typing.MatLike, ddepth: int, kernelX: cv2.typing.MatLike, kernelY: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike
							mulTransposed(src: cv2.typing.MatLike, aTa: bool, dst: cv2.typing.MatLike | None, delta: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	sepFilter2D(src: UMat, ddepth: int, kernelX: UMat, kernelY: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat
							mulTransposed(src: UMat, aTa: bool, dst: UMat | None, delta: UMat | None, scale: float, dtype: int) -> UMat	setIdentity(mtx: cv2.typing.MatLike, s: cv2.typing.Scalar) -> cv2.typing.MatLike
							multiply(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	setIdentity(mtx: UMat, s: cv2.typing.Scalar) -> UMat
							multiply(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat	setLogLevel(level: int) -> int
							namedWindow(winname: str, flags: int) -> None	setNumThreads(nthreads: int) -> None
							norm(src1: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float	setRNGSeed(seed: int) -> None
							norm(src1: UMat, normType: int, mask: UMat | None) -> float	setTrackbarMax(trackbarname: str, winname: str, maxval: int) -> None
							norm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float	setTrackbarMin(trackbarname: str, winname: str, minval: int) -> None
							norm(src1: UMat, src2: UMat, normType: int, mask: UMat | None) -> float	setTrackbarPos(trackbarname: str, winname: str, pos: int) -> None
							normalize(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, beta: float, norm_type: int, dtype: int, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	setUseOpenVX(flag: bool) -> None
							normalize(src: UMat, dst: UMat, alpha: float, beta: float, norm_type: int, dtype: int, mask: UMat | None) -> UMat	setUseOptimized(onoff: bool) -> None
							patchNaNs(a: cv2.typing.MatLike, val: float) -> cv2.typing.MatLike	setWindowProperty(winname: str, prop_id: int, prop_value: float) -> None
							patchNaNs(a: UMat, val: float) -> UMat	setWindowTitle(winname: str, title: str) -> None
							pencilSketch(src: cv2.typing.MatLike, dst1: cv2.typing.MatLike | None, dst2: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	solve(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							pencilSketch(src: UMat, dst1: UMat | None, dst2: UMat | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[UMat, UMat]	solve(src1: UMat, src2: UMat, dst: UMat | None, flags: int) -> tuple[bool, UMat]
							perspectiveTransform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	solveCubic(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							perspectiveTransform(src: UMat, m: UMat, dst: UMat | None) -> UMat	solveCubic(coeffs: UMat, roots: UMat | None) -> tuple[int, UMat]
							phase(x: cv2.typing.MatLike, y: cv2.typing.MatLike, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> cv2.typing.MatLike	solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, constr_eps: float, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							phase(x: UMat, y: UMat, angle: UMat | None, angleInDegrees: bool) -> UMat	solveLP(Func: UMat, Constr: UMat, constr_eps: float, z: UMat | None) -> tuple[int, UMat]
							phaseCorrelate(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, window: cv2.typing.MatLike | None) -> tuple[cv2.typing.Point2d, float]	solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							phaseCorrelate(src1: UMat, src2: UMat, window: UMat | None) -> tuple[cv2.typing.Point2d, float]	solveLP(Func: UMat, Constr: UMat, z: UMat | None) -> tuple[int, UMat]
							pointPolygonTest(contour: cv2.typing.MatLike, pt: cv2.typing.Point2f, measureDist: bool) -> float	solvePnP(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							pointPolygonTest(contour: UMat, pt: cv2.typing.Point2f, measureDist: bool) -> float	solvePnP(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, UMat, UMat]
							polarToCart(magnitude: cv2.typing.MatLike, angle: cv2.typing.MatLike, x: cv2.typing.MatLike | None, y: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							polarToCart(magnitude: UMat, angle: UMat, x: UMat | None, y: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]	solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: UMat | None, flags: int) -> tuple[bool, UMat, UMat, UMat]
							pollKey() -> int	solvePnPRefineLM(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							polylines(img: cv2.typing.MatLike, pts: _typing.Sequence[cv2.typing.MatLike], isClosed: bool, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	solvePnPRefineLM(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria) -> tuple[UMat, UMat]
							polylines(img: UMat, pts: _typing.Sequence[UMat], isClosed: bool, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	solvePnPRefineVVS(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							pow(src: cv2.typing.MatLike, power: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	solvePnPRefineVVS(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[UMat, UMat]
							pow(src: UMat, power: float, dst: UMat | None) -> UMat	solvePoly(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None, maxIters: int) -> tuple[float, cv2.typing.MatLike]
							preCornerDetect(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	solvePoly(coeffs: UMat, roots: UMat | None, maxIters: int) -> tuple[float, UMat]
							preCornerDetect(src: UMat, ksize: int, dst: UMat | None, borderType: int) -> UMat	sort(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							projectPoints(objectPoints: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None, aspectRatio: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	sort(src: UMat, flags: int, dst: UMat | None) -> UMat
							projectPoints(objectPoints: UMat, rvec: UMat, tvec: UMat, cameraMatrix: UMat, distCoeffs: UMat, imagePoints: UMat | None, jacobian: UMat | None, aspectRatio: float) -> tuple[UMat, UMat]	sortIdx(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							putText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> cv2.typing.MatLike	sortIdx(src: UMat, flags: int, dst: UMat | None) -> UMat
							putText(img: UMat, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> UMat	spatialGradient(src: cv2.typing.MatLike, dx: cv2.typing.MatLike | None, dy: cv2.typing.MatLike | None, ksize: int, borderType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							pyrDown(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike	spatialGradient(src: UMat, dx: UMat | None, dy: UMat | None, ksize: int, borderType: int) -> tuple[UMat, UMat]
							pyrDown(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat	sqrBoxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike
							pyrMeanShiftFiltering(src: cv2.typing.MatLike, sp: float, sr: float, dst: cv2.typing.MatLike | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> cv2.typing.MatLike	sqrBoxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat
							pyrMeanShiftFiltering(src: UMat, sp: float, sr: float, dst: UMat | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> UMat	sqrt(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							pyrUp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike	sqrt(src: UMat, dst: UMat | None) -> UMat
							pyrUp(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat	stackBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							randShuffle(dst: cv2.typing.MatLike, iterFactor: float) -> cv2.typing.MatLike	stackBlur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None) -> UMat
							randShuffle(dst: UMat, iterFactor: float) -> UMat	startWindowThread() -> int
							randn(dst: cv2.typing.MatLike, mean: cv2.typing.MatLike, stddev: cv2.typing.MatLike) -> cv2.typing.MatLike	stereoRectify(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]
							randn(dst: UMat, mean: UMat, stddev: UMat) -> UMat	stereoRectify(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, R1: UMat | None, R2: UMat | None, P1: UMat | None, P2: UMat | None, Q: UMat | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]
							randu(dst: cv2.typing.MatLike, low: cv2.typing.MatLike, high: cv2.typing.MatLike) -> cv2.typing.MatLike	stereoRectifyUncalibrated(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, F: cv2.typing.MatLike, imgSize: cv2.typing.Size, H1: cv2.typing.MatLike | None, H2: cv2.typing.MatLike | None, threshold: float) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							randu(dst: UMat, low: UMat, high: UMat) -> UMat	stereoRectifyUncalibrated(points1: UMat, points2: UMat, F: UMat, imgSize: cv2.typing.Size, H1: UMat | None, H2: UMat | None, threshold: float) -> tuple[bool, UMat, UMat]
							readOpticalFlow(path: str) -> cv2.typing.MatLike	stylization(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							recoverPose(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, E: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	stylization(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat
							recoverPose(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, E: UMat | None, R: UMat | None, t: UMat | None, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]	subtract(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	subtract(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat
							recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, R: UMat | None, t: UMat | None, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]	sumElems(src: cv2.typing.MatLike) -> cv2.typing.Scalar
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, focal: float, pp: cv2.typing.Point2d, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	sumElems(src: UMat) -> cv2.typing.Scalar
							recoverPose(E: UMat, points1: UMat, points2: UMat, R: UMat | None, t: UMat | None, focal: float, pp: cv2.typing.Point2d, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]	textureFlattening(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, low_threshold: float, high_threshold: float, kernel_size: int) -> cv2.typing.MatLike
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distanceThresh: float, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, triangulatedPoints: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	textureFlattening(src: UMat, mask: UMat, dst: UMat | None, low_threshold: float, high_threshold: float, kernel_size: int) -> UMat
							recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, distanceThresh: float, R: UMat | None, t: UMat | None, mask: UMat | None, triangulatedPoints: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]	threshold(src: cv2.typing.MatLike, thresh: float, maxval: float, type: int, dst: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							rectangle(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	threshold(src: UMat, thresh: float, maxval: float, type: int, dst: UMat | None) -> tuple[float, UMat]
							rectangle(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	trace(mtx: cv2.typing.MatLike) -> cv2.typing.Scalar
							rectangle(img: cv2.typing.MatLike, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	trace(mtx: UMat) -> cv2.typing.Scalar
							rectangle(img: UMat, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	transform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							rectangleIntersectionArea(a: cv2.typing.Rect2d, b: cv2.typing.Rect2d) -> float	transform(src: UMat, m: UMat, dst: UMat | None) -> UMat
							rectify3Collinear(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, cameraMatrix3: cv2.typing.MatLike, distCoeffs3: cv2.typing.MatLike, imgpt1: _typing.Sequence[cv2.typing.MatLike], imgpt3: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, R12: cv2.typing.MatLike, T12: cv2.typing.MatLike, R13: cv2.typing.MatLike, T13: cv2.typing.MatLike, alpha: float, newImgSize: cv2.typing.Size, flags: int, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, R3: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, P3: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]	transpose(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							rectify3Collinear(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, cameraMatrix3: UMat, distCoeffs3: UMat, imgpt1: _typing.Sequence[UMat], imgpt3: _typing.Sequence[UMat], imageSize: cv2.typing.Size, R12: UMat, T12: UMat, R13: UMat, T13: UMat, alpha: float, newImgSize: cv2.typing.Size, flags: int, R1: UMat | None, R2: UMat | None, R3: UMat | None, P1: UMat | None, P2: UMat | None, P3: UMat | None, Q: UMat | None) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]	transpose(src: UMat, dst: UMat | None) -> UMat
							reduce(src: cv2.typing.MatLike, dim: int, rtype: int, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	triangulatePoints(projMatr1: cv2.typing.MatLike, projMatr2: cv2.typing.MatLike, projPoints1: cv2.typing.MatLike, projPoints2: cv2.typing.MatLike, points4D: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							reduce(src: UMat, dim: int, rtype: int, dst: UMat | None, dtype: int) -> UMat	triangulatePoints(projMatr1: UMat, projMatr2: UMat, projPoints1: UMat, projPoints2: UMat, points4D: UMat | None) -> UMat
							reduceArgMax(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike	undistort(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, newCameraMatrix: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							reduceArgMax(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat	undistort(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, newCameraMatrix: UMat | None) -> UMat
							reduceArgMin(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike	undistortImagePoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, arg1: cv2.typing.TermCriteria) -> cv2.typing.MatLike
							reduceArgMin(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat	undistortImagePoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, arg1: cv2.typing.TermCriteria) -> UMat
							remap(src: cv2.typing.MatLike, map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, interpolation: int, dst: cv2.typing.MatLike | None, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	undistortPoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, P: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							remap(src: UMat, map1: UMat, map2: UMat, interpolation: int, dst: UMat | None, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	undistortPoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, R: UMat | None, P: UMat | None) -> UMat
							repeat(src: cv2.typing.MatLike, ny: int, nx: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	undistortPointsIter(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, P: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							repeat(src: UMat, ny: int, nx: int, dst: UMat | None) -> UMat	undistortPointsIter(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, R: UMat, P: UMat, criteria: cv2.typing.TermCriteria, dst: UMat | None) -> UMat
							reprojectImageTo3D(disparity: cv2.typing.MatLike, Q: cv2.typing.MatLike, _3dImage: cv2.typing.MatLike | None, handleMissingValues: bool, ddepth: int) -> cv2.typing.MatLike	useOpenVX() -> bool
							reprojectImageTo3D(disparity: UMat, Q: UMat, _3dImage: UMat | None, handleMissingValues: bool, ddepth: int) -> UMat	useOptimized() -> bool
							resize(src: cv2.typing.MatLike, dsize: cv2.typing.Size | None, dst: cv2.typing.MatLike | None, fx: float, fy: float, interpolation: int) -> cv2.typing.MatLike	validateDisparity(disparity: cv2.typing.MatLike, cost: cv2.typing.MatLike, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> cv2.typing.MatLike
							resize(src: UMat, dsize: cv2.typing.Size | None, dst: UMat | None, fx: float, fy: float, interpolation: int) -> UMat	validateDisparity(disparity: UMat, cost: UMat, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> UMat
							resizeWindow(winname: str, width: int, height: int) -> None	waitKey(delay: int) -> int
							resizeWindow(winname: str, size: cv2.typing.Size) -> None	waitKeyEx(delay: int) -> int
							rotate(src: cv2.typing.MatLike, rotateCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	warpAffine(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							rotate(src: UMat, rotateCode: int, dst: UMat | None) -> UMat	warpAffine(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	warpPerspective(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: UMat | None) -> tuple[int, UMat]	warpPerspective(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							sampsonDistance(pt1: cv2.typing.MatLike, pt2: cv2.typing.MatLike, F: cv2.typing.MatLike) -> float	warpPolar(src: cv2.typing.MatLike, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							sampsonDistance(pt1: UMat, pt2: UMat, F: UMat) -> float	warpPolar(src: UMat, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat
							scaleAdd(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	watershed(image: cv2.typing.MatLike, markers: cv2.typing.MatLike) -> cv2.typing.MatLike
							scaleAdd(src1: UMat, alpha: float, src2: UMat, dst: UMat | None) -> UMat	watershed(image: UMat, markers: UMat) -> UMat
							seamlessClone(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike, p: cv2.typing.Point, flags: int, blend: cv2.typing.MatLike | None) -> cv2.typing.MatLike	writeOpticalFlow(path: str, flow: cv2.typing.MatLike) -> bool
							seamlessClone(src: UMat, dst: UMat, mask: UMat, p: cv2.typing.Point, flags: int, blend: UMat | None) -> UMat	writeOpticalFlow(path: str, flow: UMat) -> bool
							selectROI(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	CV_8UC(channels: int) -> int
							selectROI(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	CV_8SC(channels: int) -> int
							selectROI(img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	CV_16UC(channels: int) -> int
							selectROI(img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	CV_16SC(channels: int) -> int
							selectROIs(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> _typing.Sequence[cv2.typing.Rect]	CV_32SC(channels: int) -> int
							selectROIs(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> _typing.Sequence[cv2.typing.Rect]	CV_32FC(channels: int) -> int
							sepFilter2D(src: cv2.typing.MatLike, ddepth: int, kernelX: cv2.typing.MatLike, kernelY: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike	CV_64FC(channels: int) -> int
							sepFilter2D(src: UMat, ddepth: int, kernelX: UMat, kernelY: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat	CV_16FC(channels: int) -> int
							setIdentity(mtx: cv2.typing.MatLike, s: cv2.typing.Scalar) -> cv2.typing.MatLike	CV_MAKETYPE(depth: int, channels: int) -> int
							setIdentity(mtx: UMat, s: cv2.typing.Scalar) -> UMat	dnn_unregisterLayer(layerTypeName: str) -> None
							setLogLevel(level: int) -> int	
							setNumThreads(nthreads: int) -> None	
							setRNGSeed(seed: int) -> None	
							setTrackbarMax(trackbarname: str, winname: str, maxval: int) -> None	
							setTrackbarMin(trackbarname: str, winname: str, minval: int) -> None	
							setTrackbarPos(trackbarname: str, winname: str, pos: int) -> None	
							setUseOpenVX(flag: bool) -> None	
							setUseOptimized(onoff: bool) -> None	
							setWindowProperty(winname: str, prop_id: int, prop_value: float) -> None	
							setWindowTitle(winname: str, title: str) -> None	
							solve(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	
							solve(src1: UMat, src2: UMat, dst: UMat | None, flags: int) -> tuple[bool, UMat]	
							solveCubic(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveCubic(coeffs: UMat, roots: UMat | None) -> tuple[int, UMat]	
							solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, constr_eps: float, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveLP(Func: UMat, Constr: UMat, constr_eps: float, z: UMat | None) -> tuple[int, UMat]	
							solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveLP(Func: UMat, Constr: UMat, z: UMat | None) -> tuple[int, UMat]	
							solveP3P(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, flags: int, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	
							solveP3P(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, flags: int, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat]]	
							solvePnP(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnP(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, UMat, UMat]	
							solvePnPGeneric(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, useExtrinsicGuess: bool, flags: SolvePnPMethod, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, reprojectionError: cv2.typing.MatLike | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	
							solvePnPGeneric(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, useExtrinsicGuess: bool, flags: SolvePnPMethod, rvec: UMat | None, tvec: UMat | None, reprojectionError: UMat | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	
							solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: UMat | None, flags: int) -> tuple[bool, UMat, UMat, UMat]	
							solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, params: UsacParams) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, inliers: UMat | None, params: UsacParams) -> tuple[bool, UMat, UMat, UMat, UMat]	
							solvePnPRefineLM(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRefineLM(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria) -> tuple[UMat, UMat]	
							solvePnPRefineVVS(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRefineVVS(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[UMat, UMat]	
							solvePoly(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None, maxIters: int) -> tuple[float, cv2.typing.MatLike]	
							solvePoly(coeffs: UMat, roots: UMat | None, maxIters: int) -> tuple[float, UMat]	
							sort(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sort(src: UMat, flags: int, dst: UMat | None) -> UMat	
							sortIdx(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sortIdx(src: UMat, flags: int, dst: UMat | None) -> UMat	
							spatialGradient(src: cv2.typing.MatLike, dx: cv2.typing.MatLike | None, dy: cv2.typing.MatLike | None, ksize: int, borderType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							spatialGradient(src: UMat, dx: UMat | None, dy: UMat | None, ksize: int, borderType: int) -> tuple[UMat, UMat]	
							split(m: cv2.typing.MatLike, mv: _typing.Sequence[cv2.typing.MatLike] | None) -> _typing.Sequence[cv2.typing.MatLike]	
							split(m: UMat, mv: _typing.Sequence[UMat] | None) -> _typing.Sequence[UMat]	
							sqrBoxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike	
							sqrBoxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat	
							sqrt(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sqrt(src: UMat, dst: UMat | None) -> UMat	
							stackBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							stackBlur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None) -> UMat	
							startWindowThread() -> int	
							stereoCalibrate(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike | None, T: cv2.typing.MatLike | None, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoCalibrate(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat | None, T: UMat | None, E: UMat | None, F: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	
							stereoCalibrate(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoCalibrate(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, E: UMat | None, F: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	
							stereoCalibrateExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	
							stereoCalibrateExtended(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, E: UMat | None, F: UMat | None, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	
							stereoRectify(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]	
							stereoRectify(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, R1: UMat | None, R2: UMat | None, P1: UMat | None, P2: UMat | None, Q: UMat | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]	
							stereoRectifyUncalibrated(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, F: cv2.typing.MatLike, imgSize: cv2.typing.Size, H1: cv2.typing.MatLike | None, H2: cv2.typing.MatLike | None, threshold: float) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoRectifyUncalibrated(points1: UMat, points2: UMat, F: UMat, imgSize: cv2.typing.Size, H1: UMat | None, H2: UMat | None, threshold: float) -> tuple[bool, UMat, UMat]	
							stylization(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	
							stylization(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat	
							subtract(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	
							subtract(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat	
							sumElems(src: cv2.typing.MatLike) -> cv2.typing.Scalar	
							sumElems(src: UMat) -> cv2.typing.Scalar	
							textureFlattening(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, low_threshold: float, high_threshold: float, kernel_size: int) -> cv2.typing.MatLike	
							textureFlattening(src: UMat, mask: UMat, dst: UMat | None, low_threshold: float, high_threshold: float, kernel_size: int) -> UMat	
							threshold(src: cv2.typing.MatLike, thresh: float, maxval: float, type: int, dst: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	
							threshold(src: UMat, thresh: float, maxval: float, type: int, dst: UMat | None) -> tuple[float, UMat]	
							trace(mtx: cv2.typing.MatLike) -> cv2.typing.Scalar	
							trace(mtx: UMat) -> cv2.typing.Scalar	
							transform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transform(src: UMat, m: UMat, dst: UMat | None) -> UMat	
							transpose(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transpose(src: UMat, dst: UMat | None) -> UMat	
							transposeND(src: cv2.typing.MatLike, order: _typing.Sequence[int], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transposeND(src: UMat, order: _typing.Sequence[int], dst: UMat | None) -> UMat	
							triangulatePoints(projMatr1: cv2.typing.MatLike, projMatr2: cv2.typing.MatLike, projPoints1: cv2.typing.MatLike, projPoints2: cv2.typing.MatLike, points4D: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							triangulatePoints(projMatr1: UMat, projMatr2: UMat, projPoints1: UMat, projPoints2: UMat, points4D: UMat | None) -> UMat	
							undistort(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, newCameraMatrix: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistort(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, newCameraMatrix: UMat | None) -> UMat	
							undistortImagePoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, arg1: cv2.typing.TermCriteria) -> cv2.typing.MatLike	
							undistortImagePoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, arg1: cv2.typing.TermCriteria) -> UMat	
							undistortPoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, P: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistortPoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, R: UMat | None, P: UMat | None) -> UMat	
							undistortPointsIter(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, P: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistortPointsIter(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, R: UMat, P: UMat, criteria: cv2.typing.TermCriteria, dst: UMat | None) -> UMat	
							useOpenVX() -> bool	
							useOptimized() -> bool	
							validateDisparity(disparity: cv2.typing.MatLike, cost: cv2.typing.MatLike, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> cv2.typing.MatLike	
							validateDisparity(disparity: UMat, cost: UMat, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> UMat	
							vconcat(src: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							vconcat(src: _typing.Sequence[UMat], dst: UMat | None) -> UMat	
							waitKey(delay: int) -> int	
							waitKeyEx(delay: int) -> int	
							warpAffine(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	
							warpAffine(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	
							warpPerspective(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	
							warpPerspective(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	
							warpPolar(src: cv2.typing.MatLike, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							warpPolar(src: UMat, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat	
							watershed(image: cv2.typing.MatLike, markers: cv2.typing.MatLike) -> cv2.typing.MatLike	
							watershed(image: UMat, markers: UMat) -> UMat	
							writeOpticalFlow(path: str, flow: cv2.typing.MatLike) -> bool	
							writeOpticalFlow(path: str, flow: UMat) -> bool	
							createTrackbar(trackbarName: str, windowName: str, value: int, count: int, onChange: _typing.Callable[[int], None]) -> None	
							createButton(buttonName: str, onChange: _typing.Callable[[tuple[int] | tuple[int, _typing.Any]], None], userData: _typing.Any | None, buttonType: int, initialButtonState: int) -> None	
							setMouseCallback(windowName: str, onMouse: _typing.Callable[[int, int, int, int, _typing.Any | None], None], param: _typing.Any | None) -> None	
							CV_8UC(channels: int) -> int	
							CV_8SC(channels: int) -> int	
							CV_16UC(channels: int) -> int	
							CV_16SC(channels: int) -> int	
							CV_32SC(channels: int) -> int	
							CV_32FC(channels: int) -> int	
							CV_64FC(channels: int) -> int	
							CV_16FC(channels: int) -> int	
							CV_MAKETYPE(depth: int, channels: int) -> int	
							dnn_registerLayer(layerTypeName: str, layerClass: _typing.Type[cv2.dnn.LayerProtocol]) -> None	
							dnn_unregisterLayer(layerTypeName: str) -> None	
							redirectError(onError: _typing.Callable[[int, str, str, str, int], None] | None) -> None	
