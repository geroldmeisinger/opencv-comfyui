params_types_unique	return_types_unique	image_types	images_types	unsupported_types	first_image_param_names	subsequent_image_param_names	signatures	signatures_filtered
ShapeTransformer	tuple[int, UMat, UMat, UMat]	UMat	_typing.Sequence[UMat]	_typing.Sequence	H	high	CamShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]	CamShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]
_typing.Callable[[tuple[int] | tuple[int, _typing.Any]], None]	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]	cv2.typing.MatLike	_typing.Sequence[cv2.typing.MatLiike]	_typing.Callable	dst	fgdModel	CamShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]	CamShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.RotatedRect, cv2.typing.Rect]
Animation	GeneralizedHoughBallard	cv2.typing.MatLike | None	_typing.Sequence[cv2.typing.Rect]	_typing.Type[cv2.dnn.LayerProtocol]	coeffs	P	Canny(image: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, apertureSize: int, L2gradient: bool) -> cv2.typing.MatLike	Canny(image: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, apertureSize: int, L2gradient: bool) -> cv2.typing.MatLike
_typing.Any | None	LineSegmentDetector	cv2.cuda.GpuMat	_typing.Sequence[cv2.typing.MatLike]	HistogramCostExtractor	flow	map2	Canny(image: UMat, threshold1: float, threshold2: float, edges: UMat | None, apertureSize: int, L2gradient: bool) -> UMat	Canny(image: UMat, threshold1: float, threshold2: float, edges: UMat | None, apertureSize: int, L2gradient: bool) -> UMat
_typing.Sequence[DMatch]	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]		_typing.Sequence[UMat] | None	ShapeTransformer	prev	Q	Canny(dx: cv2.typing.MatLike, dy: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, L2gradient: bool) -> cv2.typing.MatLike	Canny(dx: cv2.typing.MatLike, dy: cv2.typing.MatLike, threshold1: float, threshold2: float, edges: cv2.typing.MatLike | None, L2gradient: bool) -> cv2.typing.MatLike
RobotWorldHandEyeCalibrationMethod	tuple[float, float, cv2.typing.MatLike]			UsacParams	A	hist	Canny(dx: UMat, dy: UMat, threshold1: float, threshold2: float, edges: UMat | None, L2gradient: bool) -> UMat	Canny(dx: UMat, dy: UMat, threshold1: float, threshold2: float, edges: UMat | None, L2gradient: bool) -> UMat
UsacParams	tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]			Animation	v1	cost	EMD(signature1: cv2.typing.MatLike, signature2: cv2.typing.MatLike, distType: int, cost: cv2.typing.MatLike | None, lowerBound: float | None, flow: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.MatLike]	EMD(signature1: cv2.typing.MatLike, signature2: cv2.typing.MatLike, distType: int, cost: cv2.typing.MatLike | None, lowerBound: float | None, flow: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.MatLike]
cv2.cuda.GpuMat	cv2.typing.Moments			CirclesGridFinderParameters	point	dt3dr1	EMD(signature1: UMat, signature2: UMat, distType: int, cost: UMat | None, lowerBound: float | None, flow: UMat | None) -> tuple[float, float, UMat]	EMD(signature1: UMat, signature2: UMat, distType: int, cost: UMat | None, lowerBound: float | None, flow: UMat | None) -> tuple[float, float, UMat]
cv2.typing.MatLike	ShapeContextDistanceExtractor			cv2.typing.FeatureDetector	hist	imagePoints	GaussianBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, sigmaX: float, dst: cv2.typing.MatLike | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> cv2.typing.MatLike	GaussianBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, sigmaX: float, dst: cv2.typing.MatLike | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> cv2.typing.MatLike
_typing.Sequence[cv2.typing.MatLike] | None	CLAHE			AffineTransformer	Func	dist	GaussianBlur(src: UMat, ksize: cv2.typing.Size, sigmaX: float, dst: UMat | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> UMat	GaussianBlur(src: UMat, ksize: cv2.typing.Size, sigmaX: float, dst: UMat | None, sigmaY: float, borderType: int, hint: AlgorithmHint) -> UMat
bool	tuple[_typing.Sequence[UMat], UMat]			AlignMTB	signature1	mean	HoughCircles(image: cv2.typing.MatLike, method: int, dp: float, minDist: float, circles: cv2.typing.MatLike | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> cv2.typing.MatLike	HoughCircles(image: cv2.typing.MatLike, method: int, dp: float, minDist: float, circles: cv2.typing.MatLike | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> cv2.typing.MatLike
HistogramCostExtractor	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat]]			BackgroundSubtractorKNN	prevImg	centroids	HoughCircles(image: UMat, method: int, dp: float, minDist: float, circles: UMat | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> UMat	HoughCircles(image: UMat, method: int, dp: float, minDist: float, circles: UMat | None, param1: float, param2: float, minRadius: int, maxRadius: int) -> UMat
_typing.Sequence[str]	tuple[bool, UMat, UMat, UMat]			BackgroundSubtractorMOG2	points1	inliers	HoughLines(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> cv2.typing.MatLike	HoughLines(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> cv2.typing.MatLike
_typing.Sequence[_typing.Sequence[str]]	TonemapDrago			CalibrateDebevec	mtx	markers	HoughLines(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> UMat	HoughLines(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float, use_edgeval: bool) -> UMat
cv2.typing.Point2d	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat]]			CalibrateRobertson	src	window	HoughLinesP(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, minLineLength: float, maxLineGap: float) -> cv2.typing.MatLike	HoughLinesP(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, minLineLength: float, maxLineGap: float) -> cv2.typing.MatLike
_typing.Callable[[int, int, int, int, _typing.Any | None], None]	tuple[float, float, float, cv2.typing.Point2d, float]			CLAHE	buf	buf	HoughLinesP(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, minLineLength: float, maxLineGap: float) -> UMat	HoughLinesP(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, minLineLength: float, maxLineGap: float) -> UMat
cv2.typing.Rect2d	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]			GArrayDesc	w	P3	HoughLinesPointSet(point: cv2.typing.MatLike, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike	HoughLinesPointSet(point: cv2.typing.MatLike, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Moments	GeneralizedHoughGuil			GeneralizedHoughBallard	result	w	HoughLinesPointSet(point: UMat, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: UMat | None) -> UMat	HoughLinesPointSet(point: UMat, lines_max: int, threshold: int, min_rho: float, max_rho: float, rho_step: float, min_theta: float, max_theta: float, theta_step: float, lines: UMat | None) -> UMat
cv2.typing.FeatureDetector	tuple[cv2.typing.MatLike, cv2.typing.Rect]			GeneralizedHoughGuil	beforePoints	result	HoughLinesWithAccumulator(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float) -> cv2.typing.MatLike	HoughLinesWithAccumulator(image: cv2.typing.MatLike, rho: float, theta: float, threshold: int, lines: cv2.typing.MatLike | None, srn: float, stn: float, min_theta: float, max_theta: float) -> cv2.typing.MatLike
cv2.typing.Rect	None			GOpaqueDesc	objectPoints	pts2	HoughLinesWithAccumulator(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float) -> UMat	HoughLinesWithAccumulator(image: UMat, rho: float, theta: float, threshold: int, lines: UMat | None, srn: float, stn: float, min_theta: float, max_theta: float) -> UMat
float	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]			GScalarDesc	M	H2	HuMoments(m: cv2.typing.Moments, hu: cv2.typing.MatLike | None) -> cv2.typing.MatLike	HuMoments(m: cv2.typing.Moments, hu: cv2.typing.MatLike | None) -> cv2.typing.MatLike
_typing.Sequence[float]	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]			HausdorffDistanceExtractor	img1	R2	HuMoments(m: cv2.typing.Moments, hu: UMat | None) -> UMat	HuMoments(m: cv2.typing.Moments, hu: UMat | None) -> UMat
UMat	tuple[bool, UMat, UMat]			HistogramCostExtractor	dx	R1	LUT(src: cv2.typing.MatLike, lut: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	LUT(src: cv2.typing.MatLike, lut: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Scalar	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]			LineSegmentDetector	R_base2world	stddev	LUT(src: UMat, lut: UMat, dst: UMat | None) -> UMat	LUT(src: UMat, lut: UMat, dst: UMat | None) -> UMat
_typing.Sequence[_typing.Sequence[DMatch]]	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]			MergeDebevec	F	points	Laplacian(src: cv2.typing.MatLike, ddepth: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Laplacian(src: cv2.typing.MatLike, ddepth: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
str	GOpaqueDesc			MergeMertens	H1	R3	Laplacian(src: UMat, ddepth: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat	Laplacian(src: UMat, ddepth: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat
CirclesGridFinderParameters	CalibrateRobertson			MergeRobertson	projMatrix	rvec3	Mahalanobis(v1: cv2.typing.MatLike, v2: cv2.typing.MatLike, icovar: cv2.typing.MatLike) -> float	Mahalanobis(v1: cv2.typing.MatLike, v2: cv2.typing.MatLike, icovar: cv2.typing.MatLike) -> float
cv2.typing.RotatedRect	GScalarDesc			ShapeContextDistanceExtractor	R_cam2gripper	weights1	Mahalanobis(v1: UMat, v2: UMat, icovar: UMat) -> float	Mahalanobis(v1: UMat, v2: UMat, icovar: UMat) -> float
DrawMatchesFlags	_typing.Sequence[cv2.typing.MatLike]			ThinPlateSplineShapeTransformer	contour1	transVect	PCABackProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike	PCABackProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Size | None	tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]			Tonemap	data	triangulatedPoints	PCABackProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat	PCABackProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat
_typing.Sequence[UMat] | None	tuple[int, UMat, UMat, UMat, UMat]			TonemapDrago	src1	kernelY	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
HandEyeCalibrationMethod	MergeMertens			TonemapMantiuk	contour	b	PCACompute(data: UMat, mean: UMat, eigenvectors: UMat | None, maxComponents: int) -> tuple[UMat, UMat]	PCACompute(data: UMat, mean: UMat, eigenvectors: UMat | None, maxComponents: int) -> tuple[UMat, UMat]
int	tuple[UMat, UMat, UMat, UMat]			TonemapReinhard	intersectingRegion	dst1	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
AlgorithmHint	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]				array	color_boost	PCACompute(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None) -> tuple[UMat, UMat]	PCACompute(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None) -> tuple[UMat, UMat]
cv2.typing.Range	tuple[bool, cv2.typing.Point]				points	dr3dt1	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None, maxComponents: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Sequence[KeyPoint]	TonemapMantiuk				templateImage	possibleSolutions	PCACompute2(data: UMat, mean: UMat, eigenvectors: UMat | None, eigenvalues: UMat | None, maxComponents: int) -> tuple[UMat, UMat, UMat]	PCACompute2(data: UMat, mean: UMat, eigenvectors: UMat | None, eigenvalues: UMat | None, maxComponents: int) -> tuple[UMat, UMat, UMat]
_typing.Sequence[cv2.typing.Rect]	tuple[float, UMat, UMat]				mat	dt3dt2	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	PCACompute2(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, retainedVariance: float, eigenvectors: cv2.typing.MatLike | None, eigenvalues: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Type[cv2.dnn.LayerProtocol]	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				map1	rotMatrix	PCACompute2(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None, eigenvalues: UMat | None) -> tuple[UMat, UMat, UMat]	PCACompute2(data: UMat, mean: UMat, retainedVariance: float, eigenvectors: UMat | None, eigenvalues: UMat | None) -> tuple[UMat, UMat, UMat]
_typing.Sequence[int]	cv2.typing.MatLike				src2	T12	PCAProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike	PCAProject(data: cv2.typing.MatLike, mean: cv2.typing.MatLike, eigenvectors: cv2.typing.MatLike, result: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.Point2f	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				samples	status	PCAProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat	PCAProject(data: UMat, mean: UMat, eigenvectors: UMat, result: UMat | None) -> UMat
cv2.typing.Size	tuple[UMat, UMat, UMat]				p1	T	PSNR(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, R: float) -> float	PSNR(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, R: float) -> float
cv2.typing.Point	tuple[float, cv2.typing.MatLike]				projMatr1	inputMask	PSNR(src1: UMat, src2: UMat, R: float) -> float	PSNR(src1: UMat, src2: UMat, R: float) -> float
_typing.Callable[[int, str, str, str, int], None] | None	tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				rvec1	lowerb	RQDecomp3x3(src: cv2.typing.MatLike, mtxR: cv2.typing.MatLike | None, mtxQ: cv2.typing.MatLike | None, Qx: cv2.typing.MatLike | None, Qy: cv2.typing.MatLike | None, Qz: cv2.typing.MatLike | None) -> tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	RQDecomp3x3(src: cv2.typing.MatLike, mtxR: cv2.typing.MatLike | None, mtxQ: cv2.typing.MatLike | None, Qx: cv2.typing.MatLike | None, Qy: cv2.typing.MatLike | None, Qz: cv2.typing.MatLike | None) -> tuple[cv2.typing.Vec3d, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
cv2.typing.MatLike | None	tuple[int, _typing.Sequence[cv2.typing.MatLike]]				E	nextImg	RQDecomp3x3(src: UMat, mtxR: UMat | None, mtxQ: UMat | None, Qx: UMat | None, Qy: UMat | None, Qz: UMat | None) -> tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]	RQDecomp3x3(src: UMat, mtxR: UMat | None, mtxQ: UMat | None, Qx: UMat | None, Qy: UMat | None, Qz: UMat | None) -> tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]
UMat | None	MergeRobertson				probImage	rhs	Rodrigues(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	Rodrigues(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
_typing.Callable[[int], None]	tuple[int, cv2.typing.MatLike]				kx	grayscale	Rodrigues(src: UMat, dst: UMat | None, jacobian: UMat | None) -> tuple[UMat, UMat]	Rodrigues(src: UMat, dst: UMat | None, jacobian: UMat | None) -> tuple[UMat, UMat]
float | None	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]				x	p2	SVBackSubst(w: cv2.typing.MatLike, u: cv2.typing.MatLike, vt: cv2.typing.MatLike, rhs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	SVBackSubst(w: cv2.typing.MatLike, u: cv2.typing.MatLike, vt: cv2.typing.MatLike, rhs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
cv2.typing.TermCriteria	cv2.typing.Scalar				img	delta	SVBackSubst(w: UMat, u: UMat, vt: UMat, rhs: UMat, dst: UMat | None) -> UMat	SVBackSubst(w: UMat, u: UMat, vt: UMat, rhs: UMat, dst: UMat | None) -> UMat
_typing.Sequence[cv2.typing.MatLike]	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]				magnitude	Constr	SVDecomp(src: cv2.typing.MatLike, w: cv2.typing.MatLike | None, u: cv2.typing.MatLike | None, vt: cv2.typing.MatLike | None, flags: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	SVDecomp(src: cv2.typing.MatLike, w: cv2.typing.MatLike | None, u: cv2.typing.MatLike | None, vt: cv2.typing.MatLike | None, flags: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
SolvePnPMethod	str				pts1	reprojectionError	SVDecomp(src: UMat, w: UMat | None, u: UMat | None, vt: UMat | None, flags: int) -> tuple[UMat, UMat, UMat]	SVDecomp(src: UMat, w: UMat | None, u: UMat | None, vt: UMat | None, flags: int) -> tuple[UMat, UMat, UMat]
_typing.Sequence[UMat]	_typing.Sequence[cv2.typing.Point]				m	projMatr2	Scharr(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Scharr(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
	tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]				pt1	nidx	Scharr(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, scale: float, delta: float, borderType: int) -> UMat	Scharr(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, scale: float, delta: float, borderType: int) -> UMat
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]				srcPoints	err	Sobel(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike	Sobel(src: cv2.typing.MatLike, ddepth: int, dx: int, dy: int, dst: cv2.typing.MatLike | None, ksize: int, scale: float, delta: float, borderType: int) -> cv2.typing.MatLike
	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]				from_	tvec	Sobel(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat	Sobel(src: UMat, ddepth: int, dx: int, dy: int, dst: UMat | None, ksize: int, scale: float, delta: float, borderType: int) -> UMat
	tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]				disparity	hull	absdiff(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	absdiff(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]				a	rotMatrixY	absdiff(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	absdiff(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
	tuple[bool, Animation]				cameraMatrix1	iM	accumulate(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulate(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]				curve	R_gripper2cam	accumulate(src: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulate(src: UMat, dst: UMat, mask: UMat | None) -> UMat
	tuple[cv2.typing.RotatedRect, cv2.typing.Rect]				hu	eulerAngles	accumulateProduct(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateProduct(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]				cameraMatrix	P2	accumulateProduct(src1: UMat, src2: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulateProduct(src1: UMat, src2: UMat, dst: UMat, mask: UMat | None) -> UMat
	tuple[cv2.typing.MatLike, cv2.typing.MatLike]				image	kernelX	accumulateSquare(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateSquare(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	AffineTransformer				mask	circles	accumulateSquare(src: UMat, dst: UMat, mask: UMat | None) -> UMat	accumulateSquare(src: UMat, dst: UMat, mask: UMat | None) -> UMat
	tuple[cv2.typing.MatLike, float]					bgdModel	accumulateWeighted(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	accumulateWeighted(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, cv2.typing.Rect]					vt	accumulateWeighted(src: UMat, dst: UMat, alpha: float, mask: UMat | None) -> UMat	accumulateWeighted(src: UMat, dst: UMat, alpha: float, mask: UMat | None) -> UMat
	tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]					dy	adaptiveThreshold(src: cv2.typing.MatLike, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	adaptiveThreshold(src: cv2.typing.MatLike, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					Qy	adaptiveThreshold(src: UMat, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: UMat | None) -> UMat	adaptiveThreshold(src: UMat, maxValue: float, adaptiveMethod: int, thresholdType: int, blockSize: int, C: float, dst: UMat | None) -> UMat
	_typing.Sequence[UMat]					shape	add(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	add(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
	tuple[cv2.typing.Size, int]					t_cam2gripper	add(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat	add(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat
	tuple[cv2.typing.Point2d, float]					ky	addText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, nameFont: str, pointSize: int, color: cv2.typing.Scalar, weight: int, style: int, spacing: int) -> None	addText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, nameFont: str, pointSize: int, color: cv2.typing.Scalar, weight: int, style: int, spacing: int) -> None
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					dr3dr1	addWeighted(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, beta: float, gamma: float, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	addWeighted(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, beta: float, gamma: float, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
	tuple[float, float, UMat]					convexityDefects	addWeighted(src1: UMat, alpha: float, src2: UMat, beta: float, gamma: float, dst: UMat | None, dtype: int) -> UMat	addWeighted(src1: UMat, alpha: float, src2: UMat, beta: float, gamma: float, dst: UMat | None, dtype: int) -> UMat
	BackgroundSubtractorMOG2					v2	applyColorMap(src: cv2.typing.MatLike, colormap: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	applyColorMap(src: cv2.typing.MatLike, colormap: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], _typing.Sequence[UMat]]					stdDeviationsObjPoints	applyColorMap(src: UMat, colormap: int, dst: UMat | None) -> UMat	applyColorMap(src: UMat, colormap: int, dst: UMat | None) -> UMat
	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat, UMat, UMat]					dt3dr2	applyColorMap(src: cv2.typing.MatLike, userColor: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	applyColorMap(src: cv2.typing.MatLike, userColor: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					projPoints1	applyColorMap(src: UMat, userColor: UMat, dst: UMat | None) -> UMat	applyColorMap(src: UMat, userColor: UMat, dst: UMat | None) -> UMat
	tuple[int, _typing.Sequence[UMat]]					edges	approxPolyDP(curve: cv2.typing.MatLike, epsilon: float, closed: bool, approxCurve: cv2.typing.MatLike | None) -> cv2.typing.MatLike	approxPolyDP(curve: cv2.typing.MatLike, epsilon: float, closed: bool, approxCurve: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[bool, cv2.typing.MatLike]					H1	approxPolyDP(curve: UMat, epsilon: float, closed: bool, approxCurve: UMat | None) -> UMat	approxPolyDP(curve: UMat, epsilon: float, closed: bool, approxCurve: UMat | None) -> UMat
	bool					p12	approxPolyN(curve: cv2.typing.MatLike, nsides: int, approxCurve: cv2.typing.MatLike | None, epsilon_percentage: float, ensure_convex: bool) -> cv2.typing.MatLike	approxPolyN(curve: cv2.typing.MatLike, nsides: int, approxCurve: cv2.typing.MatLike | None, epsilon_percentage: float, ensure_convex: bool) -> cv2.typing.MatLike
	HistogramCostExtractor					newPoints2	approxPolyN(curve: UMat, nsides: int, approxCurve: UMat | None, epsilon_percentage: float, ensure_convex: bool) -> UMat	approxPolyN(curve: UMat, nsides: int, approxCurve: UMat | None, epsilon_percentage: float, ensure_convex: bool) -> UMat
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					tvec1	arcLength(curve: cv2.typing.MatLike, closed: bool) -> float	arcLength(curve: cv2.typing.MatLike, closed: bool) -> float
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]					patch	arcLength(curve: UMat, closed: bool) -> float	arcLength(curve: UMat, closed: bool) -> float
	cv2.typing.Rect					lines	arrowedLine(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> cv2.typing.MatLike	arrowedLine(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> cv2.typing.MatLike
	UMat					dr3dt2	arrowedLine(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> UMat	arrowedLine(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, line_type: int, shift: int, tipLength: float) -> UMat
	tuple[bool, UMat]					map1	batchDistance(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dtype: int, dist: cv2.typing.MatLike | None, nidx: cv2.typing.MatLike | None, normType: int, K: int, mask: cv2.typing.MatLike | None, update: int, crosscheck: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	batchDistance(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dtype: int, dist: cv2.typing.MatLike | None, nidx: cv2.typing.MatLike | None, normType: int, K: int, mask: cv2.typing.MatLike | None, update: int, crosscheck: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[bool, cv2.typing.Point, cv2.typing.Point]					nextPts	batchDistance(src1: UMat, src2: UMat, dtype: int, dist: UMat | None, nidx: UMat | None, normType: int, K: int, mask: UMat | None, update: int, crosscheck: bool) -> tuple[UMat, UMat]	batchDistance(src1: UMat, src2: UMat, dtype: int, dist: UMat | None, nidx: UMat | None, normType: int, K: int, mask: UMat | None, update: int, crosscheck: bool) -> tuple[UMat, UMat]
	tuple[bool, UMat, UMat, UMat, UMat]					distCoeffs	bilateralFilter(src: cv2.typing.MatLike, d: int, sigmaColor: float, sigmaSpace: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	bilateralFilter(src: cv2.typing.MatLike, d: int, sigmaColor: float, sigmaSpace: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
	int					rvec2	bilateralFilter(src: UMat, d: int, sigmaColor: float, sigmaSpace: float, dst: UMat | None, borderType: int) -> UMat	bilateralFilter(src: UMat, d: int, sigmaColor: float, sigmaSpace: float, dst: UMat | None, borderType: int) -> UMat
	TonemapReinhard					approxCurve	bitwise_and(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_and(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]					R12	bitwise_and(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_and(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	CalibrateDebevec					dist_coeff1	bitwise_not(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_not(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.Scalar, UMat]					prevPts	bitwise_not(src: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_not(src: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	HausdorffDistanceExtractor					E	bitwise_or(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_or(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	MergeDebevec					x	bitwise_or(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_or(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	tuple[cv2.typing.Scalar, cv2.typing.MatLike]					tvec2	bitwise_xor(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	bitwise_xor(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[float, UMat]					tilted	bitwise_xor(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat	bitwise_xor(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None) -> UMat
	tuple[float, float, cv2.typing.Point, cv2.typing.Point]					t_base2world	blendLinear(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, weights1: cv2.typing.MatLike, weights2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	blendLinear(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, weights1: cv2.typing.MatLike, weights2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]					cameraMatrix	blendLinear(src1: UMat, src2: UMat, weights1: UMat, weights2: UMat, dst: UMat | None) -> UMat	blendLinear(src1: UMat, src2: UMat, weights1: UMat, weights2: UMat, dst: UMat | None) -> UMat
	tuple[int, UMat, UMat, cv2.typing.Rect]					B	blur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, borderType: int) -> cv2.typing.MatLike	blur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, borderType: int) -> cv2.typing.MatLike
	tuple[int, UMat, UMat]					dstmap1	blur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, borderType: int) -> UMat	blur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, borderType: int) -> UMat
	Tonemap					mask	borderInterpolate(p: int, len: int, borderType: int) -> int	borderInterpolate(p: int, len: int, borderType: int) -> int
	BackgroundSubtractorKNN					distCoeffs2	boundingRect(array: cv2.typing.MatLike) -> cv2.typing.Rect	boundingRect(array: cv2.typing.MatLike) -> cv2.typing.Rect
	tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]					newObjPoints	boundingRect(array: UMat) -> cv2.typing.Rect	boundingRect(array: UMat) -> cv2.typing.Rect
	GArrayDesc					flow	boxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike	boxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike
	tuple[cv2.typing.Point2f, float]					bestLabels	boxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat	boxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat
	tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					distCoeffs3	boxPoints(box: cv2.typing.RotatedRect, points: cv2.typing.MatLike | None) -> cv2.typing.MatLike	boxPoints(box: cv2.typing.RotatedRect, points: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, UMat]					pointsMask	boxPoints(box: cv2.typing.RotatedRect, points: UMat | None) -> UMat	boxPoints(box: cv2.typing.RotatedRect, points: UMat | None) -> UMat
	tuple[bool, _typing.Sequence[cv2.typing.MatLike]]					line	broadcast(src: cv2.typing.MatLike, shape: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	broadcast(src: cv2.typing.MatLike, shape: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
	AlignMTB					points4D	broadcast(src: UMat, shape: UMat, dst: UMat | None) -> UMat	broadcast(src: UMat, shape: UMat, dst: UMat | None) -> UMat
	float					jacobian	buildOpticalFlowPyramid(img: cv2.typing.MatLike, winSize: cv2.typing.Size, maxLevel: int, pyramid: _typing.Sequence[cv2.typing.MatLike] | None, withDerivatives: bool, pyrBorder: int, derivBorder: int, tryReuseInputImage: bool) -> tuple[int, _typing.Sequence[cv2.typing.MatLike]]	calcCovarMatrix(samples: cv2.typing.MatLike, mean: cv2.typing.MatLike, flags: int, covar: cv2.typing.MatLike | None, ctype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					triangle	buildOpticalFlowPyramid(img: UMat, winSize: cv2.typing.Size, maxLevel: int, pyramid: _typing.Sequence[UMat] | None, withDerivatives: bool, pyrBorder: int, derivBorder: int, tryReuseInputImage: bool) -> tuple[int, _typing.Sequence[UMat]]	calcCovarMatrix(samples: UMat, mean: UMat, flags: int, covar: UMat | None, ctype: int) -> tuple[UMat, UMat]
	cv2.typing.RotatedRect					y	calcBackProject(images: _typing.Sequence[cv2.typing.MatLike], channels: _typing.Sequence[int], hist: cv2.typing.MatLike, ranges: _typing.Sequence[float], scale: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	calcOpticalFlowFarneback(prev: cv2.typing.MatLike, next: cv2.typing.MatLike, flow: cv2.typing.MatLike, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> cv2.typing.MatLike
	tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]					points1	calcBackProject(images: _typing.Sequence[UMat], channels: _typing.Sequence[int], hist: UMat, ranges: _typing.Sequence[float], scale: float, dst: UMat | None) -> UMat	calcOpticalFlowFarneback(prev: UMat, next: UMat, flow: UMat, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> UMat
	tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat]					t	calcCovarMatrix(samples: cv2.typing.MatLike, mean: cv2.typing.MatLike, flags: int, covar: cv2.typing.MatLike | None, ctype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	calcOpticalFlowPyrLK(prevImg: cv2.typing.MatLike, nextImg: cv2.typing.MatLike, prevPts: cv2.typing.MatLike, nextPts: cv2.typing.MatLike, status: cv2.typing.MatLike | None, err: cv2.typing.MatLike | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
	AlgorithmHint					next	calcCovarMatrix(samples: UMat, mean: UMat, flags: int, covar: UMat | None, ctype: int) -> tuple[UMat, UMat]	calcOpticalFlowPyrLK(prevImg: UMat, nextImg: UMat, prevPts: UMat, nextPts: UMat, status: UMat | None, err: UMat | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[UMat, UMat, UMat]
	_typing.Sequence[cv2.typing.Rect]					icovar	calcHist(images: _typing.Sequence[cv2.typing.MatLike], channels: _typing.Sequence[int], mask: cv2.typing.MatLike | None, histSize: _typing.Sequence[int], ranges: _typing.Sequence[float], hist: cv2.typing.MatLike | None, accumulate: bool) -> cv2.typing.MatLike	calibrationMatrixValues(cameraMatrix: cv2.typing.MatLike, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]
	tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]					distCoeffs1	calcHist(images: _typing.Sequence[UMat], channels: _typing.Sequence[int], mask: UMat | None, histSize: _typing.Sequence[int], ranges: _typing.Sequence[float], hist: UMat | None, accumulate: bool) -> UMat	calibrationMatrixValues(cameraMatrix: UMat, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]
	tuple[int, UMat]					cameraMatrix2	calcOpticalFlowFarneback(prev: cv2.typing.MatLike, next: cv2.typing.MatLike, flow: cv2.typing.MatLike, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> cv2.typing.MatLike	cartToPolar(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
	ThinPlateSplineShapeTransformer					dABdA	calcOpticalFlowFarneback(prev: UMat, next: UMat, flow: UMat, pyr_scale: float, levels: int, winsize: int, iterations: int, poly_n: int, poly_sigma: float, flags: int) -> UMat	cartToPolar(x: UMat, y: UMat, magnitude: UMat | None, angle: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]
	tuple[_typing.Sequence[cv2.typing.Rect], _typing.Sequence[int]]					outImage	calcOpticalFlowPyrLK(prevImg: cv2.typing.MatLike, nextImg: cv2.typing.MatLike, prevPts: cv2.typing.MatLike, nextPts: cv2.typing.MatLike, status: cv2.typing.MatLike | None, err: cv2.typing.MatLike | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	checkChessboard(img: cv2.typing.MatLike, size: cv2.typing.Size) -> bool
	tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]					perViewErrors	calcOpticalFlowPyrLK(prevImg: UMat, nextImg: UMat, prevPts: UMat, nextPts: UMat, status: UMat | None, err: UMat | None, winSize: cv2.typing.Size, maxLevel: int, criteria: cv2.typing.TermCriteria, flags: int, minEigThreshold: float) -> tuple[UMat, UMat, UMat]	checkChessboard(img: UMat, size: cv2.typing.Size) -> bool
	tuple[cv2.typing.Vec3d, UMat, UMat, UMat, UMat, UMat]					t_gripper2cam	calibrateCamera(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	checkHardwareSupport(feature: int) -> bool
	tuple[UMat, UMat]					_3dImage	calibrateCamera(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat]]	checkRange(a: cv2.typing.MatLike, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]
						F	calibrateCameraExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, stdDeviationsIntrinsics: cv2.typing.MatLike | None, stdDeviationsExtrinsics: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	checkRange(a: UMat, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]
						cameraMatrix3	calibrateCameraExtended(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, stdDeviationsIntrinsics: UMat | None, stdDeviationsExtrinsics: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat]	circle(img: cv2.typing.MatLike, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
						pt2	calibrateCameraRO(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, newObjPoints: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	circle(img: UMat, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
						Qx	calibrateCameraRO(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, newObjPoints: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	clipLine(imgRect: cv2.typing.Rect, pt1: cv2.typing.Point, pt2: cv2.typing.Point) -> tuple[bool, cv2.typing.Point, cv2.typing.Point]
						rotMatrixX	calibrateCameraROExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, newObjPoints: cv2.typing.MatLike | None, stdDeviationsIntrinsics: cv2.typing.MatLike | None, stdDeviationsExtrinsics: cv2.typing.MatLike | None, stdDeviationsObjPoints: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	colorChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, red_mul: float, green_mul: float, blue_mul: float) -> cv2.typing.MatLike
						inputImage	calibrateCameraROExtended(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, iFixedPoint: int, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, newObjPoints: UMat | None, stdDeviationsIntrinsics: UMat | None, stdDeviationsExtrinsics: UMat | None, stdDeviationsObjPoints: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat, UMat, UMat, UMat, UMat]	colorChange(src: UMat, mask: UMat, dst: UMat | None, red_mul: float, green_mul: float, blue_mul: float) -> UMat
						eigenvectors	calibrateHandEye(R_gripper2base: _typing.Sequence[cv2.typing.MatLike], t_gripper2base: _typing.Sequence[cv2.typing.MatLike], R_target2cam: _typing.Sequence[cv2.typing.MatLike], t_target2cam: _typing.Sequence[cv2.typing.MatLike], R_cam2gripper: cv2.typing.MatLike | None, t_cam2gripper: cv2.typing.MatLike | None, method: HandEyeCalibrationMethod) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	compare(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, cmpop: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						kernel	calibrateHandEye(R_gripper2base: _typing.Sequence[UMat], t_gripper2base: _typing.Sequence[UMat], R_target2cam: _typing.Sequence[UMat], t_target2cam: _typing.Sequence[UMat], R_cam2gripper: UMat | None, t_cam2gripper: UMat | None, method: HandEyeCalibrationMethod) -> tuple[UMat, UMat]	compare(src1: UMat, src2: UMat, cmpop: int, dst: UMat | None) -> UMat
						idx	calibrateRobotWorldHandEye(R_world2cam: _typing.Sequence[cv2.typing.MatLike], t_world2cam: _typing.Sequence[cv2.typing.MatLike], R_base2gripper: _typing.Sequence[cv2.typing.MatLike], t_base2gripper: _typing.Sequence[cv2.typing.MatLike], R_base2world: cv2.typing.MatLike | None, t_base2world: cv2.typing.MatLike | None, R_gripper2cam: cv2.typing.MatLike | None, t_gripper2cam: cv2.typing.MatLike | None, method: RobotWorldHandEyeCalibrationMethod) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	compareHist(H1: cv2.typing.MatLike, H2: cv2.typing.MatLike, method: int) -> float
						R13	calibrateRobotWorldHandEye(R_world2cam: _typing.Sequence[UMat], t_world2cam: _typing.Sequence[UMat], R_base2gripper: _typing.Sequence[UMat], t_base2gripper: _typing.Sequence[UMat], R_base2world: UMat | None, t_base2world: UMat | None, R_gripper2cam: UMat | None, t_gripper2cam: UMat | None, method: RobotWorldHandEyeCalibrationMethod) -> tuple[UMat, UMat, UMat, UMat]	compareHist(H1: UMat, H2: UMat, method: int) -> float
						meta	calibrationMatrixValues(cameraMatrix: cv2.typing.MatLike, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]	completeSymm(m: cv2.typing.MatLike, lowerToUpper: bool) -> cv2.typing.MatLike
						mtxR	calibrationMatrixValues(cameraMatrix: UMat, imageSize: cv2.typing.Size, apertureWidth: float, apertureHeight: float) -> tuple[float, float, float, cv2.typing.Point2d, float]	completeSymm(m: UMat, lowerToUpper: bool) -> UMat
						rotMatrixZ	cartToPolar(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	composeRT(rvec1: cv2.typing.MatLike, tvec1: cv2.typing.MatLike, rvec2: cv2.typing.MatLike, tvec2: cv2.typing.MatLike, rvec3: cv2.typing.MatLike | None, tvec3: cv2.typing.MatLike | None, dr3dr1: cv2.typing.MatLike | None, dr3dt1: cv2.typing.MatLike | None, dr3dr2: cv2.typing.MatLike | None, dr3dt2: cv2.typing.MatLike | None, dt3dr1: cv2.typing.MatLike | None, dt3dt1: cv2.typing.MatLike | None, dt3dr2: cv2.typing.MatLike | None, dt3dt2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						lut	cartToPolar(x: UMat, y: UMat, magnitude: UMat | None, angle: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]	composeRT(rvec1: UMat, tvec1: UMat, rvec2: UMat, tvec2: UMat, rvec3: UMat | None, tvec3: UMat | None, dr3dr1: UMat | None, dr3dt1: UMat | None, dr3dr2: UMat | None, dr3dt2: UMat | None, dt3dr1: UMat | None, dt3dt1: UMat | None, dt3dr2: UMat | None, dt3dt2: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]
						userColor	checkChessboard(img: cv2.typing.MatLike, size: cv2.typing.Size) -> bool	computeCorrespondEpilines(points: cv2.typing.MatLike, whichImage: int, F: cv2.typing.MatLike, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						magnitude	checkChessboard(img: UMat, size: cv2.typing.Size) -> bool	computeCorrespondEpilines(points: UMat, whichImage: int, F: UMat, lines: UMat | None) -> UMat
						out	checkHardwareSupport(feature: int) -> bool	computeECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, inputMask: cv2.typing.MatLike | None) -> float
						points2	checkRange(a: cv2.typing.MatLike, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]	computeECC(templateImage: UMat, inputImage: UMat, inputMask: UMat | None) -> float
						m	checkRange(a: UMat, quiet: bool, minVal: float, maxVal: float) -> tuple[bool, cv2.typing.Point]	connectedComponents(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike]
						low	circle(img: cv2.typing.MatLike, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	connectedComponents(image: UMat, labels: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat]
						src3	circle(img: UMat, center: cv2.typing.Point, radius: int, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	connectedComponentsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
						centers	clipLine(imgRect: cv2.typing.Rect, pt1: cv2.typing.Point, pt2: cv2.typing.Point) -> tuple[bool, cv2.typing.Point, cv2.typing.Point]	connectedComponentsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None) -> tuple[int, UMat]
						dist_coeff2	colorChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, red_mul: float, green_mul: float, blue_mul: float) -> cv2.typing.MatLike	connectedComponentsWithStats(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						dstmap2	colorChange(src: UMat, mask: UMat, dst: UMat | None, red_mul: float, green_mul: float, blue_mul: float) -> UMat	connectedComponentsWithStats(image: UMat, labels: UMat | None, stats: UMat | None, centroids: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat, UMat, UMat]
						sharpness	compare(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, cmpop: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	connectedComponentsWithStatsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						roots	compare(src1: UMat, src2: UMat, cmpop: int, dst: UMat | None) -> UMat	connectedComponentsWithStatsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None, stats: UMat | None, centroids: UMat | None) -> tuple[int, UMat, UMat, UMat]
						dst	compareHist(H1: cv2.typing.MatLike, H2: cv2.typing.MatLike, method: int) -> float	contourArea(contour: cv2.typing.MatLike, oriented: bool) -> float
						c	compareHist(H1: UMat, H2: UMat, method: int) -> float	contourArea(contour: UMat, oriented: bool) -> float
						z	completeSymm(m: cv2.typing.MatLike, lowerToUpper: bool) -> cv2.typing.MatLike	convertFp16(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						signature2	completeSymm(m: UMat, lowerToUpper: bool) -> UMat	convertFp16(src: UMat, dst: UMat | None) -> UMat
						to	composeRT(rvec1: cv2.typing.MatLike, tvec1: cv2.typing.MatLike, rvec2: cv2.typing.MatLike, tvec2: cv2.typing.MatLike, rvec3: cv2.typing.MatLike | None, tvec3: cv2.typing.MatLike | None, dr3dr1: cv2.typing.MatLike | None, dr3dt1: cv2.typing.MatLike | None, dr3dr2: cv2.typing.MatLike | None, dr3dt2: cv2.typing.MatLike | None, dt3dr1: cv2.typing.MatLike | None, dt3dt1: cv2.typing.MatLike | None, dt3dr2: cv2.typing.MatLike | None, dt3dt2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	convertMaps(map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, dstmap1type: int, dstmap1: cv2.typing.MatLike | None, dstmap2: cv2.typing.MatLike | None, nninterpolation: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
						covar	composeRT(rvec1: UMat, tvec1: UMat, rvec2: UMat, tvec2: UMat, rvec3: UMat | None, tvec3: UMat | None, dr3dr1: UMat | None, dr3dt1: UMat | None, dr3dr2: UMat | None, dr3dt2: UMat | None, dt3dr1: UMat | None, dt3dt1: UMat | None, dt3dr2: UMat | None, dt3dt2: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	convertMaps(map1: UMat, map2: UMat, dstmap1type: int, dstmap1: UMat | None, dstmap2: UMat | None, nninterpolation: bool) -> tuple[UMat, UMat]
						K	computeCorrespondEpilines(points: cv2.typing.MatLike, whichImage: int, F: cv2.typing.MatLike, lines: cv2.typing.MatLike | None) -> cv2.typing.MatLike	convertPointsFromHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						sqsum	computeCorrespondEpilines(points: UMat, whichImage: int, F: UMat, lines: UMat | None) -> UMat	convertPointsFromHomogeneous(src: UMat, dst: UMat | None) -> UMat
						angle	computeECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, inputMask: cv2.typing.MatLike | None) -> float	convertPointsToHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						corners	computeECC(templateImage: UMat, inputImage: UMat, inputMask: UMat | None) -> float	convertPointsToHomogeneous(src: UMat, dst: UMat | None) -> UMat
						P1	connectedComponents(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike]	convertScaleAbs(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike
						dstPoints	connectedComponents(image: UMat, labels: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat]	convertScaleAbs(src: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat
						dt3dt1	connectedComponentsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	convexHull(points: cv2.typing.MatLike, hull: cv2.typing.MatLike | None, clockwise: bool, returnPoints: bool) -> cv2.typing.MatLike
						stdDeviationsExtrinsics	connectedComponentsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None) -> tuple[int, UMat]	convexHull(points: UMat, hull: UMat | None, clockwise: bool, returnPoints: bool) -> UMat
						inpaintMask	connectedComponentsWithStats(image: cv2.typing.MatLike, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None, connectivity: int, ltype: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	convexityDefects(contour: cv2.typing.MatLike, convexhull: cv2.typing.MatLike, convexityDefects: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						img2	connectedComponentsWithStats(image: UMat, labels: UMat | None, stats: UMat | None, centroids: UMat | None, connectivity: int, ltype: int) -> tuple[int, UMat, UMat, UMat]	convexityDefects(contour: UMat, convexhull: UMat, convexityDefects: UMat | None) -> UMat
						stats	connectedComponentsWithStatsWithAlgorithm(image: cv2.typing.MatLike, connectivity: int, ltype: int, ccltype: int, labels: cv2.typing.MatLike | None, stats: cv2.typing.MatLike | None, centroids: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	copyMakeBorder(src: cv2.typing.MatLike, top: int, bottom: int, left: int, right: int, borderType: int, dst: cv2.typing.MatLike | None, value: cv2.typing.Scalar) -> cv2.typing.MatLike
						warpMatrix	connectedComponentsWithStatsWithAlgorithm(image: UMat, connectivity: int, ltype: int, ccltype: int, labels: UMat | None, stats: UMat | None, centroids: UMat | None) -> tuple[int, UMat, UMat, UMat]	copyMakeBorder(src: UMat, top: int, bottom: int, left: int, right: int, borderType: int, dst: UMat | None, value: cv2.typing.Scalar) -> UMat
						dst2	contourArea(contour: cv2.typing.MatLike, oriented: bool) -> float	copyTo(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						labels	contourArea(contour: UMat, oriented: bool) -> float	copyTo(src: UMat, mask: UMat, dst: UMat | None) -> UMat
						dx	convertFp16(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerEigenValsAndVecs(src: cv2.typing.MatLike, blockSize: int, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
						M	convertFp16(src: UMat, dst: UMat | None) -> UMat	cornerEigenValsAndVecs(src: UMat, blockSize: int, ksize: int, dst: UMat | None, borderType: int) -> UMat
						weights2	convertMaps(map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, dstmap1type: int, dstmap1: cv2.typing.MatLike | None, dstmap2: cv2.typing.MatLike | None, nninterpolation: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	cornerHarris(src: cv2.typing.MatLike, blockSize: int, ksize: int, k: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
						T13	convertMaps(map1: UMat, map2: UMat, dstmap1type: int, dstmap1: UMat | None, dstmap2: UMat | None, nninterpolation: bool) -> tuple[UMat, UMat]	cornerHarris(src: UMat, blockSize: int, ksize: int, k: float, dst: UMat | None, borderType: int) -> UMat
						newCameraMatrix	convertPointsFromHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerMinEigenVal(src: cv2.typing.MatLike, blockSize: int, dst: cv2.typing.MatLike | None, ksize: int, borderType: int) -> cv2.typing.MatLike
						afterPoints	convertPointsFromHomogeneous(src: UMat, dst: UMat | None) -> UMat	cornerMinEigenVal(src: UMat, blockSize: int, dst: UMat | None, ksize: int, borderType: int) -> UMat
						dABdB	convertPointsToHomogeneous(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cornerSubPix(image: cv2.typing.MatLike, corners: cv2.typing.MatLike, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> cv2.typing.MatLike
						dr3dr2	convertPointsToHomogeneous(src: UMat, dst: UMat | None) -> UMat	cornerSubPix(image: UMat, corners: UMat, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> UMat
						outImg	convertScaleAbs(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike	correctMatches(F: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, newPoints1: cv2.typing.MatLike | None, newPoints2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
						src2	convertScaleAbs(src: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat	correctMatches(F: UMat, points1: UMat, points2: UMat, newPoints1: UMat | None, newPoints2: UMat | None) -> tuple[UMat, UMat]
						rvec	convexHull(points: cv2.typing.MatLike, hull: cv2.typing.MatLike | None, clockwise: bool, returnPoints: bool) -> cv2.typing.MatLike	countNonZero(src: cv2.typing.MatLike) -> int
						templ	convexHull(points: UMat, hull: UMat | None, clockwise: bool, returnPoints: bool) -> UMat	countNonZero(src: UMat) -> int
						stdDeviationsIntrinsics	convexityDefects(contour: cv2.typing.MatLike, convexhull: cv2.typing.MatLike, convexityDefects: cv2.typing.MatLike | None) -> cv2.typing.MatLike	createHanningWindow(winSize: cv2.typing.Size, type: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
						sum	convexityDefects(contour: UMat, convexhull: UMat, convexityDefects: UMat | None) -> UMat	createHanningWindow(winSize: cv2.typing.Size, type: int, dst: UMat | None) -> UMat
						contour2	copyMakeBorder(src: cv2.typing.MatLike, top: int, bottom: int, left: int, right: int, borderType: int, dst: cv2.typing.MatLike | None, value: cv2.typing.Scalar) -> cv2.typing.MatLike	cubeRoot(val: float) -> float
						u	copyMakeBorder(src: UMat, top: int, bottom: int, left: int, right: int, borderType: int, dst: UMat | None, value: cv2.typing.Scalar) -> UMat	currentUIFramework() -> str
						eigenvalues	copyTo(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	cvtColor(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int, hint: AlgorithmHint) -> cv2.typing.MatLike
						R	copyTo(src: UMat, mask: UMat, dst: UMat | None) -> UMat	cvtColor(src: UMat, code: int, dst: UMat | None, dstCn: int, hint: AlgorithmHint) -> UMat
						newPoints1	cornerEigenValsAndVecs(src: cv2.typing.MatLike, blockSize: int, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	cvtColorTwoPlane(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, hint: AlgorithmHint) -> cv2.typing.MatLike
						Qz	cornerEigenValsAndVecs(src: UMat, blockSize: int, ksize: int, dst: UMat | None, borderType: int) -> UMat	cvtColorTwoPlane(src1: UMat, src2: UMat, code: int, dst: UMat | None, hint: AlgorithmHint) -> UMat
						mtxQ	cornerHarris(src: cv2.typing.MatLike, blockSize: int, ksize: int, k: float, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	dct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
						tvec3	cornerHarris(src: UMat, blockSize: int, ksize: int, k: float, dst: UMat | None, borderType: int) -> UMat	dct(src: UMat, dst: UMat | None, flags: int) -> UMat
						cameraMatrix1	cornerMinEigenVal(src: cv2.typing.MatLike, blockSize: int, dst: cv2.typing.MatLike | None, ksize: int, borderType: int) -> cv2.typing.MatLike	decolor(src: cv2.typing.MatLike, grayscale: cv2.typing.MatLike | None, color_boost: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
						projPoints2	cornerMinEigenVal(src: UMat, blockSize: int, dst: UMat | None, ksize: int, borderType: int) -> UMat	decolor(src: UMat, grayscale: UMat | None, color_boost: UMat | None) -> tuple[UMat, UMat]
						convexhull	cornerSubPix(image: cv2.typing.MatLike, corners: cv2.typing.MatLike, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> cv2.typing.MatLike	decomposeEssentialMat(E: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						cornersQuality	cornerSubPix(image: UMat, corners: UMat, winSize: cv2.typing.Size, zeroZone: cv2.typing.Size, criteria: cv2.typing.TermCriteria) -> UMat	decomposeEssentialMat(E: UMat, R1: UMat | None, R2: UMat | None, t: UMat | None) -> tuple[UMat, UMat, UMat]
						blend	correctMatches(F: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, newPoints1: cv2.typing.MatLike | None, newPoints2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	decomposeProjectionMatrix(projMatrix: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike | None, rotMatrix: cv2.typing.MatLike | None, transVect: cv2.typing.MatLike | None, rotMatrixX: cv2.typing.MatLike | None, rotMatrixY: cv2.typing.MatLike | None, rotMatrixZ: cv2.typing.MatLike | None, eulerAngles: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
						upperb	correctMatches(F: UMat, points1: UMat, points2: UMat, newPoints1: UMat | None, newPoints2: UMat | None) -> tuple[UMat, UMat]	decomposeProjectionMatrix(projMatrix: UMat, cameraMatrix: UMat | None, rotMatrix: UMat | None, transVect: UMat | None, rotMatrixX: UMat | None, rotMatrixY: UMat | None, rotMatrixZ: UMat | None, eulerAngles: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]
						hierarchy	countNonZero(src: cv2.typing.MatLike) -> int	demosaicing(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int) -> cv2.typing.MatLike
							countNonZero(src: UMat) -> int	demosaicing(src: UMat, code: int, dst: UMat | None, dstCn: int) -> UMat
							createAffineTransformer(fullAffine: bool) -> AffineTransformer	destroyAllWindows() -> None
							createAlignMTB(max_bits: int, exclude_range: int, cut: bool) -> AlignMTB	destroyWindow(winname: str) -> None
							createBackgroundSubtractorKNN(history: int, dist2Threshold: float, detectShadows: bool) -> BackgroundSubtractorKNN	detailEnhance(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							createBackgroundSubtractorMOG2(history: int, varThreshold: float, detectShadows: bool) -> BackgroundSubtractorMOG2	detailEnhance(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat
							createCLAHE(clipLimit: float, tileGridSize: cv2.typing.Size) -> CLAHE	determinant(mtx: cv2.typing.MatLike) -> float
							createCalibrateDebevec(samples: int, lambda_: float, random: bool) -> CalibrateDebevec	determinant(mtx: UMat) -> float
							createCalibrateRobertson(max_iter: int, threshold: float) -> CalibrateRobertson	dft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike
							createChiHistogramCostExtractor(nDummies: int, defaultCost: float) -> HistogramCostExtractor	dft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat
							createEMDHistogramCostExtractor(flag: int, nDummies: int, defaultCost: float) -> HistogramCostExtractor	dilate(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							createEMDL1HistogramCostExtractor(nDummies: int, defaultCost: float) -> HistogramCostExtractor	dilate(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							createGeneralizedHoughBallard() -> GeneralizedHoughBallard	displayOverlay(winname: str, text: str, delayms: int) -> None
							createGeneralizedHoughGuil() -> GeneralizedHoughGuil	displayStatusBar(winname: str, text: str, delayms: int) -> None
							createHanningWindow(winSize: cv2.typing.Size, type: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	distanceTransform(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, dstType: int) -> cv2.typing.MatLike
							createHanningWindow(winSize: cv2.typing.Size, type: int, dst: UMat | None) -> UMat	distanceTransform(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, dstType: int) -> UMat
							createHausdorffDistanceExtractor(distanceFlag: int, rankProp: float) -> HausdorffDistanceExtractor	distanceTransformWithLabels(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, labels: cv2.typing.MatLike | None, labelType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							createLineSegmentDetector(refine: int, scale: float, sigma_scale: float, quant: float, ang_th: float, log_eps: float, density_th: float, n_bins: int) -> LineSegmentDetector	distanceTransformWithLabels(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, labels: UMat | None, labelType: int) -> tuple[UMat, UMat]
							createMergeDebevec() -> MergeDebevec	divSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike
							createMergeMertens(contrast_weight: float, saturation_weight: float, exposure_weight: float) -> MergeMertens	divSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat
							createMergeRobertson() -> MergeRobertson	divide(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							createNormHistogramCostExtractor(flag: int, nDummies: int, defaultCost: float) -> HistogramCostExtractor	divide(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat
							createShapeContextDistanceExtractor(nAngularBins: int, nRadialBins: int, innerRadius: float, outerRadius: float, iterations: int, comparer: HistogramCostExtractor, transformer: ShapeTransformer) -> ShapeContextDistanceExtractor	divide(scale: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							createThinPlateSplineShapeTransformer(regularizationParameter: float) -> ThinPlateSplineShapeTransformer	divide(scale: float, src2: UMat, dst: UMat | None, dtype: int) -> UMat
							createTonemap(gamma: float) -> Tonemap	drawChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, patternWasFound: bool) -> cv2.typing.MatLike
							createTonemapDrago(gamma: float, saturation: float, bias: float) -> TonemapDrago	drawChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat, patternWasFound: bool) -> UMat
							createTonemapMantiuk(gamma: float, scale: float, saturation: float) -> TonemapMantiuk	drawFrameAxes(image: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, length: float, thickness: int) -> cv2.typing.MatLike
							createTonemapReinhard(gamma: float, intensity: float, light_adapt: float, color_adapt: float) -> TonemapReinhard	drawFrameAxes(image: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, length: float, thickness: int) -> UMat
							cubeRoot(val: float) -> float	drawMarker(img: cv2.typing.MatLike, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> cv2.typing.MatLike
							currentUIFramework() -> str	drawMarker(img: UMat, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> UMat
							cvtColor(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int, hint: AlgorithmHint) -> cv2.typing.MatLike	edgePreservingFilter(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							cvtColor(src: UMat, code: int, dst: UMat | None, dstCn: int, hint: AlgorithmHint) -> UMat	edgePreservingFilter(src: UMat, dst: UMat | None, flags: int, sigma_s: float, sigma_r: float) -> UMat
							cvtColorTwoPlane(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, hint: AlgorithmHint) -> cv2.typing.MatLike	eigen(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							cvtColorTwoPlane(src1: UMat, src2: UMat, code: int, dst: UMat | None, hint: AlgorithmHint) -> UMat	eigen(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[bool, UMat, UMat]
							dct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	eigenNonSymmetric(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							dct(src: UMat, dst: UMat | None, flags: int) -> UMat	eigenNonSymmetric(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[UMat, UMat]
							decolor(src: cv2.typing.MatLike, grayscale: cv2.typing.MatLike | None, color_boost: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	ellipse(img: cv2.typing.MatLike, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							decolor(src: UMat, grayscale: UMat | None, color_boost: UMat | None) -> tuple[UMat, UMat]	ellipse(img: UMat, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							decomposeEssentialMat(E: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	ellipse(img: cv2.typing.MatLike, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> cv2.typing.MatLike
							decomposeEssentialMat(E: UMat, R1: UMat | None, R2: UMat | None, t: UMat | None) -> tuple[UMat, UMat, UMat]	ellipse(img: UMat, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> UMat
							decomposeHomographyMat(H: cv2.typing.MatLike, K: cv2.typing.MatLike, rotations: _typing.Sequence[cv2.typing.MatLike] | None, translations: _typing.Sequence[cv2.typing.MatLike] | None, normals: _typing.Sequence[cv2.typing.MatLike] | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	equalizeHist(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							decomposeHomographyMat(H: UMat, K: UMat, rotations: _typing.Sequence[UMat] | None, translations: _typing.Sequence[UMat] | None, normals: _typing.Sequence[UMat] | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], _typing.Sequence[UMat]]	equalizeHist(src: UMat, dst: UMat | None) -> UMat
							decomposeProjectionMatrix(projMatrix: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike | None, rotMatrix: cv2.typing.MatLike | None, transVect: cv2.typing.MatLike | None, rotMatrixX: cv2.typing.MatLike | None, rotMatrixY: cv2.typing.MatLike | None, rotMatrixZ: cv2.typing.MatLike | None, eulerAngles: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	erode(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							decomposeProjectionMatrix(projMatrix: UMat, cameraMatrix: UMat | None, rotMatrix: UMat | None, transVect: UMat | None, rotMatrixX: UMat | None, rotMatrixY: UMat | None, rotMatrixZ: UMat | None, eulerAngles: UMat | None) -> tuple[UMat, UMat, UMat, UMat, UMat, UMat, UMat]	erode(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							demosaicing(src: cv2.typing.MatLike, code: int, dst: cv2.typing.MatLike | None, dstCn: int) -> cv2.typing.MatLike	estimateAffine2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							demosaicing(src: UMat, code: int, dst: UMat | None, dstCn: int) -> UMat	estimateAffine2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]
							denoise_TVL1(observations: _typing.Sequence[cv2.typing.MatLike], result: cv2.typing.MatLike, lambda_: float, niters: int) -> None	estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]
							destroyAllWindows() -> None	estimateAffine3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]
							destroyWindow(winname: str) -> None	estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]
							detailEnhance(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	estimateAffine3D(src: UMat, dst: UMat, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]
							detailEnhance(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat	estimateAffinePartial2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							determinant(mtx: cv2.typing.MatLike) -> float	estimateAffinePartial2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]
							determinant(mtx: UMat) -> float	estimateChessboardSharpness(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, rise_distance: float, vertical: bool, sharpness: cv2.typing.MatLike | None) -> tuple[cv2.typing.Scalar, cv2.typing.MatLike]
							dft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike	estimateChessboardSharpness(image: UMat, patternSize: cv2.typing.Size, corners: UMat, rise_distance: float, vertical: bool, sharpness: UMat | None) -> tuple[cv2.typing.Scalar, UMat]
							dft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat	estimateTranslation3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]
							dilate(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	estimateTranslation3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]
							dilate(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	exp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							displayOverlay(winname: str, text: str, delayms: int) -> None	exp(src: UMat, dst: UMat | None) -> UMat
							displayStatusBar(winname: str, text: str, delayms: int) -> None	extractChannel(src: cv2.typing.MatLike, coi: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							distanceTransform(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, dstType: int) -> cv2.typing.MatLike	extractChannel(src: UMat, coi: int, dst: UMat | None) -> UMat
							distanceTransform(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, dstType: int) -> UMat	fastAtan2(y: float, x: float) -> float
							distanceTransformWithLabels(src: cv2.typing.MatLike, distanceType: int, maskSize: int, dst: cv2.typing.MatLike | None, labels: cv2.typing.MatLike | None, labelType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	fastNlMeansDenoising(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike
							distanceTransformWithLabels(src: UMat, distanceType: int, maskSize: int, dst: UMat | None, labels: UMat | None, labelType: int) -> tuple[UMat, UMat]	fastNlMeansDenoising(src: UMat, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat
							divSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike	fastNlMeansDenoisingColored(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike
							divSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat	fastNlMeansDenoisingColored(src: UMat, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat
							divide(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	fillConvexPoly(img: cv2.typing.MatLike, points: cv2.typing.MatLike, color: cv2.typing.Scalar, lineType: int, shift: int) -> cv2.typing.MatLike
							divide(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat	fillConvexPoly(img: UMat, points: UMat, color: cv2.typing.Scalar, lineType: int, shift: int) -> UMat
							divide(scale: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	filter2D(src: cv2.typing.MatLike, ddepth: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike
							divide(scale: float, src2: UMat, dst: UMat | None, dtype: int) -> UMat	filter2D(src: UMat, ddepth: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat
							drawChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, patternWasFound: bool) -> cv2.typing.MatLike	filterSpeckles(img: cv2.typing.MatLike, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							drawChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat, patternWasFound: bool) -> UMat	filterSpeckles(img: UMat, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: UMat | None) -> tuple[UMat, UMat]
							drawContours(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike], contourIdx: int, color: cv2.typing.Scalar, thickness: int, lineType: int, hierarchy: cv2.typing.MatLike | None, maxLevel: int, offset: cv2.typing.Point) -> cv2.typing.MatLike	find4QuadCornerSubpix(img: cv2.typing.MatLike, corners: cv2.typing.MatLike, region_size: cv2.typing.Size) -> tuple[bool, cv2.typing.MatLike]
							drawContours(image: UMat, contours: _typing.Sequence[UMat], contourIdx: int, color: cv2.typing.Scalar, thickness: int, lineType: int, hierarchy: UMat | None, maxLevel: int, offset: cv2.typing.Point) -> UMat	find4QuadCornerSubpix(img: UMat, corners: UMat, region_size: cv2.typing.Size) -> tuple[bool, UMat]
							drawFrameAxes(image: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, length: float, thickness: int) -> cv2.typing.MatLike	findChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							drawFrameAxes(image: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, length: float, thickness: int) -> UMat	findChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]
							drawKeypoints(image: cv2.typing.MatLike, keypoints: _typing.Sequence[KeyPoint], outImage: cv2.typing.MatLike, color: cv2.typing.Scalar, flags: DrawMatchesFlags) -> cv2.typing.MatLike	findChessboardCornersSB(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							drawKeypoints(image: UMat, keypoints: _typing.Sequence[KeyPoint], outImage: UMat, color: cv2.typing.Scalar, flags: DrawMatchesFlags) -> UMat	findChessboardCornersSB(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]
							drawMarker(img: cv2.typing.MatLike, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> cv2.typing.MatLike	findChessboardCornersSBWithMeta(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, corners: cv2.typing.MatLike | None, meta: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							drawMarker(img: UMat, position: cv2.typing.Point, color: cv2.typing.Scalar, markerType: int, markerSize: int, thickness: int, line_type: int) -> UMat	findChessboardCornersSBWithMeta(image: UMat, patternSize: cv2.typing.Size, flags: int, corners: UMat | None, meta: UMat | None) -> tuple[bool, UMat, UMat]
							drawMatches(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: cv2.typing.MatLike, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> cv2.typing.MatLike	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							drawMatches(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: UMat, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> UMat	findEssentialMat(points1: UMat, points2: UMat, cameraMatrix: UMat, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							drawMatches(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: cv2.typing.MatLike, matchesThickness: int, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> cv2.typing.MatLike	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							drawMatches(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[DMatch], outImg: UMat, matchesThickness: int, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[str], flags: DrawMatchesFlags) -> UMat	findEssentialMat(points1: UMat, points2: UMat, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							drawMatchesKnn(img1: cv2.typing.MatLike, keypoints1: _typing.Sequence[KeyPoint], img2: cv2.typing.MatLike, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[_typing.Sequence[DMatch]], outImg: cv2.typing.MatLike, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[_typing.Sequence[str]], flags: DrawMatchesFlags) -> cv2.typing.MatLike	findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							drawMatchesKnn(img1: UMat, keypoints1: _typing.Sequence[KeyPoint], img2: UMat, keypoints2: _typing.Sequence[KeyPoint], matches1to2: _typing.Sequence[_typing.Sequence[DMatch]], outImg: UMat, matchColor: cv2.typing.Scalar, singlePointColor: cv2.typing.Scalar, matchesMask: _typing.Sequence[_typing.Sequence[str]], flags: DrawMatchesFlags) -> UMat	findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							edgePreservingFilter(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							edgePreservingFilter(src: UMat, dst: UMat | None, flags: int, sigma_s: float, sigma_r: float) -> UMat	findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							eigen(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							eigen(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[bool, UMat, UMat]	findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]
							eigenNonSymmetric(src: cv2.typing.MatLike, eigenvalues: cv2.typing.MatLike | None, eigenvectors: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, mask: cv2.typing.MatLike | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							eigenNonSymmetric(src: UMat, eigenvalues: UMat | None, eigenvectors: UMat | None) -> tuple[UMat, UMat]	findHomography(srcPoints: UMat, dstPoints: UMat, method: int, ransacReprojThreshold: float, mask: UMat | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, UMat]
							ellipse(img: cv2.typing.MatLike, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	findNonZero(src: cv2.typing.MatLike, idx: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							ellipse(img: UMat, center: cv2.typing.Point, axes: cv2.typing.Size, angle: float, startAngle: float, endAngle: float, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	findNonZero(src: UMat, idx: UMat | None) -> UMat
							ellipse(img: cv2.typing.MatLike, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> cv2.typing.MatLike	findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike, gaussFiltSize: int) -> tuple[float, cv2.typing.MatLike]
							ellipse(img: UMat, box: cv2.typing.RotatedRect, color: cv2.typing.Scalar, thickness: int, lineType: int) -> UMat	findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat, gaussFiltSize: int) -> tuple[float, UMat]
							ellipse2Poly(center: cv2.typing.Point, axes: cv2.typing.Size, angle: int, arcStart: int, arcEnd: int, delta: int) -> _typing.Sequence[cv2.typing.Point]	findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							empty_array_desc() -> GArrayDesc	findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat | None) -> tuple[float, UMat]
							empty_gopaque_desc() -> GOpaqueDesc	fitEllipse(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							empty_scalar_desc() -> GScalarDesc	fitEllipse(points: UMat) -> cv2.typing.RotatedRect
							equalizeHist(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	fitEllipseAMS(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							equalizeHist(src: UMat, dst: UMat | None) -> UMat	fitEllipseAMS(points: UMat) -> cv2.typing.RotatedRect
							erode(src: cv2.typing.MatLike, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	fitEllipseDirect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							erode(src: UMat, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	fitEllipseDirect(points: UMat) -> cv2.typing.RotatedRect
							estimateAffine2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	fitLine(points: cv2.typing.MatLike, distType: int, param: float, reps: float, aeps: float, line: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							estimateAffine2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]	fitLine(points: UMat, distType: int, param: float, reps: float, aeps: float, line: UMat | None) -> UMat
							estimateAffine2D(pts1: cv2.typing.MatLike, pts2: cv2.typing.MatLike, params: UsacParams, inliers: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	flip(src: cv2.typing.MatLike, flipCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							estimateAffine2D(pts1: UMat, pts2: UMat, params: UsacParams, inliers: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	flip(src: UMat, flipCode: int, dst: UMat | None) -> UMat
							estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]	flipND(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							estimateAffine3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]	flipND(src: UMat, axis: int, dst: UMat | None) -> UMat
							estimateAffine3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]	floodFill(image: cv2.typing.MatLike, mask: cv2.typing.MatLike | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]
							estimateAffine3D(src: UMat, dst: UMat, force_rotation: bool) -> tuple[cv2.typing.MatLike, float]	floodFill(image: UMat, mask: UMat | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, UMat, UMat, cv2.typing.Rect]
							estimateAffinePartial2D(from_: cv2.typing.MatLike, to: cv2.typing.MatLike, inliers: cv2.typing.MatLike | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	gemm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, alpha: float, src3: cv2.typing.MatLike, beta: float, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							estimateAffinePartial2D(from_: UMat, to: UMat, inliers: UMat | None, method: int, ransacReprojThreshold: float, maxIters: int, confidence: float, refineIters: int) -> tuple[cv2.typing.MatLike, UMat]	gemm(src1: UMat, src2: UMat, alpha: float, src3: UMat, beta: float, dst: UMat | None, flags: int) -> UMat
							estimateChessboardSharpness(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike, rise_distance: float, vertical: bool, sharpness: cv2.typing.MatLike | None) -> tuple[cv2.typing.Scalar, cv2.typing.MatLike]	getAffineTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike) -> cv2.typing.MatLike
							estimateChessboardSharpness(image: UMat, patternSize: cv2.typing.Size, corners: UMat, rise_distance: float, vertical: bool, sharpness: UMat | None) -> tuple[cv2.typing.Scalar, UMat]	getAffineTransform(src: UMat, dst: UMat) -> cv2.typing.MatLike
							estimateTranslation3D(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, out: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, ransacThreshold: float, confidence: float) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike]	getBuildInformation() -> str
							estimateTranslation3D(src: UMat, dst: UMat, out: UMat | None, inliers: UMat | None, ransacThreshold: float, confidence: float) -> tuple[int, UMat, UMat]	getCPUFeaturesLine() -> str
							exp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	getCPUTickCount() -> int
							exp(src: UMat, dst: UMat | None) -> UMat	getDefaultAlgorithmHint() -> AlgorithmHint
							extractChannel(src: cv2.typing.MatLike, coi: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	getDefaultNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike
							extractChannel(src: UMat, coi: int, dst: UMat | None) -> UMat	getDefaultNewCameraMatrix(cameraMatrix: UMat, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike
							fastAtan2(y: float, x: float) -> float	getDerivKernels(dx: int, dy: int, ksize: int, kx: cv2.typing.MatLike | None, ky: cv2.typing.MatLike | None, normalize: bool, ktype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							fastNlMeansDenoising(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	getDerivKernels(dx: int, dy: int, ksize: int, kx: UMat | None, ky: UMat | None, normalize: bool, ktype: int) -> tuple[UMat, UMat]
							fastNlMeansDenoising(src: UMat, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat	getFontScaleFromHeight(fontFace: int, pixelHeight: int, thickness: int) -> float
							fastNlMeansDenoising(src: cv2.typing.MatLike, h: _typing.Sequence[float], dst: cv2.typing.MatLike | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> cv2.typing.MatLike	getGaborKernel(ksize: cv2.typing.Size, sigma: float, theta: float, lambd: float, gamma: float, psi: float, ktype: int) -> cv2.typing.MatLike
							fastNlMeansDenoising(src: UMat, h: _typing.Sequence[float], dst: UMat | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> UMat	getGaussianKernel(ksize: int, sigma: float, ktype: int) -> cv2.typing.MatLike
							fastNlMeansDenoisingColored(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	getHardwareFeatureName(feature: int) -> str
							fastNlMeansDenoisingColored(src: UMat, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat	getLogLevel() -> int
							fastNlMeansDenoisingColoredMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, dst: cv2.typing.MatLike | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	getNumThreads() -> int
							fastNlMeansDenoisingColoredMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, dst: UMat | None, h: float, hColor: float, templateWindowSize: int, searchWindowSize: int) -> UMat	getNumberOfCPUs() -> int
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, dst: cv2.typing.MatLike | None, h: float, templateWindowSize: int, searchWindowSize: int) -> cv2.typing.MatLike	getOptimalDFTSize(vecsize: int) -> int
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, dst: UMat | None, h: float, templateWindowSize: int, searchWindowSize: int) -> UMat	getOptimalNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[cv2.typing.MatLike], imgToDenoiseIndex: int, temporalWindowSize: int, h: _typing.Sequence[float], dst: cv2.typing.MatLike | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> cv2.typing.MatLike	getOptimalNewCameraMatrix(cameraMatrix: UMat, distCoeffs: UMat, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]
							fastNlMeansDenoisingMulti(srcImgs: _typing.Sequence[UMat], imgToDenoiseIndex: int, temporalWindowSize: int, h: _typing.Sequence[float], dst: UMat | None, templateWindowSize: int, searchWindowSize: int, normType: int) -> UMat	getPerspectiveTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, solveMethod: int) -> cv2.typing.MatLike
							fillConvexPoly(img: cv2.typing.MatLike, points: cv2.typing.MatLike, color: cv2.typing.Scalar, lineType: int, shift: int) -> cv2.typing.MatLike	getPerspectiveTransform(src: UMat, dst: UMat, solveMethod: int) -> cv2.typing.MatLike
							fillConvexPoly(img: UMat, points: UMat, color: cv2.typing.Scalar, lineType: int, shift: int) -> UMat	getRectSubPix(image: cv2.typing.MatLike, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: cv2.typing.MatLike | None, patchType: int) -> cv2.typing.MatLike
							fillPoly(img: cv2.typing.MatLike, pts: _typing.Sequence[cv2.typing.MatLike], color: cv2.typing.Scalar, lineType: int, shift: int, offset: cv2.typing.Point) -> cv2.typing.MatLike	getRectSubPix(image: UMat, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: UMat | None, patchType: int) -> UMat
							fillPoly(img: UMat, pts: _typing.Sequence[UMat], color: cv2.typing.Scalar, lineType: int, shift: int, offset: cv2.typing.Point) -> UMat	getRotationMatrix2D(center: cv2.typing.Point2f, angle: float, scale: float) -> cv2.typing.MatLike
							filter2D(src: cv2.typing.MatLike, ddepth: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike	getStructuringElement(shape: int, ksize: cv2.typing.Size, anchor: cv2.typing.Point) -> cv2.typing.MatLike
							filter2D(src: UMat, ddepth: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat	getTextSize(text: str, fontFace: int, fontScale: float, thickness: int) -> tuple[cv2.typing.Size, int]
							filterHomographyDecompByVisibleRefpoints(rotations: _typing.Sequence[cv2.typing.MatLike], normals: _typing.Sequence[cv2.typing.MatLike], beforePoints: cv2.typing.MatLike, afterPoints: cv2.typing.MatLike, possibleSolutions: cv2.typing.MatLike | None, pointsMask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	getThreadNum() -> int
							filterHomographyDecompByVisibleRefpoints(rotations: _typing.Sequence[UMat], normals: _typing.Sequence[UMat], beforePoints: UMat, afterPoints: UMat, possibleSolutions: UMat | None, pointsMask: UMat | None) -> UMat	getTickCount() -> int
							filterSpeckles(img: cv2.typing.MatLike, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	getTickFrequency() -> float
							filterSpeckles(img: UMat, newVal: float, maxSpeckleSize: int, maxDiff: float, buf: UMat | None) -> tuple[UMat, UMat]	getTrackbarPos(trackbarname: str, winname: str) -> int
							find4QuadCornerSubpix(img: cv2.typing.MatLike, corners: cv2.typing.MatLike, region_size: cv2.typing.Size) -> tuple[bool, cv2.typing.MatLike]	getValidDisparityROI(roi1: cv2.typing.Rect, roi2: cv2.typing.Rect, minDisparity: int, numberOfDisparities: int, blockSize: int) -> cv2.typing.Rect
							find4QuadCornerSubpix(img: UMat, corners: UMat, region_size: cv2.typing.Size) -> tuple[bool, UMat]	getVersionMajor() -> int
							findChessboardCorners(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	getVersionMinor() -> int
							findChessboardCorners(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]	getVersionRevision() -> int
							findChessboardCornersSB(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, corners: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	getVersionString() -> str
							findChessboardCornersSB(image: UMat, patternSize: cv2.typing.Size, corners: UMat | None, flags: int) -> tuple[bool, UMat]	getWindowImageRect(winname: str) -> cv2.typing.Rect
							findChessboardCornersSBWithMeta(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, corners: cv2.typing.MatLike | None, meta: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	getWindowProperty(winname: str, prop_id: int) -> float
							findChessboardCornersSBWithMeta(image: UMat, patternSize: cv2.typing.Size, flags: int, corners: UMat | None, meta: UMat | None) -> tuple[bool, UMat, UMat]	goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, corners: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, blockSize: int, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike
							findCirclesGrid(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, flags: int, blobDetector: cv2.typing.FeatureDetector, parameters: CirclesGridFinderParameters, centers: cv2.typing.MatLike | None) -> tuple[bool, cv2.typing.MatLike]	goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, corners: UMat | None, mask: UMat | None, blockSize: int, useHarrisDetector: bool, k: float) -> UMat
							findCirclesGrid(image: UMat, patternSize: cv2.typing.Size, flags: int, blobDetector: cv2.typing.FeatureDetector, parameters: CirclesGridFinderParameters, centers: UMat | None) -> tuple[bool, UMat]	goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, blockSize: int, gradientSize: int, corners: cv2.typing.MatLike | None, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike
							findCirclesGrid(image: cv2.typing.MatLike, patternSize: cv2.typing.Size, centers: cv2.typing.MatLike | None, flags: int, blobDetector: cv2.typing.FeatureDetector) -> tuple[bool, cv2.typing.MatLike]	goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, blockSize: int, gradientSize: int, corners: UMat | None, useHarrisDetector: bool, k: float) -> UMat
							findCirclesGrid(image: UMat, patternSize: cv2.typing.Size, centers: UMat | None, flags: int, blobDetector: cv2.typing.FeatureDetector) -> tuple[bool, UMat]	goodFeaturesToTrackWithQuality(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, corners: cv2.typing.MatLike | None, cornersQuality: cv2.typing.MatLike | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							findContours(image: cv2.typing.MatLike, mode: int, method: int, contours: _typing.Sequence[cv2.typing.MatLike] | None, hierarchy: cv2.typing.MatLike | None, offset: cv2.typing.Point) -> tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	goodFeaturesToTrackWithQuality(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, corners: UMat | None, cornersQuality: UMat | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[UMat, UMat]
							findContours(image: UMat, mode: int, method: int, contours: _typing.Sequence[UMat] | None, hierarchy: UMat | None, offset: cv2.typing.Point) -> tuple[_typing.Sequence[UMat], UMat]	grabCut(img: cv2.typing.MatLike, mask: cv2.typing.MatLike, rect: cv2.typing.Rect, bgdModel: cv2.typing.MatLike, fgdModel: cv2.typing.MatLike, iterCount: int, mode: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							findContoursLinkRuns(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike] | None, hierarchy: cv2.typing.MatLike | None) -> tuple[_typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	grabCut(img: UMat, mask: UMat, rect: cv2.typing.Rect, bgdModel: UMat, fgdModel: UMat, iterCount: int, mode: int) -> tuple[UMat, UMat, UMat]
							findContoursLinkRuns(image: UMat, contours: _typing.Sequence[UMat] | None, hierarchy: UMat | None) -> tuple[_typing.Sequence[UMat], UMat]	hasNonZero(src: cv2.typing.MatLike) -> bool
							findContoursLinkRuns(image: cv2.typing.MatLike, contours: _typing.Sequence[cv2.typing.MatLike] | None) -> _typing.Sequence[cv2.typing.MatLike]	hasNonZero(src: UMat) -> bool
							findContoursLinkRuns(image: UMat, contours: _typing.Sequence[UMat] | None) -> _typing.Sequence[UMat]	haveImageReader(filename: str) -> bool
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	haveImageWriter(filename: str) -> bool
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix: UMat, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	haveOpenVX() -> bool
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	idct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							findEssentialMat(points1: UMat, points2: UMat, focal: float, pp: cv2.typing.Point2d, method: int, prob: float, threshold: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	idct(src: UMat, dst: UMat | None, flags: int) -> UMat
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	idft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	idft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat
							findEssentialMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, dist_coeff1: cv2.typing.MatLike, dist_coeff2: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	illuminationChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike
							findEssentialMat(points1: UMat, points2: UMat, cameraMatrix1: UMat, cameraMatrix2: UMat, dist_coeff1: UMat, dist_coeff2: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	illuminationChange(src: UMat, mask: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	imcount(filename: str, flags: int) -> int
							findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, maxIters: int, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	imdecode(buf: cv2.typing.MatLike, flags: int) -> cv2.typing.MatLike
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, confidence: float, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	imdecode(buf: UMat, flags: int) -> cv2.typing.MatLike
							findFundamentalMat(points1: UMat, points2: UMat, method: int, ransacReprojThreshold: float, confidence: float, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	imread(filename: str, flags: int) -> cv2.typing.MatLike
							findFundamentalMat(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	imread(filename: str, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike
							findFundamentalMat(points1: UMat, points2: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	imread(filename: str, dst: UMat | None, flags: int) -> UMat
							findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, method: int, ransacReprojThreshold: float, mask: cv2.typing.MatLike | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	imshow(winname: str, mat: cv2.typing.MatLike) -> None
							findHomography(srcPoints: UMat, dstPoints: UMat, method: int, ransacReprojThreshold: float, mask: UMat | None, maxIters: int, confidence: float) -> tuple[cv2.typing.MatLike, UMat]	imshow(winname: str, mat: cv2.cuda.GpuMat) -> None
							findHomography(srcPoints: cv2.typing.MatLike, dstPoints: cv2.typing.MatLike, params: UsacParams, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	imshow(winname: str, mat: UMat) -> None
							findHomography(srcPoints: UMat, dstPoints: UMat, params: UsacParams, mask: UMat | None) -> tuple[cv2.typing.MatLike, UMat]	inRange(src: cv2.typing.MatLike, lowerb: cv2.typing.MatLike, upperb: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							findNonZero(src: cv2.typing.MatLike, idx: cv2.typing.MatLike | None) -> cv2.typing.MatLike	inRange(src: UMat, lowerb: UMat, upperb: UMat, dst: UMat | None) -> UMat
							findNonZero(src: UMat, idx: UMat | None) -> UMat	initInverseRectificationMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike, gaussFiltSize: int) -> tuple[float, cv2.typing.MatLike]	initInverseRectificationMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]
							findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat, gaussFiltSize: int) -> tuple[float, UMat]	initUndistortRectifyMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							findTransformECC(templateImage: cv2.typing.MatLike, inputImage: cv2.typing.MatLike, warpMatrix: cv2.typing.MatLike, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	initUndistortRectifyMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]
							findTransformECC(templateImage: UMat, inputImage: UMat, warpMatrix: UMat, motionType: int, criteria: cv2.typing.TermCriteria, inputMask: UMat | None) -> tuple[float, UMat]	inpaint(src: cv2.typing.MatLike, inpaintMask: cv2.typing.MatLike, inpaintRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							fitEllipse(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	inpaint(src: UMat, inpaintMask: UMat, inpaintRadius: float, flags: int, dst: UMat | None) -> UMat
							fitEllipse(points: UMat) -> cv2.typing.RotatedRect	insertChannel(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, coi: int) -> cv2.typing.MatLike
							fitEllipseAMS(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	insertChannel(src: UMat, dst: UMat, coi: int) -> UMat
							fitEllipseAMS(points: UMat) -> cv2.typing.RotatedRect	integral(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sdepth: int) -> cv2.typing.MatLike
							fitEllipseDirect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	integral(src: UMat, sum: UMat | None, sdepth: int) -> UMat
							fitEllipseDirect(points: UMat) -> cv2.typing.RotatedRect	integral2(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							fitLine(points: cv2.typing.MatLike, distType: int, param: float, reps: float, aeps: float, line: cv2.typing.MatLike | None) -> cv2.typing.MatLike	integral2(src: UMat, sum: UMat | None, sqsum: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat]
							fitLine(points: UMat, distType: int, param: float, reps: float, aeps: float, line: UMat | None) -> UMat	integral3(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, tilted: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							flip(src: cv2.typing.MatLike, flipCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	integral3(src: UMat, sum: UMat | None, sqsum: UMat | None, tilted: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat, UMat]
							flip(src: UMat, flipCode: int, dst: UMat | None) -> UMat	intersectConvexConvex(p1: cv2.typing.MatLike, p2: cv2.typing.MatLike, p12: cv2.typing.MatLike | None, handleNested: bool) -> tuple[float, cv2.typing.MatLike]
							flipND(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	intersectConvexConvex(p1: UMat, p2: UMat, p12: UMat | None, handleNested: bool) -> tuple[float, UMat]
							flipND(src: UMat, axis: int, dst: UMat | None) -> UMat	invert(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[float, cv2.typing.MatLike]
							floodFill(image: cv2.typing.MatLike, mask: cv2.typing.MatLike | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect]	invert(src: UMat, dst: UMat | None, flags: int) -> tuple[float, UMat]
							floodFill(image: UMat, mask: UMat | None, seedPoint: cv2.typing.Point, newVal: cv2.typing.Scalar, loDiff: cv2.typing.Scalar, upDiff: cv2.typing.Scalar, flags: int) -> tuple[int, UMat, UMat, cv2.typing.Rect]	invertAffineTransform(M: cv2.typing.MatLike, iM: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							gemm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, alpha: float, src3: cv2.typing.MatLike, beta: float, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	invertAffineTransform(M: UMat, iM: UMat | None) -> UMat
							gemm(src1: UMat, src2: UMat, alpha: float, src3: UMat, beta: float, dst: UMat | None, flags: int) -> UMat	isContourConvex(contour: cv2.typing.MatLike) -> bool
							getAffineTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike) -> cv2.typing.MatLike	isContourConvex(contour: UMat) -> bool
							getAffineTransform(src: UMat, dst: UMat) -> cv2.typing.MatLike	kmeans(data: cv2.typing.MatLike, K: int, bestLabels: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]
							getBuildInformation() -> str	kmeans(data: UMat, K: int, bestLabels: UMat, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: UMat | None) -> tuple[float, UMat, UMat]
							getCPUFeaturesLine() -> str	line(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							getCPUTickCount() -> int	line(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							getDefaultAlgorithmHint() -> AlgorithmHint	linearPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getDefaultNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike	linearPolar(src: UMat, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat
							getDefaultNewCameraMatrix(cameraMatrix: UMat, imgsize: cv2.typing.Size, centerPrincipalPoint: bool) -> cv2.typing.MatLike	log(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getDerivKernels(dx: int, dy: int, ksize: int, kx: cv2.typing.MatLike | None, ky: cv2.typing.MatLike | None, normalize: bool, ktype: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	log(src: UMat, dst: UMat | None) -> UMat
							getDerivKernels(dx: int, dy: int, ksize: int, kx: UMat | None, ky: UMat | None, normalize: bool, ktype: int) -> tuple[UMat, UMat]	logPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, M: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getFontScaleFromHeight(fontFace: int, pixelHeight: int, thickness: int) -> float	logPolar(src: UMat, center: cv2.typing.Point2f, M: float, flags: int, dst: UMat | None) -> UMat
							getGaborKernel(ksize: cv2.typing.Size, sigma: float, theta: float, lambd: float, gamma: float, psi: float, ktype: int) -> cv2.typing.MatLike	magnitude(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getGaussianKernel(ksize: int, sigma: float, ktype: int) -> cv2.typing.MatLike	magnitude(x: UMat, y: UMat, magnitude: UMat | None) -> UMat
							getHardwareFeatureName(feature: int) -> str	matMulDeriv(A: cv2.typing.MatLike, B: cv2.typing.MatLike, dABdA: cv2.typing.MatLike | None, dABdB: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getLogLevel() -> int	matMulDeriv(A: UMat, B: UMat, dABdA: UMat | None, dABdB: UMat | None) -> tuple[UMat, UMat]
							getNumThreads() -> int	matchShapes(contour1: cv2.typing.MatLike, contour2: cv2.typing.MatLike, method: int, parameter: float) -> float
							getNumberOfCPUs() -> int	matchShapes(contour1: UMat, contour2: UMat, method: int, parameter: float) -> float
							getOptimalDFTSize(vecsize: int) -> int	matchTemplate(image: cv2.typing.MatLike, templ: cv2.typing.MatLike, method: int, result: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getOptimalNewCameraMatrix(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]	matchTemplate(image: UMat, templ: UMat, method: int, result: UMat | None, mask: UMat | None) -> UMat
							getOptimalNewCameraMatrix(cameraMatrix: UMat, distCoeffs: UMat, imageSize: cv2.typing.Size, alpha: float, newImgSize: cv2.typing.Size, centerPrincipalPoint: bool) -> tuple[cv2.typing.MatLike, cv2.typing.Rect]	max(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getPerspectiveTransform(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, solveMethod: int) -> cv2.typing.MatLike	max(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
							getPerspectiveTransform(src: UMat, dst: UMat, solveMethod: int) -> cv2.typing.MatLike	mean(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.Scalar
							getRectSubPix(image: cv2.typing.MatLike, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: cv2.typing.MatLike | None, patchType: int) -> cv2.typing.MatLike	mean(src: UMat, mask: UMat | None) -> cv2.typing.Scalar
							getRectSubPix(image: UMat, patchSize: cv2.typing.Size, center: cv2.typing.Point2f, patch: UMat | None, patchType: int) -> UMat	meanShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]
							getRotationMatrix2D(center: cv2.typing.Point2f, angle: float, scale: float) -> cv2.typing.MatLike	meanShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]
							getStructuringElement(shape: int, ksize: cv2.typing.Size, anchor: cv2.typing.Point) -> cv2.typing.MatLike	meanStdDev(src: cv2.typing.MatLike, mean: cv2.typing.MatLike | None, stddev: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							getTextSize(text: str, fontFace: int, fontScale: float, thickness: int) -> tuple[cv2.typing.Size, int]	meanStdDev(src: UMat, mean: UMat | None, stddev: UMat | None, mask: UMat | None) -> tuple[UMat, UMat]
							getThreadNum() -> int	medianBlur(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getTickCount() -> int	medianBlur(src: UMat, ksize: int, dst: UMat | None) -> UMat
							getTickFrequency() -> float	min(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							getTrackbarPos(trackbarname: str, winname: str) -> int	min(src1: UMat, src2: UMat, dst: UMat | None) -> UMat
							getValidDisparityROI(roi1: cv2.typing.Rect, roi2: cv2.typing.Rect, minDisparity: int, numberOfDisparities: int, blockSize: int) -> cv2.typing.Rect	minAreaRect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect
							getVersionMajor() -> int	minAreaRect(points: UMat) -> cv2.typing.RotatedRect
							getVersionMinor() -> int	minEnclosingCircle(points: cv2.typing.MatLike) -> tuple[cv2.typing.Point2f, float]
							getVersionRevision() -> int	minEnclosingCircle(points: UMat) -> tuple[cv2.typing.Point2f, float]
							getVersionString() -> str	minEnclosingTriangle(points: cv2.typing.MatLike, triangle: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							getWindowImageRect(winname: str) -> cv2.typing.Rect	minEnclosingTriangle(points: UMat, triangle: UMat | None) -> tuple[float, UMat]
							getWindowProperty(winname: str, prop_id: int) -> float	minMaxLoc(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]
							goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, corners: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, blockSize: int, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike	minMaxLoc(src: UMat, mask: UMat | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]
							goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, corners: UMat | None, mask: UMat | None, blockSize: int, useHarrisDetector: bool, k: float) -> UMat	moments(array: cv2.typing.MatLike, binaryImage: bool) -> cv2.typing.Moments
							goodFeaturesToTrack(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, blockSize: int, gradientSize: int, corners: cv2.typing.MatLike | None, useHarrisDetector: bool, k: float) -> cv2.typing.MatLike	moments(array: UMat, binaryImage: bool) -> cv2.typing.Moments
							goodFeaturesToTrack(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, blockSize: int, gradientSize: int, corners: UMat | None, useHarrisDetector: bool, k: float) -> UMat	morphologyEx(src: cv2.typing.MatLike, op: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							goodFeaturesToTrackWithQuality(image: cv2.typing.MatLike, maxCorners: int, qualityLevel: float, minDistance: float, mask: cv2.typing.MatLike, corners: cv2.typing.MatLike | None, cornersQuality: cv2.typing.MatLike | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	morphologyEx(src: UMat, op: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat
							goodFeaturesToTrackWithQuality(image: UMat, maxCorners: int, qualityLevel: float, minDistance: float, mask: UMat, corners: UMat | None, cornersQuality: UMat | None, blockSize: int, gradientSize: int, useHarrisDetector: bool, k: float) -> tuple[UMat, UMat]	moveWindow(winname: str, x: int, y: int) -> None
							grabCut(img: cv2.typing.MatLike, mask: cv2.typing.MatLike, rect: cv2.typing.Rect, bgdModel: cv2.typing.MatLike, fgdModel: cv2.typing.MatLike, iterCount: int, mode: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	mulSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike
							grabCut(img: UMat, mask: UMat, rect: cv2.typing.Rect, bgdModel: UMat, fgdModel: UMat, iterCount: int, mode: int) -> tuple[UMat, UMat, UMat]	mulSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat
							groupRectangles(rectList: _typing.Sequence[cv2.typing.Rect], groupThreshold: int, eps: float) -> tuple[_typing.Sequence[cv2.typing.Rect], _typing.Sequence[int]]	mulTransposed(src: cv2.typing.MatLike, aTa: bool, dst: cv2.typing.MatLike | None, delta: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							hasNonZero(src: cv2.typing.MatLike) -> bool	mulTransposed(src: UMat, aTa: bool, dst: UMat | None, delta: UMat | None, scale: float, dtype: int) -> UMat
							hasNonZero(src: UMat) -> bool	multiply(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike
							haveImageReader(filename: str) -> bool	multiply(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat
							haveImageWriter(filename: str) -> bool	namedWindow(winname: str, flags: int) -> None
							haveOpenVX() -> bool	norm(src1: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float
							hconcat(src: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	norm(src1: UMat, normType: int, mask: UMat | None) -> float
							hconcat(src: _typing.Sequence[UMat], dst: UMat | None) -> UMat	norm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float
							idct(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	norm(src1: UMat, src2: UMat, normType: int, mask: UMat | None) -> float
							idct(src: UMat, dst: UMat | None, flags: int) -> UMat	normalize(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, beta: float, norm_type: int, dtype: int, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							idft(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int, nonzeroRows: int) -> cv2.typing.MatLike	normalize(src: UMat, dst: UMat, alpha: float, beta: float, norm_type: int, dtype: int, mask: UMat | None) -> UMat
							idft(src: UMat, dst: UMat | None, flags: int, nonzeroRows: int) -> UMat	patchNaNs(a: cv2.typing.MatLike, val: float) -> cv2.typing.MatLike
							illuminationChange(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, alpha: float, beta: float) -> cv2.typing.MatLike	patchNaNs(a: UMat, val: float) -> UMat
							illuminationChange(src: UMat, mask: UMat, dst: UMat | None, alpha: float, beta: float) -> UMat	pencilSketch(src: cv2.typing.MatLike, dst1: cv2.typing.MatLike | None, dst2: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							imcount(filename: str, flags: int) -> int	pencilSketch(src: UMat, dst1: UMat | None, dst2: UMat | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[UMat, UMat]
							imdecode(buf: cv2.typing.MatLike, flags: int) -> cv2.typing.MatLike	perspectiveTransform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							imdecode(buf: UMat, flags: int) -> cv2.typing.MatLike	perspectiveTransform(src: UMat, m: UMat, dst: UMat | None) -> UMat
							imdecodemulti(buf: cv2.typing.MatLike, flags: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, range: cv2.typing.Range) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	phase(x: cv2.typing.MatLike, y: cv2.typing.MatLike, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> cv2.typing.MatLike
							imdecodemulti(buf: UMat, flags: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, range: cv2.typing.Range) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	phase(x: UMat, y: UMat, angle: UMat | None, angleInDegrees: bool) -> UMat
							imencode(ext: str, img: cv2.typing.MatLike, params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	phaseCorrelate(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, window: cv2.typing.MatLike | None) -> tuple[cv2.typing.Point2d, float]
							imencode(ext: str, img: UMat, params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	phaseCorrelate(src1: UMat, src2: UMat, window: UMat | None) -> tuple[cv2.typing.Point2d, float]
							imencodemulti(ext: str, imgs: _typing.Sequence[cv2.typing.MatLike], params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	pointPolygonTest(contour: cv2.typing.MatLike, pt: cv2.typing.Point2f, measureDist: bool) -> float
							imencodemulti(ext: str, imgs: _typing.Sequence[UMat], params: _typing.Sequence[int]) -> tuple[bool, numpy.ndarray[_typing.Any, numpy.dtype[numpy.uint8]]]	pointPolygonTest(contour: UMat, pt: cv2.typing.Point2f, measureDist: bool) -> float
							imread(filename: str, flags: int) -> cv2.typing.MatLike	polarToCart(magnitude: cv2.typing.MatLike, angle: cv2.typing.MatLike, x: cv2.typing.MatLike | None, y: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							imread(filename: str, dst: cv2.typing.MatLike | None, flags: int) -> cv2.typing.MatLike	polarToCart(magnitude: UMat, angle: UMat, x: UMat | None, y: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]
							imread(filename: str, dst: UMat | None, flags: int) -> UMat	pollKey() -> int
							imreadanimation(filename: str, start: int, count: int) -> tuple[bool, Animation]	pow(src: cv2.typing.MatLike, power: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							imreadmulti(filename: str, mats: _typing.Sequence[cv2.typing.MatLike] | None, flags: int) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	pow(src: UMat, power: float, dst: UMat | None) -> UMat
							imreadmulti(filename: str, start: int, count: int, mats: _typing.Sequence[cv2.typing.MatLike] | None, flags: int) -> tuple[bool, _typing.Sequence[cv2.typing.MatLike]]	preCornerDetect(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike
							imshow(winname: str, mat: cv2.typing.MatLike) -> None	preCornerDetect(src: UMat, ksize: int, dst: UMat | None, borderType: int) -> UMat
							imshow(winname: str, mat: cv2.cuda.GpuMat) -> None	projectPoints(objectPoints: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None, aspectRatio: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							imshow(winname: str, mat: UMat) -> None	projectPoints(objectPoints: UMat, rvec: UMat, tvec: UMat, cameraMatrix: UMat, distCoeffs: UMat, imagePoints: UMat | None, jacobian: UMat | None, aspectRatio: float) -> tuple[UMat, UMat]
							imwrite(filename: str, img: cv2.typing.MatLike, params: _typing.Sequence[int]) -> bool	putText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> cv2.typing.MatLike
							imwrite(filename: str, img: UMat, params: _typing.Sequence[int]) -> bool	putText(img: UMat, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> UMat
							imwriteanimation(filename: str, animation: Animation, params: _typing.Sequence[int]) -> bool	pyrDown(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike
							imwritemulti(filename: str, img: _typing.Sequence[cv2.typing.MatLike], params: _typing.Sequence[int]) -> bool	pyrDown(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat
							imwritemulti(filename: str, img: _typing.Sequence[UMat], params: _typing.Sequence[int]) -> bool	pyrMeanShiftFiltering(src: cv2.typing.MatLike, sp: float, sr: float, dst: cv2.typing.MatLike | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> cv2.typing.MatLike
							inRange(src: cv2.typing.MatLike, lowerb: cv2.typing.MatLike, upperb: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	pyrMeanShiftFiltering(src: UMat, sp: float, sr: float, dst: UMat | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> UMat
							inRange(src: UMat, lowerb: UMat, upperb: UMat, dst: UMat | None) -> UMat	pyrUp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike
							initCameraMatrix2D(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, aspectRatio: float) -> cv2.typing.MatLike	pyrUp(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat
							initCameraMatrix2D(objectPoints: _typing.Sequence[UMat], imagePoints: _typing.Sequence[UMat], imageSize: cv2.typing.Size, aspectRatio: float) -> cv2.typing.MatLike	randShuffle(dst: cv2.typing.MatLike, iterFactor: float) -> cv2.typing.MatLike
							initInverseRectificationMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	randShuffle(dst: UMat, iterFactor: float) -> UMat
							initInverseRectificationMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]	randn(dst: cv2.typing.MatLike, mean: cv2.typing.MatLike, stddev: cv2.typing.MatLike) -> cv2.typing.MatLike
							initUndistortRectifyMap(cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, newCameraMatrix: cv2.typing.MatLike, size: cv2.typing.Size, m1type: int, map1: cv2.typing.MatLike | None, map2: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	randn(dst: UMat, mean: UMat, stddev: UMat) -> UMat
							initUndistortRectifyMap(cameraMatrix: UMat, distCoeffs: UMat, R: UMat, newCameraMatrix: UMat, size: cv2.typing.Size, m1type: int, map1: UMat | None, map2: UMat | None) -> tuple[UMat, UMat]	randu(dst: cv2.typing.MatLike, low: cv2.typing.MatLike, high: cv2.typing.MatLike) -> cv2.typing.MatLike
							inpaint(src: cv2.typing.MatLike, inpaintMask: cv2.typing.MatLike, inpaintRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	randu(dst: UMat, low: UMat, high: UMat) -> UMat
							inpaint(src: UMat, inpaintMask: UMat, inpaintRadius: float, flags: int, dst: UMat | None) -> UMat	readOpticalFlow(path: str) -> cv2.typing.MatLike
							insertChannel(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, coi: int) -> cv2.typing.MatLike	recoverPose(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, E: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							insertChannel(src: UMat, dst: UMat, coi: int) -> UMat	recoverPose(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, E: UMat | None, R: UMat | None, t: UMat | None, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]
							integral(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sdepth: int) -> cv2.typing.MatLike	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							integral(src: UMat, sum: UMat | None, sdepth: int) -> UMat	recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, R: UMat | None, t: UMat | None, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]
							integral2(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, focal: float, pp: cv2.typing.Point2d, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							integral2(src: UMat, sum: UMat | None, sqsum: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat]	recoverPose(E: UMat, points1: UMat, points2: UMat, R: UMat | None, t: UMat | None, focal: float, pp: cv2.typing.Point2d, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]
							integral3(src: cv2.typing.MatLike, sum: cv2.typing.MatLike | None, sqsum: cv2.typing.MatLike | None, tilted: cv2.typing.MatLike | None, sdepth: int, sqdepth: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distanceThresh: float, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, triangulatedPoints: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							integral3(src: UMat, sum: UMat | None, sqsum: UMat | None, tilted: UMat | None, sdepth: int, sqdepth: int) -> tuple[UMat, UMat, UMat]	recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, distanceThresh: float, R: UMat | None, t: UMat | None, mask: UMat | None, triangulatedPoints: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]
							intersectConvexConvex(p1: cv2.typing.MatLike, p2: cv2.typing.MatLike, p12: cv2.typing.MatLike | None, handleNested: bool) -> tuple[float, cv2.typing.MatLike]	rectangle(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							intersectConvexConvex(p1: UMat, p2: UMat, p12: UMat | None, handleNested: bool) -> tuple[float, UMat]	rectangle(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							invert(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[float, cv2.typing.MatLike]	rectangle(img: cv2.typing.MatLike, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike
							invert(src: UMat, dst: UMat | None, flags: int) -> tuple[float, UMat]	rectangle(img: UMat, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat
							invertAffineTransform(M: cv2.typing.MatLike, iM: cv2.typing.MatLike | None) -> cv2.typing.MatLike	rectangleIntersectionArea(a: cv2.typing.Rect2d, b: cv2.typing.Rect2d) -> float
							invertAffineTransform(M: UMat, iM: UMat | None) -> UMat	reduce(src: cv2.typing.MatLike, dim: int, rtype: int, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							isContourConvex(contour: cv2.typing.MatLike) -> bool	reduce(src: UMat, dim: int, rtype: int, dst: UMat | None, dtype: int) -> UMat
							isContourConvex(contour: UMat) -> bool	reduceArgMax(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike
							kmeans(data: cv2.typing.MatLike, K: int, bestLabels: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike]	reduceArgMax(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat
							kmeans(data: UMat, K: int, bestLabels: UMat, criteria: cv2.typing.TermCriteria, attempts: int, flags: int, centers: UMat | None) -> tuple[float, UMat, UMat]	reduceArgMin(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike
							line(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	reduceArgMin(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat
							line(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	remap(src: cv2.typing.MatLike, map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, interpolation: int, dst: cv2.typing.MatLike | None, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							linearPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	remap(src: UMat, map1: UMat, map2: UMat, interpolation: int, dst: UMat | None, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							linearPolar(src: UMat, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat	repeat(src: cv2.typing.MatLike, ny: int, nx: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							log(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	repeat(src: UMat, ny: int, nx: int, dst: UMat | None) -> UMat
							log(src: UMat, dst: UMat | None) -> UMat	reprojectImageTo3D(disparity: cv2.typing.MatLike, Q: cv2.typing.MatLike, _3dImage: cv2.typing.MatLike | None, handleMissingValues: bool, ddepth: int) -> cv2.typing.MatLike
							logPolar(src: cv2.typing.MatLike, center: cv2.typing.Point2f, M: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	reprojectImageTo3D(disparity: UMat, Q: UMat, _3dImage: UMat | None, handleMissingValues: bool, ddepth: int) -> UMat
							logPolar(src: UMat, center: cv2.typing.Point2f, M: float, flags: int, dst: UMat | None) -> UMat	resize(src: cv2.typing.MatLike, dsize: cv2.typing.Size | None, dst: cv2.typing.MatLike | None, fx: float, fy: float, interpolation: int) -> cv2.typing.MatLike
							magnitude(x: cv2.typing.MatLike, y: cv2.typing.MatLike, magnitude: cv2.typing.MatLike | None) -> cv2.typing.MatLike	resize(src: UMat, dsize: cv2.typing.Size | None, dst: UMat | None, fx: float, fy: float, interpolation: int) -> UMat
							magnitude(x: UMat, y: UMat, magnitude: UMat | None) -> UMat	resizeWindow(winname: str, width: int, height: int) -> None
							matMulDeriv(A: cv2.typing.MatLike, B: cv2.typing.MatLike, dABdA: cv2.typing.MatLike | None, dABdB: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	resizeWindow(winname: str, size: cv2.typing.Size) -> None
							matMulDeriv(A: UMat, B: UMat, dABdA: UMat | None, dABdB: UMat | None) -> tuple[UMat, UMat]	rotate(src: cv2.typing.MatLike, rotateCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							matchShapes(contour1: cv2.typing.MatLike, contour2: cv2.typing.MatLike, method: int, parameter: float) -> float	rotate(src: UMat, rotateCode: int, dst: UMat | None) -> UMat
							matchShapes(contour1: UMat, contour2: UMat, method: int, parameter: float) -> float	rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							matchTemplate(image: cv2.typing.MatLike, templ: cv2.typing.MatLike, method: int, result: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: UMat | None) -> tuple[int, UMat]
							matchTemplate(image: UMat, templ: UMat, method: int, result: UMat | None, mask: UMat | None) -> UMat	sampsonDistance(pt1: cv2.typing.MatLike, pt2: cv2.typing.MatLike, F: cv2.typing.MatLike) -> float
							max(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	sampsonDistance(pt1: UMat, pt2: UMat, F: UMat) -> float
							max(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	scaleAdd(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							mean(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> cv2.typing.Scalar	scaleAdd(src1: UMat, alpha: float, src2: UMat, dst: UMat | None) -> UMat
							mean(src: UMat, mask: UMat | None) -> cv2.typing.Scalar	seamlessClone(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike, p: cv2.typing.Point, flags: int, blend: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							meanShift(probImage: cv2.typing.MatLike, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]	seamlessClone(src: UMat, dst: UMat, mask: UMat, p: cv2.typing.Point, flags: int, blend: UMat | None) -> UMat
							meanShift(probImage: UMat, window: cv2.typing.Rect, criteria: cv2.typing.TermCriteria) -> tuple[int, cv2.typing.Rect]	selectROI(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							meanStdDev(src: cv2.typing.MatLike, mean: cv2.typing.MatLike | None, stddev: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	selectROI(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							meanStdDev(src: UMat, mean: UMat | None, stddev: UMat | None, mask: UMat | None) -> tuple[UMat, UMat]	selectROI(img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							medianBlur(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	selectROI(img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect
							medianBlur(src: UMat, ksize: int, dst: UMat | None) -> UMat	sepFilter2D(src: cv2.typing.MatLike, ddepth: int, kernelX: cv2.typing.MatLike, kernelY: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike
							merge(mv: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	sepFilter2D(src: UMat, ddepth: int, kernelX: UMat, kernelY: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat
							merge(mv: _typing.Sequence[UMat], dst: UMat | None) -> UMat	setIdentity(mtx: cv2.typing.MatLike, s: cv2.typing.Scalar) -> cv2.typing.MatLike
							min(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	setIdentity(mtx: UMat, s: cv2.typing.Scalar) -> UMat
							min(src1: UMat, src2: UMat, dst: UMat | None) -> UMat	setLogLevel(level: int) -> int
							minAreaRect(points: cv2.typing.MatLike) -> cv2.typing.RotatedRect	setNumThreads(nthreads: int) -> None
							minAreaRect(points: UMat) -> cv2.typing.RotatedRect	setRNGSeed(seed: int) -> None
							minEnclosingCircle(points: cv2.typing.MatLike) -> tuple[cv2.typing.Point2f, float]	setTrackbarMax(trackbarname: str, winname: str, maxval: int) -> None
							minEnclosingCircle(points: UMat) -> tuple[cv2.typing.Point2f, float]	setTrackbarMin(trackbarname: str, winname: str, minval: int) -> None
							minEnclosingTriangle(points: cv2.typing.MatLike, triangle: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	setTrackbarPos(trackbarname: str, winname: str, pos: int) -> None
							minEnclosingTriangle(points: UMat, triangle: UMat | None) -> tuple[float, UMat]	setUseOpenVX(flag: bool) -> None
							minMaxLoc(src: cv2.typing.MatLike, mask: cv2.typing.MatLike | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]	setUseOptimized(onoff: bool) -> None
							minMaxLoc(src: UMat, mask: UMat | None) -> tuple[float, float, cv2.typing.Point, cv2.typing.Point]	setWindowProperty(winname: str, prop_id: int, prop_value: float) -> None
							mixChannels(src: _typing.Sequence[cv2.typing.MatLike], dst: _typing.Sequence[cv2.typing.MatLike], fromTo: _typing.Sequence[int]) -> _typing.Sequence[cv2.typing.MatLike]	setWindowTitle(winname: str, title: str) -> None
							mixChannels(src: _typing.Sequence[UMat], dst: _typing.Sequence[UMat], fromTo: _typing.Sequence[int]) -> _typing.Sequence[UMat]	solve(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]
							moments(array: cv2.typing.MatLike, binaryImage: bool) -> cv2.typing.Moments	solve(src1: UMat, src2: UMat, dst: UMat | None, flags: int) -> tuple[bool, UMat]
							moments(array: UMat, binaryImage: bool) -> cv2.typing.Moments	solveCubic(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							morphologyEx(src: cv2.typing.MatLike, op: int, kernel: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	solveCubic(coeffs: UMat, roots: UMat | None) -> tuple[int, UMat]
							morphologyEx(src: UMat, op: int, kernel: UMat, dst: UMat | None, anchor: cv2.typing.Point, iterations: int, borderType: int, borderValue: cv2.typing.Scalar) -> UMat	solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, constr_eps: float, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							moveWindow(winname: str, x: int, y: int) -> None	solveLP(Func: UMat, Constr: UMat, constr_eps: float, z: UMat | None) -> tuple[int, UMat]
							mulSpectrums(a: cv2.typing.MatLike, b: cv2.typing.MatLike, flags: int, c: cv2.typing.MatLike | None, conjB: bool) -> cv2.typing.MatLike	solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]
							mulSpectrums(a: UMat, b: UMat, flags: int, c: UMat | None, conjB: bool) -> UMat	solveLP(Func: UMat, Constr: UMat, z: UMat | None) -> tuple[int, UMat]
							mulTransposed(src: cv2.typing.MatLike, aTa: bool, dst: cv2.typing.MatLike | None, delta: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	solvePnP(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							mulTransposed(src: UMat, aTa: bool, dst: UMat | None, delta: UMat | None, scale: float, dtype: int) -> UMat	solvePnP(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, UMat, UMat]
							multiply(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, scale: float, dtype: int) -> cv2.typing.MatLike	solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]
							multiply(src1: UMat, src2: UMat, dst: UMat | None, scale: float, dtype: int) -> UMat	solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: UMat | None, flags: int) -> tuple[bool, UMat, UMat, UMat]
							namedWindow(winname: str, flags: int) -> None	solvePnPRefineLM(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							norm(src1: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float	solvePnPRefineLM(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria) -> tuple[UMat, UMat]
							norm(src1: UMat, normType: int, mask: UMat | None) -> float	solvePnPRefineVVS(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							norm(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, normType: int, mask: cv2.typing.MatLike | None) -> float	solvePnPRefineVVS(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[UMat, UMat]
							norm(src1: UMat, src2: UMat, normType: int, mask: UMat | None) -> float	solvePoly(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None, maxIters: int) -> tuple[float, cv2.typing.MatLike]
							normalize(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, alpha: float, beta: float, norm_type: int, dtype: int, mask: cv2.typing.MatLike | None) -> cv2.typing.MatLike	solvePoly(coeffs: UMat, roots: UMat | None, maxIters: int) -> tuple[float, UMat]
							normalize(src: UMat, dst: UMat, alpha: float, beta: float, norm_type: int, dtype: int, mask: UMat | None) -> UMat	sort(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							patchNaNs(a: cv2.typing.MatLike, val: float) -> cv2.typing.MatLike	sort(src: UMat, flags: int, dst: UMat | None) -> UMat
							patchNaNs(a: UMat, val: float) -> UMat	sortIdx(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							pencilSketch(src: cv2.typing.MatLike, dst1: cv2.typing.MatLike | None, dst2: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	sortIdx(src: UMat, flags: int, dst: UMat | None) -> UMat
							pencilSketch(src: UMat, dst1: UMat | None, dst2: UMat | None, sigma_s: float, sigma_r: float, shade_factor: float) -> tuple[UMat, UMat]	spatialGradient(src: cv2.typing.MatLike, dx: cv2.typing.MatLike | None, dy: cv2.typing.MatLike | None, ksize: int, borderType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]
							perspectiveTransform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	spatialGradient(src: UMat, dx: UMat | None, dy: UMat | None, ksize: int, borderType: int) -> tuple[UMat, UMat]
							perspectiveTransform(src: UMat, m: UMat, dst: UMat | None) -> UMat	sqrBoxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike
							phase(x: cv2.typing.MatLike, y: cv2.typing.MatLike, angle: cv2.typing.MatLike | None, angleInDegrees: bool) -> cv2.typing.MatLike	sqrBoxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat
							phase(x: UMat, y: UMat, angle: UMat | None, angleInDegrees: bool) -> UMat	sqrt(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							phaseCorrelate(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, window: cv2.typing.MatLike | None) -> tuple[cv2.typing.Point2d, float]	sqrt(src: UMat, dst: UMat | None) -> UMat
							phaseCorrelate(src1: UMat, src2: UMat, window: UMat | None) -> tuple[cv2.typing.Point2d, float]	stackBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							pointPolygonTest(contour: cv2.typing.MatLike, pt: cv2.typing.Point2f, measureDist: bool) -> float	stackBlur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None) -> UMat
							pointPolygonTest(contour: UMat, pt: cv2.typing.Point2f, measureDist: bool) -> float	startWindowThread() -> int
							polarToCart(magnitude: cv2.typing.MatLike, angle: cv2.typing.MatLike, x: cv2.typing.MatLike | None, y: cv2.typing.MatLike | None, angleInDegrees: bool) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	stereoRectify(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]
							polarToCart(magnitude: UMat, angle: UMat, x: UMat | None, y: UMat | None, angleInDegrees: bool) -> tuple[UMat, UMat]	stereoRectify(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, R1: UMat | None, R2: UMat | None, P1: UMat | None, P2: UMat | None, Q: UMat | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]
							pollKey() -> int	stereoRectifyUncalibrated(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, F: cv2.typing.MatLike, imgSize: cv2.typing.Size, H1: cv2.typing.MatLike | None, H2: cv2.typing.MatLike | None, threshold: float) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]
							polylines(img: cv2.typing.MatLike, pts: _typing.Sequence[cv2.typing.MatLike], isClosed: bool, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	stereoRectifyUncalibrated(points1: UMat, points2: UMat, F: UMat, imgSize: cv2.typing.Size, H1: UMat | None, H2: UMat | None, threshold: float) -> tuple[bool, UMat, UMat]
							polylines(img: UMat, pts: _typing.Sequence[UMat], isClosed: bool, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	stylization(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike
							pow(src: cv2.typing.MatLike, power: float, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	stylization(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat
							pow(src: UMat, power: float, dst: UMat | None) -> UMat	subtract(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike
							preCornerDetect(src: cv2.typing.MatLike, ksize: int, dst: cv2.typing.MatLike | None, borderType: int) -> cv2.typing.MatLike	subtract(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat
							preCornerDetect(src: UMat, ksize: int, dst: UMat | None, borderType: int) -> UMat	sumElems(src: cv2.typing.MatLike) -> cv2.typing.Scalar
							projectPoints(objectPoints: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike | None, jacobian: cv2.typing.MatLike | None, aspectRatio: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	sumElems(src: UMat) -> cv2.typing.Scalar
							projectPoints(objectPoints: UMat, rvec: UMat, tvec: UMat, cameraMatrix: UMat, distCoeffs: UMat, imagePoints: UMat | None, jacobian: UMat | None, aspectRatio: float) -> tuple[UMat, UMat]	textureFlattening(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, low_threshold: float, high_threshold: float, kernel_size: int) -> cv2.typing.MatLike
							putText(img: cv2.typing.MatLike, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> cv2.typing.MatLike	textureFlattening(src: UMat, mask: UMat, dst: UMat | None, low_threshold: float, high_threshold: float, kernel_size: int) -> UMat
							putText(img: UMat, text: str, org: cv2.typing.Point, fontFace: int, fontScale: float, color: cv2.typing.Scalar, thickness: int, lineType: int, bottomLeftOrigin: bool) -> UMat	threshold(src: cv2.typing.MatLike, thresh: float, maxval: float, type: int, dst: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]
							pyrDown(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike	threshold(src: UMat, thresh: float, maxval: float, type: int, dst: UMat | None) -> tuple[float, UMat]
							pyrDown(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat	trace(mtx: cv2.typing.MatLike) -> cv2.typing.Scalar
							pyrMeanShiftFiltering(src: cv2.typing.MatLike, sp: float, sr: float, dst: cv2.typing.MatLike | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> cv2.typing.MatLike	trace(mtx: UMat) -> cv2.typing.Scalar
							pyrMeanShiftFiltering(src: UMat, sp: float, sr: float, dst: UMat | None, maxLevel: int, termcrit: cv2.typing.TermCriteria) -> UMat	transform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							pyrUp(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, dstsize: cv2.typing.Size, borderType: int) -> cv2.typing.MatLike	transform(src: UMat, m: UMat, dst: UMat | None) -> UMat
							pyrUp(src: UMat, dst: UMat | None, dstsize: cv2.typing.Size, borderType: int) -> UMat	transpose(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							randShuffle(dst: cv2.typing.MatLike, iterFactor: float) -> cv2.typing.MatLike	transpose(src: UMat, dst: UMat | None) -> UMat
							randShuffle(dst: UMat, iterFactor: float) -> UMat	triangulatePoints(projMatr1: cv2.typing.MatLike, projMatr2: cv2.typing.MatLike, projPoints1: cv2.typing.MatLike, projPoints2: cv2.typing.MatLike, points4D: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							randn(dst: cv2.typing.MatLike, mean: cv2.typing.MatLike, stddev: cv2.typing.MatLike) -> cv2.typing.MatLike	triangulatePoints(projMatr1: UMat, projMatr2: UMat, projPoints1: UMat, projPoints2: UMat, points4D: UMat | None) -> UMat
							randn(dst: UMat, mean: UMat, stddev: UMat) -> UMat	undistort(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, newCameraMatrix: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							randu(dst: cv2.typing.MatLike, low: cv2.typing.MatLike, high: cv2.typing.MatLike) -> cv2.typing.MatLike	undistort(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, newCameraMatrix: UMat | None) -> UMat
							randu(dst: UMat, low: UMat, high: UMat) -> UMat	undistortImagePoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, arg1: cv2.typing.TermCriteria) -> cv2.typing.MatLike
							readOpticalFlow(path: str) -> cv2.typing.MatLike	undistortImagePoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, arg1: cv2.typing.TermCriteria) -> UMat
							recoverPose(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, E: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, method: int, prob: float, threshold: float, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	undistortPoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, P: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							recoverPose(points1: UMat, points2: UMat, cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, E: UMat | None, R: UMat | None, t: UMat | None, method: int, prob: float, threshold: float, mask: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]	undistortPoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, R: UMat | None, P: UMat | None) -> UMat
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	undistortPointsIter(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, P: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, R: UMat | None, t: UMat | None, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]	undistortPointsIter(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, R: UMat, P: UMat, criteria: cv2.typing.TermCriteria, dst: UMat | None) -> UMat
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, focal: float, pp: cv2.typing.Point2d, mask: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	useOpenVX() -> bool
							recoverPose(E: UMat, points1: UMat, points2: UMat, R: UMat | None, t: UMat | None, focal: float, pp: cv2.typing.Point2d, mask: UMat | None) -> tuple[int, UMat, UMat, UMat]	useOptimized() -> bool
							recoverPose(E: cv2.typing.MatLike, points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distanceThresh: float, R: cv2.typing.MatLike | None, t: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, triangulatedPoints: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	validateDisparity(disparity: cv2.typing.MatLike, cost: cv2.typing.MatLike, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> cv2.typing.MatLike
							recoverPose(E: UMat, points1: UMat, points2: UMat, cameraMatrix: UMat, distanceThresh: float, R: UMat | None, t: UMat | None, mask: UMat | None, triangulatedPoints: UMat | None) -> tuple[int, UMat, UMat, UMat, UMat]	validateDisparity(disparity: UMat, cost: UMat, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> UMat
							rectangle(img: cv2.typing.MatLike, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	waitKey(delay: int) -> int
							rectangle(img: UMat, pt1: cv2.typing.Point, pt2: cv2.typing.Point, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	waitKeyEx(delay: int) -> int
							rectangle(img: cv2.typing.MatLike, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> cv2.typing.MatLike	warpAffine(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							rectangle(img: UMat, rec: cv2.typing.Rect, color: cv2.typing.Scalar, thickness: int, lineType: int, shift: int) -> UMat	warpAffine(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							rectangleIntersectionArea(a: cv2.typing.Rect2d, b: cv2.typing.Rect2d) -> float	warpPerspective(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike
							rectify3Collinear(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, cameraMatrix3: cv2.typing.MatLike, distCoeffs3: cv2.typing.MatLike, imgpt1: _typing.Sequence[cv2.typing.MatLike], imgpt3: _typing.Sequence[cv2.typing.MatLike], imageSize: cv2.typing.Size, R12: cv2.typing.MatLike, T12: cv2.typing.MatLike, R13: cv2.typing.MatLike, T13: cv2.typing.MatLike, alpha: float, newImgSize: cv2.typing.Size, flags: int, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, R3: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, P3: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]	warpPerspective(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat
							rectify3Collinear(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, cameraMatrix3: UMat, distCoeffs3: UMat, imgpt1: _typing.Sequence[UMat], imgpt3: _typing.Sequence[UMat], imageSize: cv2.typing.Size, R12: UMat, T12: UMat, R13: UMat, T13: UMat, alpha: float, newImgSize: cv2.typing.Size, flags: int, R1: UMat | None, R2: UMat | None, R3: UMat | None, P1: UMat | None, P2: UMat | None, P3: UMat | None, Q: UMat | None) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]	warpPolar(src: cv2.typing.MatLike, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike
							reduce(src: cv2.typing.MatLike, dim: int, rtype: int, dst: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	warpPolar(src: UMat, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat
							reduce(src: UMat, dim: int, rtype: int, dst: UMat | None, dtype: int) -> UMat	watershed(image: cv2.typing.MatLike, markers: cv2.typing.MatLike) -> cv2.typing.MatLike
							reduceArgMax(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike	watershed(image: UMat, markers: UMat) -> UMat
							reduceArgMax(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat	writeOpticalFlow(path: str, flow: cv2.typing.MatLike) -> bool
							reduceArgMin(src: cv2.typing.MatLike, axis: int, dst: cv2.typing.MatLike | None, lastIndex: bool) -> cv2.typing.MatLike	writeOpticalFlow(path: str, flow: UMat) -> bool
							reduceArgMin(src: UMat, axis: int, dst: UMat | None, lastIndex: bool) -> UMat	CV_8UC(channels: int) -> int
							remap(src: cv2.typing.MatLike, map1: cv2.typing.MatLike, map2: cv2.typing.MatLike, interpolation: int, dst: cv2.typing.MatLike | None, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	CV_8SC(channels: int) -> int
							remap(src: UMat, map1: UMat, map2: UMat, interpolation: int, dst: UMat | None, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	CV_16UC(channels: int) -> int
							repeat(src: cv2.typing.MatLike, ny: int, nx: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	CV_16SC(channels: int) -> int
							repeat(src: UMat, ny: int, nx: int, dst: UMat | None) -> UMat	CV_32SC(channels: int) -> int
							reprojectImageTo3D(disparity: cv2.typing.MatLike, Q: cv2.typing.MatLike, _3dImage: cv2.typing.MatLike | None, handleMissingValues: bool, ddepth: int) -> cv2.typing.MatLike	CV_32FC(channels: int) -> int
							reprojectImageTo3D(disparity: UMat, Q: UMat, _3dImage: UMat | None, handleMissingValues: bool, ddepth: int) -> UMat	CV_64FC(channels: int) -> int
							resize(src: cv2.typing.MatLike, dsize: cv2.typing.Size | None, dst: cv2.typing.MatLike | None, fx: float, fy: float, interpolation: int) -> cv2.typing.MatLike	CV_16FC(channels: int) -> int
							resize(src: UMat, dsize: cv2.typing.Size | None, dst: UMat | None, fx: float, fy: float, interpolation: int) -> UMat	CV_MAKETYPE(depth: int, channels: int) -> int
							resizeWindow(winname: str, width: int, height: int) -> None	dnn_unregisterLayer(layerTypeName: str) -> None
							resizeWindow(winname: str, size: cv2.typing.Size) -> None	
							rotate(src: cv2.typing.MatLike, rotateCode: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							rotate(src: UMat, rotateCode: int, dst: UMat | None) -> UMat	
							rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							rotatedRectangleIntersection(rect1: cv2.typing.RotatedRect, rect2: cv2.typing.RotatedRect, intersectingRegion: UMat | None) -> tuple[int, UMat]	
							sampsonDistance(pt1: cv2.typing.MatLike, pt2: cv2.typing.MatLike, F: cv2.typing.MatLike) -> float	
							sampsonDistance(pt1: UMat, pt2: UMat, F: UMat) -> float	
							scaleAdd(src1: cv2.typing.MatLike, alpha: float, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							scaleAdd(src1: UMat, alpha: float, src2: UMat, dst: UMat | None) -> UMat	
							seamlessClone(src: cv2.typing.MatLike, dst: cv2.typing.MatLike, mask: cv2.typing.MatLike, p: cv2.typing.Point, flags: int, blend: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							seamlessClone(src: UMat, dst: UMat, mask: UMat, p: cv2.typing.Point, flags: int, blend: UMat | None) -> UMat	
							selectROI(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	
							selectROI(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	
							selectROI(img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	
							selectROI(img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> cv2.typing.Rect	
							selectROIs(windowName: str, img: cv2.typing.MatLike, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> _typing.Sequence[cv2.typing.Rect]	
							selectROIs(windowName: str, img: UMat, showCrosshair: bool, fromCenter: bool, printNotice: bool) -> _typing.Sequence[cv2.typing.Rect]	
							sepFilter2D(src: cv2.typing.MatLike, ddepth: int, kernelX: cv2.typing.MatLike, kernelY: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> cv2.typing.MatLike	
							sepFilter2D(src: UMat, ddepth: int, kernelX: UMat, kernelY: UMat, dst: UMat | None, anchor: cv2.typing.Point, delta: float, borderType: int) -> UMat	
							setIdentity(mtx: cv2.typing.MatLike, s: cv2.typing.Scalar) -> cv2.typing.MatLike	
							setIdentity(mtx: UMat, s: cv2.typing.Scalar) -> UMat	
							setLogLevel(level: int) -> int	
							setNumThreads(nthreads: int) -> None	
							setRNGSeed(seed: int) -> None	
							setTrackbarMax(trackbarname: str, winname: str, maxval: int) -> None	
							setTrackbarMin(trackbarname: str, winname: str, minval: int) -> None	
							setTrackbarPos(trackbarname: str, winname: str, pos: int) -> None	
							setUseOpenVX(flag: bool) -> None	
							setUseOptimized(onoff: bool) -> None	
							setWindowProperty(winname: str, prop_id: int, prop_value: float) -> None	
							setWindowTitle(winname: str, title: str) -> None	
							solve(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike]	
							solve(src1: UMat, src2: UMat, dst: UMat | None, flags: int) -> tuple[bool, UMat]	
							solveCubic(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveCubic(coeffs: UMat, roots: UMat | None) -> tuple[int, UMat]	
							solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, constr_eps: float, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveLP(Func: UMat, Constr: UMat, constr_eps: float, z: UMat | None) -> tuple[int, UMat]	
							solveLP(Func: cv2.typing.MatLike, Constr: cv2.typing.MatLike, z: cv2.typing.MatLike | None) -> tuple[int, cv2.typing.MatLike]	
							solveLP(Func: UMat, Constr: UMat, z: UMat | None) -> tuple[int, UMat]	
							solveP3P(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, flags: int, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike]]	
							solveP3P(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, flags: int, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat]]	
							solvePnP(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnP(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, flags: int) -> tuple[bool, UMat, UMat]	
							solvePnPGeneric(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, useExtrinsicGuess: bool, flags: SolvePnPMethod, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, reprojectionError: cv2.typing.MatLike | None) -> tuple[int, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	
							solvePnPGeneric(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, useExtrinsicGuess: bool, flags: SolvePnPMethod, rvec: UMat | None, tvec: UMat | None, reprojectionError: UMat | None) -> tuple[int, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	
							solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: cv2.typing.MatLike | None, flags: int) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, useExtrinsicGuess: bool, iterationsCount: int, reprojectionError: float, confidence: float, inliers: UMat | None, flags: int) -> tuple[bool, UMat, UMat, UMat]	
							solvePnPRansac(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike | None, tvec: cv2.typing.MatLike | None, inliers: cv2.typing.MatLike | None, params: UsacParams) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRansac(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat | None, tvec: UMat | None, inliers: UMat | None, params: UsacParams) -> tuple[bool, UMat, UMat, UMat, UMat]	
							solvePnPRefineLM(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRefineLM(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria) -> tuple[UMat, UMat]	
							solvePnPRefineVVS(objectPoints: cv2.typing.MatLike, imagePoints: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, rvec: cv2.typing.MatLike, tvec: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							solvePnPRefineVVS(objectPoints: UMat, imagePoints: UMat, cameraMatrix: UMat, distCoeffs: UMat, rvec: UMat, tvec: UMat, criteria: cv2.typing.TermCriteria, VVSlambda: float) -> tuple[UMat, UMat]	
							solvePoly(coeffs: cv2.typing.MatLike, roots: cv2.typing.MatLike | None, maxIters: int) -> tuple[float, cv2.typing.MatLike]	
							solvePoly(coeffs: UMat, roots: UMat | None, maxIters: int) -> tuple[float, UMat]	
							sort(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sort(src: UMat, flags: int, dst: UMat | None) -> UMat	
							sortIdx(src: cv2.typing.MatLike, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sortIdx(src: UMat, flags: int, dst: UMat | None) -> UMat	
							spatialGradient(src: cv2.typing.MatLike, dx: cv2.typing.MatLike | None, dy: cv2.typing.MatLike | None, ksize: int, borderType: int) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike]	
							spatialGradient(src: UMat, dx: UMat | None, dy: UMat | None, ksize: int, borderType: int) -> tuple[UMat, UMat]	
							split(m: cv2.typing.MatLike, mv: _typing.Sequence[cv2.typing.MatLike] | None) -> _typing.Sequence[cv2.typing.MatLike]	
							split(m: UMat, mv: _typing.Sequence[UMat] | None) -> _typing.Sequence[UMat]	
							sqrBoxFilter(src: cv2.typing.MatLike, ddepth: int, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> cv2.typing.MatLike	
							sqrBoxFilter(src: UMat, ddepth: int, ksize: cv2.typing.Size, dst: UMat | None, anchor: cv2.typing.Point, normalize: bool, borderType: int) -> UMat	
							sqrt(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							sqrt(src: UMat, dst: UMat | None) -> UMat	
							stackBlur(src: cv2.typing.MatLike, ksize: cv2.typing.Size, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							stackBlur(src: UMat, ksize: cv2.typing.Size, dst: UMat | None) -> UMat	
							startWindowThread() -> int	
							stereoCalibrate(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike | None, T: cv2.typing.MatLike | None, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoCalibrate(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat | None, T: UMat | None, E: UMat | None, F: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	
							stereoCalibrate(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoCalibrate(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, E: UMat | None, F: UMat | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat]	
							stereoCalibrateExtended(objectPoints: _typing.Sequence[cv2.typing.MatLike], imagePoints1: _typing.Sequence[cv2.typing.MatLike], imagePoints2: _typing.Sequence[cv2.typing.MatLike], cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, E: cv2.typing.MatLike | None, F: cv2.typing.MatLike | None, rvecs: _typing.Sequence[cv2.typing.MatLike] | None, tvecs: _typing.Sequence[cv2.typing.MatLike] | None, perViewErrors: cv2.typing.MatLike | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, _typing.Sequence[cv2.typing.MatLike], _typing.Sequence[cv2.typing.MatLike], cv2.typing.MatLike]	
							stereoCalibrateExtended(objectPoints: _typing.Sequence[UMat], imagePoints1: _typing.Sequence[UMat], imagePoints2: _typing.Sequence[UMat], cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, E: UMat | None, F: UMat | None, rvecs: _typing.Sequence[UMat] | None, tvecs: _typing.Sequence[UMat] | None, perViewErrors: UMat | None, flags: int, criteria: cv2.typing.TermCriteria) -> tuple[float, UMat, UMat, UMat, UMat, UMat, UMat, UMat, UMat, _typing.Sequence[UMat], _typing.Sequence[UMat], UMat]	
							stereoRectify(cameraMatrix1: cv2.typing.MatLike, distCoeffs1: cv2.typing.MatLike, cameraMatrix2: cv2.typing.MatLike, distCoeffs2: cv2.typing.MatLike, imageSize: cv2.typing.Size, R: cv2.typing.MatLike, T: cv2.typing.MatLike, R1: cv2.typing.MatLike | None, R2: cv2.typing.MatLike | None, P1: cv2.typing.MatLike | None, P2: cv2.typing.MatLike | None, Q: cv2.typing.MatLike | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.MatLike, cv2.typing.Rect, cv2.typing.Rect]	
							stereoRectify(cameraMatrix1: UMat, distCoeffs1: UMat, cameraMatrix2: UMat, distCoeffs2: UMat, imageSize: cv2.typing.Size, R: UMat, T: UMat, R1: UMat | None, R2: UMat | None, P1: UMat | None, P2: UMat | None, Q: UMat | None, flags: int, alpha: float, newImageSize: cv2.typing.Size) -> tuple[UMat, UMat, UMat, UMat, UMat, cv2.typing.Rect, cv2.typing.Rect]	
							stereoRectifyUncalibrated(points1: cv2.typing.MatLike, points2: cv2.typing.MatLike, F: cv2.typing.MatLike, imgSize: cv2.typing.Size, H1: cv2.typing.MatLike | None, H2: cv2.typing.MatLike | None, threshold: float) -> tuple[bool, cv2.typing.MatLike, cv2.typing.MatLike]	
							stereoRectifyUncalibrated(points1: UMat, points2: UMat, F: UMat, imgSize: cv2.typing.Size, H1: UMat | None, H2: UMat | None, threshold: float) -> tuple[bool, UMat, UMat]	
							stylization(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, sigma_s: float, sigma_r: float) -> cv2.typing.MatLike	
							stylization(src: UMat, dst: UMat | None, sigma_s: float, sigma_r: float) -> UMat	
							subtract(src1: cv2.typing.MatLike, src2: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, mask: cv2.typing.MatLike | None, dtype: int) -> cv2.typing.MatLike	
							subtract(src1: UMat, src2: UMat, dst: UMat | None, mask: UMat | None, dtype: int) -> UMat	
							sumElems(src: cv2.typing.MatLike) -> cv2.typing.Scalar	
							sumElems(src: UMat) -> cv2.typing.Scalar	
							textureFlattening(src: cv2.typing.MatLike, mask: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, low_threshold: float, high_threshold: float, kernel_size: int) -> cv2.typing.MatLike	
							textureFlattening(src: UMat, mask: UMat, dst: UMat | None, low_threshold: float, high_threshold: float, kernel_size: int) -> UMat	
							threshold(src: cv2.typing.MatLike, thresh: float, maxval: float, type: int, dst: cv2.typing.MatLike | None) -> tuple[float, cv2.typing.MatLike]	
							threshold(src: UMat, thresh: float, maxval: float, type: int, dst: UMat | None) -> tuple[float, UMat]	
							trace(mtx: cv2.typing.MatLike) -> cv2.typing.Scalar	
							trace(mtx: UMat) -> cv2.typing.Scalar	
							transform(src: cv2.typing.MatLike, m: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transform(src: UMat, m: UMat, dst: UMat | None) -> UMat	
							transpose(src: cv2.typing.MatLike, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transpose(src: UMat, dst: UMat | None) -> UMat	
							transposeND(src: cv2.typing.MatLike, order: _typing.Sequence[int], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							transposeND(src: UMat, order: _typing.Sequence[int], dst: UMat | None) -> UMat	
							triangulatePoints(projMatr1: cv2.typing.MatLike, projMatr2: cv2.typing.MatLike, projPoints1: cv2.typing.MatLike, projPoints2: cv2.typing.MatLike, points4D: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							triangulatePoints(projMatr1: UMat, projMatr2: UMat, projPoints1: UMat, projPoints2: UMat, points4D: UMat | None) -> UMat	
							undistort(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, newCameraMatrix: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistort(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, newCameraMatrix: UMat | None) -> UMat	
							undistortImagePoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, arg1: cv2.typing.TermCriteria) -> cv2.typing.MatLike	
							undistortImagePoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, arg1: cv2.typing.TermCriteria) -> UMat	
							undistortPoints(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, dst: cv2.typing.MatLike | None, R: cv2.typing.MatLike | None, P: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistortPoints(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, dst: UMat | None, R: UMat | None, P: UMat | None) -> UMat	
							undistortPointsIter(src: cv2.typing.MatLike, cameraMatrix: cv2.typing.MatLike, distCoeffs: cv2.typing.MatLike, R: cv2.typing.MatLike, P: cv2.typing.MatLike, criteria: cv2.typing.TermCriteria, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							undistortPointsIter(src: UMat, cameraMatrix: UMat, distCoeffs: UMat, R: UMat, P: UMat, criteria: cv2.typing.TermCriteria, dst: UMat | None) -> UMat	
							useOpenVX() -> bool	
							useOptimized() -> bool	
							validateDisparity(disparity: cv2.typing.MatLike, cost: cv2.typing.MatLike, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> cv2.typing.MatLike	
							validateDisparity(disparity: UMat, cost: UMat, minDisparity: int, numberOfDisparities: int, disp12MaxDisp: int) -> UMat	
							vconcat(src: _typing.Sequence[cv2.typing.MatLike], dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							vconcat(src: _typing.Sequence[UMat], dst: UMat | None) -> UMat	
							waitKey(delay: int) -> int	
							waitKeyEx(delay: int) -> int	
							warpAffine(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	
							warpAffine(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	
							warpPerspective(src: cv2.typing.MatLike, M: cv2.typing.MatLike, dsize: cv2.typing.Size, dst: cv2.typing.MatLike | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> cv2.typing.MatLike	
							warpPerspective(src: UMat, M: UMat, dsize: cv2.typing.Size, dst: UMat | None, flags: int, borderMode: int, borderValue: cv2.typing.Scalar) -> UMat	
							warpPolar(src: cv2.typing.MatLike, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: cv2.typing.MatLike | None) -> cv2.typing.MatLike	
							warpPolar(src: UMat, dsize: cv2.typing.Size, center: cv2.typing.Point2f, maxRadius: float, flags: int, dst: UMat | None) -> UMat	
							watershed(image: cv2.typing.MatLike, markers: cv2.typing.MatLike) -> cv2.typing.MatLike	
							watershed(image: UMat, markers: UMat) -> UMat	
							writeOpticalFlow(path: str, flow: cv2.typing.MatLike) -> bool	
							writeOpticalFlow(path: str, flow: UMat) -> bool	
							createTrackbar(trackbarName: str, windowName: str, value: int, count: int, onChange: _typing.Callable[[int], None]) -> None	
							createButton(buttonName: str, onChange: _typing.Callable[[tuple[int] | tuple[int, _typing.Any]], None], userData: _typing.Any | None, buttonType: int, initialButtonState: int) -> None	
							setMouseCallback(windowName: str, onMouse: _typing.Callable[[int, int, int, int, _typing.Any | None], None], param: _typing.Any | None) -> None	
							CV_8UC(channels: int) -> int	
							CV_8SC(channels: int) -> int	
							CV_16UC(channels: int) -> int	
							CV_16SC(channels: int) -> int	
							CV_32SC(channels: int) -> int	
							CV_32FC(channels: int) -> int	
							CV_64FC(channels: int) -> int	
							CV_16FC(channels: int) -> int	
							CV_MAKETYPE(depth: int, channels: int) -> int	
							dnn_registerLayer(layerTypeName: str, layerClass: _typing.Type[cv2.dnn.LayerProtocol]) -> None	
							dnn_unregisterLayer(layerTypeName: str) -> None	
							redirectError(onError: _typing.Callable[[int, str, str, str, int], None] | None) -> None	
